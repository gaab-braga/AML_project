{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caec9e05",
   "metadata": {},
   "source": [
    "# Multi-GNN Benchmark Development no Google Colab\n",
    "\n",
    "Este notebook automatiza todo o processo de desenvolvimento do Multi-GNN para detec√ß√£o de AML:\n",
    "\n",
    "1. **Instala√ß√£o do ambiente** com PyTorch e PyTorch Geometric\n",
    "2. **Download dos dados** do Kaggle (dataset IBM AML)\n",
    "3. **Clone e modifica√ß√£o** do reposit√≥rio IBM/multi-gnn\n",
    "4. **Execu√ß√£o do pipeline** de treinamento e gera√ß√£o de predi√ß√µes\n",
    "\n",
    "## üöÄ Como usar:\n",
    "\n",
    "1. Execute todas as c√©lulas em ordem\n",
    "2. Para teste r√°pido, use `--sample-size 10000` na √∫ltima c√©lula\n",
    "3. O arquivo `multi_gnn_predictions.csv` ser√° gerado em `/content/`\n",
    "\n",
    "## üìã Requisitos:\n",
    "\n",
    "- Conta Kaggle com API key\n",
    "- GPU habilitada no Colab (T4 recomendada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b5c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script Aut√¥nomo para Desenvolvimento do Multi-GNN no Google Colab\n",
    "\n",
    "Este script automatiza todo o processo:\n",
    "1. Instala√ß√£o do ambiente com pip.\n",
    "2. Download dos dados do Kaggle.\n",
    "3. Clone do reposit√≥rio IBM/multi-gnn.\n",
    "4. Modifica√ß√£o do c√≥digo para salvar predi√ß√µes.\n",
    "5. Execu√ß√£o do pipeline de treinamento.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import shutil\n",
    "import argparse\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command, cwd=None):\n",
    "    \"\"\"Executa um comando no shell e lida com erros.\"\"\"\n",
    "    print(f\"üöÄ Executando: {' '.join(command)}\")\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            command,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True,\n",
    "            cwd=cwd\n",
    "        )\n",
    "        print(result.stdout)\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå ERRO ao executar comando: {' '.join(command)}\")\n",
    "        print(f\"STDOUT: {e.stdout}\")\n",
    "        print(f\"STDERR: {e.stderr}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4debc55",
   "metadata": {},
   "source": [
    "## üì¶ Classe ColabMultiGNNBenchmark\n",
    "\n",
    "Classe principal que gerencia todo o pipeline de desenvolvimento do Multi-GNN no ambiente Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColabMultiGNNBenchmark:\n",
    "    \"\"\"Gerencia o pipeline de benchmark do Multi-GNN no Colab.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.workdir = Path(\"/content/aml_project\")\n",
    "        self.repo_path = self.workdir / \"multi-gnn\"\n",
    "        self.data_path = self.workdir / \"data\"\n",
    "        self.raw_data_path = self.data_path / \"raw\"\n",
    "        self.processed_data_path = self.data_path / \"processed\" / \"Small_HI\"\n",
    "        self.kaggle_data_path = self.raw_data_path / \"ibm-transactions-for-anti-money-laundering-aml\"\n",
    "\n",
    "        # Criar diret√≥rios\n",
    "        for path in [self.workdir, self.raw_data_path, self.processed_data_path]:\n",
    "            path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e49724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment(self):\n",
    "    \"\"\"Fase 1: Instalar depend√™ncias com pip.\"\"\"\n",
    "    print(\"üîß FASE 1: Instalando ambiente...\")\n",
    "\n",
    "    commands = [\n",
    "        [\"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"],\n",
    "        [\"pip\", \"install\", \"torch-scatter\", \"torch-sparse\", \"-f\", \"https://data.pyg.org/whl/torch-2.1.0+cu118.html\"],\n",
    "        [\"pip\", \"install\", \"torch-geometric\"],\n",
    "        [\"pip\", \"install\", \"datatable\", \"wandb\", \"tqdm\", \"scikit-learn\", \"pandas\", \"numpy\", \"munch\"]\n",
    "    ]\n",
    "\n",
    "    for cmd in commands:\n",
    "        if not run_command(cmd):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f566d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(self, sample_size=None):\n",
    "    \"\"\"Fase 2: Baixar dados do Kaggle.\"\"\"\n",
    "    print(\"üìä FASE 2: Baixando dados do Kaggle...\")\n",
    "\n",
    "    # Configurar Kaggle API\n",
    "    if not Path(\"/root/.kaggle/kaggle.json\").exists():\n",
    "        print(\"‚ùå ERRO: Arquivo kaggle.json n√£o encontrado.\")\n",
    "        print(\"   Fa√ßa o upload do seu arquivo kaggle.json para a sess√£o do Colab.\")\n",
    "        return False\n",
    "\n",
    "    run_command([\"chmod\", \"600\", \"/root/.kaggle/kaggle.json\"])\n",
    "\n",
    "    # Baixar e descompactar\n",
    "    dataset = \"ealtman2019/ibm-transactions-for-anti-money-laundering-aml\"\n",
    "    if not run_command([\"kaggle\", \"datasets\", \"download\", \"-d\", dataset, \"-p\", str(self.raw_data_path)]):\n",
    "        return False\n",
    "    if not run_command([\"unzip\", \"-o\", str(self.raw_data_path / f\"{dataset.split('/')[1]}.zip\"), \"-d\", str(self.kaggle_data_path)]):\n",
    "        return False\n",
    "\n",
    "    # Criar sample se solicitado\n",
    "    if sample_size:\n",
    "        print(f\"üéØ Criando sample de {sample_size} registros...\")\n",
    "        import pandas as pd\n",
    "        csv_file = self.kaggle_data_path / \"HI-Small_Trans.csv\"\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df_sample = df.sample(n=sample_size, random_state=42)\n",
    "        df_sample.to_csv(csv_file, index=False)\n",
    "        print(f\"‚úÖ Sample criado: {len(df_sample)} registros\")\n",
    "\n",
    "    print(\"‚úÖ Dados baixados com sucesso.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_and_patch_repo(self):\n",
    "    \"\"\"Fase 3: Clonar e modificar o reposit√≥rio.\"\"\"\n",
    "    print(\"üîß FASE 3: Clonando e modificando o reposit√≥rio...\")\n",
    "\n",
    "    # Clonar\n",
    "    if not run_command([\"git\", \"clone\", \"https://github.com/ibm/multi-gnn.git\"], cwd=self.workdir):\n",
    "        return False\n",
    "\n",
    "    # Modificar train_util.py\n",
    "    train_util_file = self.repo_path / \"train_util.py\"\n",
    "    with open(train_util_file, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    if \"--- IN√çCIO DA MODIFICA√á√ÉO ---\" in content:\n",
    "        print(\"‚úÖ Reposit√≥rio j√° modificado.\")\n",
    "        return True\n",
    "\n",
    "    # C√≥digo de modifica√ß√£o\n",
    "    modification_code = '''\n",
    "# --- IN√çCIO DA MODIFICA√á√ÉO ---\n",
    "import pandas as pd\n",
    "import os\n",
    "if args.save_model:\n",
    "    print(\"üíæ Salvando predi√ß√µes do conjunto de teste...\")\n",
    "    pred_numpy = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    gt_numpy = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "    output_df = pd.DataFrame({'prediction_prob': pred_numpy, 'ground_truth': gt_numpy})\n",
    "    output_df.to_csv(\"/content/multi_gnn_predictions.csv\", index=False)\n",
    "    print(f\"‚úÖ Predi√ß√µes salvas em /content/multi_gnn_predictions.csv\")\n",
    "# --- FIM DA MODIFICA√á√ÉO ---\n",
    "'''\n",
    "    # Inserir antes do `return f1` na fun√ß√£o `evaluate_homo`\n",
    "    content = content.replace(\"    return f1\", f\"{modification_code}\\n    return f1\")\n",
    "\n",
    "    with open(train_util_file, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "    print(\"‚úÖ Reposit√≥rio modificado com sucesso.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(self, epochs=50, sample_size=None):\n",
    "    \"\"\"Fase 4: Executar o pipeline de dados e treinamento.\"\"\"\n",
    "    print(\"üöÄ FASE 4: Executando pipeline...\")\n",
    "\n",
    "    # Formatar dados\n",
    "    kaggle_csv = self.kaggle_data_path / \"HI-Small_Trans.csv\"\n",
    "    if not run_command([\"python\", \"format_kaggle_files.py\", str(kaggle_csv)], cwd=self.repo_path):\n",
    "        return False\n",
    "\n",
    "    # Mover arquivo formatado\n",
    "    shutil.move(\n",
    "        str(self.kaggle_data_path / \"formatted_transactions.csv\"),\n",
    "        str(self.processed_data_path / \"formatted_transactions.csv\")\n",
    "    )\n",
    "\n",
    "    # Atualizar data_config.json\n",
    "    config_file = self.repo_path / \"data_config.json\"\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    config[\"paths\"][\"aml_data\"] = str(self.data_path / \"processed\")\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "    # Treinar\n",
    "    train_cmd = [\n",
    "        \"python\", \"main.py\",\n",
    "        \"--data\", \"Small_HI\",\n",
    "        \"--model\", \"gin\",\n",
    "        \"--emlps\", \"--reverse_mp\", \"--ego\", \"--ports\",\n",
    "        \"--testing\",\n",
    "        \"--n_epochs\", str(epochs),\n",
    "        \"--batch_size\", \"2048\",\n",
    "        \"--save_model\",\n",
    "        \"--unique_name\", \"colab_benchmark\"\n",
    "    ]\n",
    "    if not run_command(train_cmd, cwd=self.repo_path):\n",
    "        return False\n",
    "\n",
    "    print(\"‚úÖ Pipeline executado com sucesso.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c22a8",
   "metadata": {},
   "source": [
    "## üéØ Fun√ß√£o Main\n",
    "\n",
    "Fun√ß√£o principal que orquestra todas as fases do pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Orquestra todas as fases.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Multi-GNN Benchmark Development')\n",
    "    parser.add_argument('--sample-size', type=int, default=None,\n",
    "                       help='Tamanho da amostra para teste (opcional)')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    benchmark = ColabMultiGNNBenchmark()\n",
    "\n",
    "    phases = [\n",
    "        (\"Configura√ß√£o do Ambiente\", benchmark.setup_environment),\n",
    "        (\"Download dos Dados\", lambda: benchmark.download_data(sample_size=args.sample_size)),\n",
    "        (\"Clone e Modifica√ß√£o do Reposit√≥rio\", benchmark.clone_and_patch_repo),\n",
    "        (\"Execu√ß√£o do Pipeline\", lambda: benchmark.run_pipeline(sample_size=args.sample_size))\n",
    "    ]\n",
    "\n",
    "    for name, func in phases:\n",
    "        if not func():\n",
    "            print(f\"‚ùå FALHA na fase: {name}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    print(\"\\nüéâ PROCESSO CONCLU√çDO! üéâ\")\n",
    "    print(\"üìÑ O arquivo 'multi_gnn_predictions.csv' est√° pronto no diret√≥rio /content/.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1cb7d",
   "metadata": {},
   "source": [
    "## üîë Configura√ß√£o do Kaggle API\n",
    "\n",
    "Antes de executar o pipeline, voc√™ precisa configurar sua chave API do Kaggle.\n",
    "\n",
    "Execute o c√≥digo abaixo para fazer upload do seu arquivo `kaggle.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload do kaggle.json\n",
    "from google.colab import files\n",
    "\n",
    "# Criar diret√≥rio e fazer upload\n",
    "!mkdir -p /root/.kaggle/\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    !mv {fn} /root/.kaggle/kaggle.json\n",
    "    !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "print(\"‚úÖ Kaggle API configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2834b",
   "metadata": {},
   "source": [
    "## üöÄ Execu√ß√£o do Pipeline\n",
    "\n",
    "Agora execute o pipeline completo. Para teste r√°pido, use `--sample-size 10000` para trabalhar com uma amostra menor.\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANTE**: A primeira execu√ß√£o completa pode levar 2-3 horas. Use sample-size para testes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47709512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execu√ß√£o do Pipeline Multi-GNN\n",
    "# ‚ö†Ô∏è IMPORTANTE: Modifique SAMPLE_SIZE abaixo para None (dados completos) ou um n√∫mero (amostra)\n",
    "\n",
    "SAMPLE_SIZE = 10000  # None para dados completos, 10000 para teste r√°pido\n",
    "\n",
    "# Simular argumentos de linha de comando\n",
    "import sys\n",
    "sys.argv = ['colab_develop_multignn.py']\n",
    "if SAMPLE_SIZE is not None:\n",
    "    sys.argv.extend(['--sample-size', str(SAMPLE_SIZE)])\n",
    "\n",
    "# Executar o pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b145d",
   "metadata": {},
   "source": [
    "## üì• Download dos Resultados\n",
    "\n",
    "Ap√≥s a conclus√£o bem-sucedida, baixe o arquivo de predi√ß√µes para usar no benchmark contra XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download do arquivo de predi√ß√µes\n",
    "from google.colab import files\n",
    "\n",
    "try:\n",
    "    files.download('/content/multi_gnn_predictions.csv')\n",
    "    print(\"‚úÖ Arquivo baixado com sucesso!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Arquivo n√£o encontrado. Verifique se o pipeline foi executado com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
