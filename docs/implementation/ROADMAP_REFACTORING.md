# üöÄ Roadmap de Refatora√ß√£o: AML Project - Do Notebook √† Produ√ß√£o

> **Objetivo:** Transformar um projeto de ci√™ncia de dados baseado em notebooks em um sistema profissional, modular e pronto para produ√ß√£o, seguindo princ√≠pios de Clean Code, MLOps e arquitetura de software.

---

## üìã Sum√°rio Executivo

### Situa√ß√£o Atual
- ‚úÖ **Notebooks completos e funcionais** (7 notebooks de ponta a ponta)
- ‚úÖ **Modelos treinados e avaliados** com m√©tricas excelentes
- ‚úÖ **Estrutura inicial de produ√ß√£o** (API, dashboard, scripts)
- ‚ö†Ô∏è **C√≥digo duplicado** entre notebooks e m√≥dulos `src/`
- ‚ö†Ô∏è **Refer√™ncias legadas** em scripts e configura√ß√µes
- ‚ö†Ô∏è **Complexidade desnecess√°ria** em alguns m√≥dulos

### Objetivo Final
Um sistema de ML profissional com:
- **Modularidade:** Cada m√≥dulo tem responsabilidade √∫nica e clara
- **Reprodutibilidade:** Qualquer pessoa pode executar o pipeline completo
- **Manutenibilidade:** C√≥digo limpo, documentado e testado
- **Production-Ready:** API, monitoramento, logging e deployment

---

## üéØ Princ√≠pios Orientadores

### 1. **KISS (Keep It Simple, Stupid)**
- Se pode ser feito em 10 linhas, n√£o fa√ßa em 100
- Evite abstra√ß√µes prematuras
- Prefira clareza sobre "eleg√¢ncia"

### 2. **DRY (Don't Repeat Yourself)**
- Fun√ß√£o escrita uma vez, usada em m√∫ltiplos lugares
- Configura√ß√µes centralizadas
- Zero duplica√ß√£o entre notebooks e c√≥digo de produ√ß√£o

### 3. **Single Responsibility Principle**
- Cada m√≥dulo/fun√ß√£o faz **UMA COISA** e a faz bem
- Nomes descritivos que revelam a inten√ß√£o
- Separa√ß√£o clara entre: dados, features, modelos, avalia√ß√£o, deploy

### 4. **Human-Readable Code**
- C√≥digo auto-explicativo (nomes claros > coment√°rios excessivos)
- Estrutura intuitiva de diret√≥rios
- Documenta√ß√£o concisa e objetiva

---

## üìÇ An√°lise da Estrutura Atual

### ‚úÖ O que **MANTER**

#### 1. `data/` - Dados do Projeto
```
data/
‚îú‚îÄ‚îÄ raw/          # ‚úÖ Dados originais, imut√°veis
‚îî‚îÄ‚îÄ processed/    # ‚úÖ Dados prontos para modelagem
```
**Status:** Estrutura correta. Manter.

#### 2. `models/` - Artefatos de Modelo
```
models/
‚îú‚îÄ‚îÄ *.pkl         # Modelos serializados
‚îú‚îÄ‚îÄ *.pt          # Modelos PyTorch
‚îî‚îÄ‚îÄ metadata.yaml # Metadados dos modelos
```
**Status:** Correto. Adicionar versionamento sem√¢ntico.

#### 3. `artifacts/` - Resultados e M√©tricas
```
artifacts/
‚îú‚îÄ‚îÄ *_results.json
‚îú‚îÄ‚îÄ *_report.json
‚îú‚îÄ‚îÄ *.csv
‚îî‚îÄ‚îÄ shap_plots/
```
**Status:** Bom para rastreabilidade. Manter.

#### 4. `notebooks/` - Explora√ß√£o e Relat√≥rios
```
notebooks/
‚îú‚îÄ‚îÄ 01_Data_Ingestion_EDA.ipynb
‚îú‚îÄ‚îÄ 02_IBM_Benchmark.ipynb
‚îú‚îÄ‚îÄ 03_Model_Selection_Tuning.ipynb
‚îú‚îÄ‚îÄ 04_Ensemble_Modeling.ipynb
‚îú‚îÄ‚îÄ 05_Model_Interpretation.ipynb
‚îú‚îÄ‚îÄ 06_Robustness_Validation.ipynb
‚îî‚îÄ‚îÄ 07_Executive_Summary.ipynb
```
**Status:** Excelente documenta√ß√£o. Notebooks devem **importar** fun√ß√µes de `src/`, n√£o reimplement√°-las.

#### 5. `config/` - Configura√ß√µes
```
config/
‚îú‚îÄ‚îÄ pipeline_config.yaml       # ‚úÖ Pipeline ML
‚îú‚îÄ‚îÄ features.yaml              # ‚úÖ Feature engineering
‚îú‚îÄ‚îÄ monitoring_config.yaml     # ‚úÖ Monitoramento
‚îú‚îÄ‚îÄ dashboard_config.yaml      # ‚úÖ Dashboard
‚îî‚îÄ‚îÄ security_config.yaml       # ‚úÖ Seguran√ßa
```
**Status:** Bem organizado. Consolidar em um √∫nico `config.yaml` principal.

---

### ‚ö†Ô∏è O que **REFATORAR**

#### 1. `src/` - C√≥digo Fonte (CR√çTICO)

**Estrutura Atual:**
```
src/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ eda/
‚îú‚îÄ‚îÄ evaluation/
‚îú‚îÄ‚îÄ evaluation_module/    # ‚ö†Ô∏è Duplica√ß√£o com evaluation/
‚îú‚îÄ‚îÄ features/
‚îú‚îÄ‚îÄ interfaces/
‚îú‚îÄ‚îÄ modeling/
‚îú‚îÄ‚îÄ models/               # ‚ö†Ô∏è Confuso com models/ na raiz
‚îú‚îÄ‚îÄ optimization/
‚îú‚îÄ‚îÄ orchestration/
‚îú‚îÄ‚îÄ reporting/
‚îú‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ visualization/
‚îî‚îÄ‚îÄ monitoring_service.py
```

**Problemas Identificados:**
- **Duplica√ß√£o:** `evaluation/` vs `evaluation_module/`
- **Confus√£o:** `src/models/` vs `models/` (raiz)
- **Over-engineering:** M√≥dulos como `interfaces/`, `orchestration/` podem estar vazios ou subutilizados
- **Falta de clareza:** Muitos subdiret√≥rios dificultam navega√ß√£o

**Estrutura Proposta (LIMPA):**
```
src/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ config.py              # Carregamento centralizado de configs
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ loader.py          # Carregar dados brutos
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py   # Limpeza e transforma√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ engineering.py     # Criar features (temporal, network, etc)
‚îÇ   ‚îî‚îÄ‚îÄ selection.py       # Sele√ß√£o de features
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ train.py           # Treinamento de modelos
‚îÇ   ‚îú‚îÄ‚îÄ predict.py         # Predi√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py        # M√©tricas e avalia√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ explainability/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ shap_analysis.py   # SHAP e interpretabilidade
‚îÇ
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ service.py         # Monitoramento de produ√ß√£o
‚îÇ
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ logger.py          # Logging centralizado
    ‚îî‚îÄ‚îÄ helpers.py         # Fun√ß√µes auxiliares gen√©ricas

entrypoints/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ cli.py                 # Interface de linha de comando (Click/Typer)
‚îú‚îÄ‚îÄ api.py                 # API REST (FastAPI)
‚îú‚îÄ‚îÄ batch.py               # Processamento em batch
‚îî‚îÄ‚îÄ stream.py              # Processamento em stream (Kafka/Redis)
```

**A√ß√µes:**
1. **Deletar:** `evaluation_module/`, `src/models/`, `interfaces/`, `orchestration/`, `eda/`, `reporting/`
2. **Consolidar:** Mover c√≥digo √∫til para os m√≥dulos principais
3. **Simplificar:** Reduzir de 15+ subdiret√≥rios para 6 essenciais
4. **Criar:** Novo diret√≥rio `entrypoints/` para separar pontos de entrada do core business logic

---

#### 2. `entrypoints/` - Pontos de Entrada do Sistema (NOVO!)

**Por que criar este diret√≥rio?**

Em uma arquitetura limpa, **separamos a l√≥gica de neg√≥cio (src/) dos pontos de entrada (entrypoints/)**. Isso permite:

- ‚úÖ **M√∫ltiplas interfaces** para o mesmo core: CLI, API REST, batch jobs, streaming
- ‚úÖ **Testabilidade:** Testar l√≥gica de neg√≥cio sem inicializar servidor/CLI
- ‚úÖ **Flexibilidade:** Adicionar novos entrypoints sem modificar `src/`
- ‚úÖ **Clareza:** Fica expl√≠cito onde o sistema pode ser invocado

**Estrutura Proposta:**
```
entrypoints/
‚îú‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ cli.py                 # Interface de linha de comando
‚îÇ   ‚îî‚îÄ‚îÄ Comandos: train, predict, evaluate, serve
‚îÇ
‚îú‚îÄ‚îÄ api.py                 # API REST (FastAPI)
‚îÇ   ‚îî‚îÄ‚îÄ Endpoints: /predict, /batch, /health
‚îÇ
‚îú‚îÄ‚îÄ batch.py               # Processamento em lote (Airflow/Cron)
‚îÇ   ‚îî‚îÄ‚îÄ Processa grandes volumes de dados
‚îÇ
‚îî‚îÄ‚îÄ stream.py              # Processamento em tempo real (Kafka/Redis)
    ‚îî‚îÄ‚îÄ Consome eventos e faz predi√ß√µes
```

**Exemplo de Uso:**
```powershell
# Via CLI
python -m entrypoints.cli train --config config/pipeline_config.yaml
python -m entrypoints.cli predict --input data.csv --output predictions.csv

# Via API
python -m entrypoints.api
# ou
uvicorn entrypoints.api:app --reload

# Via Batch (scheduled)
python -m entrypoints.batch --date 2025-11-06

# Via Stream
python -m entrypoints.stream --kafka-topic transactions
```

**A√ß√µes:**
1. **Criar:** Novo diret√≥rio `entrypoints/` na raiz (mesmo n√≠vel que `src/`)
2. **Migrar:** C√≥digo de `api/production_api.py` ‚Üí `entrypoints/api.py`
3. **Migrar:** L√≥gica de `scripts/train_pipeline.py` ‚Üí `entrypoints/cli.py`
4. **Deletar:** Diret√≥rio `api/` antigo (substitu√≠do por `entrypoints/api.py`)

---

#### 3. `scripts/` - Scripts Utilit√°rios (REDUZIDO)

**Estrutura Atual:**
```
scripts/
‚îú‚îÄ‚îÄ integrate_patterns.py
‚îú‚îÄ‚îÄ pattern_integration_demo.py
‚îú‚îÄ‚îÄ production_readiness.py
‚îú‚îÄ‚îÄ reproduce_all.py
‚îú‚îÄ‚îÄ retraining_pipeline.py
‚îú‚îÄ‚îÄ robustness_validation.py
‚îú‚îÄ‚îÄ scenario_analysis_demo.py
‚îî‚îÄ‚îÄ README_convert_to_multignn_csv.md
```

**Problemas:**
- Nomes gen√©ricos (`demo`, `integrate`)
- Mistura de responsabilidades (alguns deveriam estar em `entrypoints/`)
- Alguns podem estar obsoletos

**Estrutura Proposta (MINIMALISTA):**
```
scripts/
‚îú‚îÄ‚îÄ setup_project.sh       # Setup inicial do projeto
‚îú‚îÄ‚îÄ export_to_multignn.py  # Convers√£o para benchmark IBM
‚îî‚îÄ‚îÄ generate_report.py     # Relat√≥rios ad-hoc para stakeholders
```

**A√ß√µes:**
1. **Migrar:** `reproduce_all.py`, `retraining_pipeline.py` ‚Üí `entrypoints/cli.py`
2. **Deletar:** Todos os arquivos `*_demo.py` (c√≥digo deve estar em `src/`)
3. **Deletar:** `production_readiness.py` (l√≥gica em `src/`, invocado via `entrypoints/`)
4. **Manter:** Apenas scripts auxiliares que N√ÉO fazem parte do fluxo principal

---

#### 4. `dashboard/` - Dashboard Streamlit

**Estrutura Atual:**
```
dashboard/
‚îî‚îÄ‚îÄ app.py
```

**Status:** Funcional. Garantir que importa de `src/` e n√£o reimplementa l√≥gica.

---

### üóëÔ∏è O que **DELETAR**

#### Diret√≥rios a Remover:
1. **`benchmark/`** - Se n√£o for usado ativamente, mover para documenta√ß√£o externa
2. **`deploy/`** - Deployment deve ser via Docker/K8s (n√£o apenas manifests soltos)
3. **`logs/`** - Logs devem ser gerados dinamicamente, n√£o versionados
4. **`__pycache__/`** - Sempre no `.gitignore`

#### Arquivos Obsoletos:
- Scripts duplicados ou de teste
- Notebooks antigos (`*_old.ipynb`, `*_backup.ipynb`)
- Configs n√£o utilizados

---

## üõ†Ô∏è Plano de Execu√ß√£o Detalhado

### **FASE 1: LIMPEZA E ORGANIZA√á√ÉO** (2-3 horas)

#### Passo 1.1: Backup e Prepara√ß√£o
```powershell
# Criar branch de refatora√ß√£o
git checkout -b refactor/mlops-structure

# Backup completo
git commit -am "Checkpoint antes da refatora√ß√£o"
```

#### Passo 1.2: Deletar Diret√≥rios Desnecess√°rios
```powershell
# Remover caches e logs
Remove-Item -Recurse -Force __pycache__, logs/, .pytest_cache/

# Remover duplica√ß√µes em src/
Remove-Item -Recurse -Force src/evaluation_module/, src/interfaces/, src/orchestration/, src/eda/, src/reporting/
```

#### Passo 1.3: Reestruturar `src/`
```powershell
# Criar nova estrutura limpa
New-Item -ItemType Directory -Force src/explainability
New-Item -ItemType Directory -Force src/monitoring

# Mover arquivos para locais corretos
Move-Item src/monitoring_service.py src/monitoring/service.py
```

---

### **FASE 2: REFATORA√á√ÉO DO C√ìDIGO** (8-12 horas)

#### Passo 2.1: Criar `src/config.py`

**Objetivo:** Centralizar carregamento de todas as configura√ß√µes.

```python
# src/config.py
"""
Gerenciamento centralizado de configura√ß√µes.
Carrega e valida arquivos YAML de config/.
"""
from pathlib import Path
from typing import Dict, Any
import yaml

class Config:
    """Singleton para configura√ß√µes do projeto."""
    
    _instance = None
    _config = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._config is None:
            self.load()
    
    def load(self, config_path: str = "config/pipeline_config.yaml"):
        """Carrega configura√ß√£o principal."""
        with open(config_path, 'r') as f:
            self._config = yaml.safe_load(f)
    
    def get(self, key: str, default: Any = None) -> Any:
        """Acessa valor de configura√ß√£o via dot notation."""
        keys = key.split('.')
        value = self._config
        for k in keys:
            value = value.get(k, default)
            if value is None:
                return default
        return value
    
    @property
    def data_path(self) -> Path:
        return Path(self.get('data.path', 'data/'))
    
    @property
    def model_path(self) -> Path:
        return Path(self.get('output.model_path', 'models/'))

# Inst√¢ncia global
config = Config()
```

**Uso em qualquer m√≥dulo:**
```python
from src.config import config

data_dir = config.data_path
model_params = config.get('model.params')
```

---

#### Passo 2.2: Refatorar `src/data/`

**`src/data/loader.py`** - Carregamento de dados
```python
"""
Carregamento de dados brutos e processados.
Responsabilidade: I/O de dados.
"""
import pandas as pd
from pathlib import Path
from src.config import config
from src.utils.logger import get_logger

logger = get_logger(__name__)

def load_raw_data(filename: str = "transactions.csv") -> pd.DataFrame:
    """
    Carrega dados brutos do diret√≥rio raw/.
    
    Args:
        filename: Nome do arquivo CSV
        
    Returns:
        DataFrame com dados brutos
    """
    filepath = config.data_path / "raw" / filename
    logger.info(f"Carregando dados de {filepath}")
    
    df = pd.read_csv(filepath)
    logger.info(f"Carregados {len(df)} registros com {df.shape[1]} colunas")
    
    return df

def load_processed_data(split: str = "train") -> pd.DataFrame:
    """
    Carrega dados processados (train/test).
    
    Args:
        split: 'train' ou 'test'
        
    Returns:
        DataFrame processado
    """
    filepath = config.data_path / "processed" / f"{split}.pkl"
    logger.info(f"Carregando dados processados de {filepath}")
    
    return pd.read_pickle(filepath)

def save_processed_data(df: pd.DataFrame, split: str = "train"):
    """Salva dados processados."""
    filepath = config.data_path / "processed" / f"{split}.pkl"
    filepath.parent.mkdir(parents=True, exist_ok=True)
    
    df.to_pickle(filepath)
    logger.info(f"Dados salvos em {filepath}")
```

**`src/data/preprocessing.py`** - Limpeza e transforma√ß√£o
```python
"""
Pr√©-processamento de dados: limpeza, imputa√ß√£o, split.
Responsabilidade: Transforma√ß√µes de dados brutos.
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from src.config import config
from src.utils.logger import get_logger

logger = get_logger(__name__)

def clean_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Limpeza b√°sica: remover duplicatas, tratar nulos.
    
    Args:
        df: DataFrame bruto
        
    Returns:
        DataFrame limpo
    """
    logger.info("Iniciando limpeza de dados")
    
    # Remover duplicatas
    initial_rows = len(df)
    df = df.drop_duplicates()
    logger.info(f"Removidas {initial_rows - len(df)} duplicatas")
    
    # Tratar valores ausentes (estrat√©gia simples)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
    
    categorical_cols = df.select_dtypes(include=['object']).columns
    df[categorical_cols] = df[categorical_cols].fillna('MISSING')
    
    logger.info("Limpeza conclu√≠da")
    return df

def split_train_test(df: pd.DataFrame, target_col: str = None) -> tuple:
    """
    Divide dados em treino e teste.
    
    Args:
        df: DataFrame completo
        target_col: Nome da coluna alvo (pega do config se None)
        
    Returns:
        (X_train, X_test, y_train, y_test)
    """
    if target_col is None:
        target_col = config.get('model.target_column', 'is_laundering')
    
    test_size = config.get('validation.test_size', 0.2)
    random_state = config.get('model.random_state', 42)
    
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=test_size, 
        random_state=random_state,
        stratify=y
    )
    
    logger.info(f"Split: {len(X_train)} treino, {len(X_test)} teste")
    return X_train, X_test, y_train, y_test
```

---

#### Passo 2.3: Refatorar `src/features/`

**`src/features/engineering.py`** - Cria√ß√£o de features
```python
"""
Feature Engineering: cria√ß√£o de features temporais, de rede, estat√≠sticas.
Responsabilidade: Transformar dados limpos em features para ML.
"""
import pandas as pd
import numpy as np
from src.config import config
from src.utils.logger import get_logger

logger = get_logger(__name__)

def create_temporal_features(df: pd.DataFrame, timestamp_col: str = 'timestamp') -> pd.DataFrame:
    """
    Cria features temporais (hora do dia, dia da semana, etc).
    
    Args:
        df: DataFrame com coluna de timestamp
        timestamp_col: Nome da coluna de timestamp
        
    Returns:
        DataFrame com features temporais adicionadas
    """
    logger.info("Criando features temporais")
    
    df = df.copy()
    df[timestamp_col] = pd.to_datetime(df[timestamp_col])
    
    df['hour'] = df[timestamp_col].dt.hour
    df['day_of_week'] = df[timestamp_col].dt.dayofweek
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
    df['is_night'] = df['hour'].between(22, 6).astype(int)
    
    logger.info("Features temporais criadas")
    return df

def create_aggregation_features(
    df: pd.DataFrame, 
    group_col: str, 
    agg_col: str,
    windows: list = None
) -> pd.DataFrame:
    """
    Cria features de agrega√ß√£o (soma, m√©dia, contagem em janelas).
    
    Args:
        df: DataFrame
        group_col: Coluna para agrupar (ex: 'account_id')
        agg_col: Coluna para agregar (ex: 'amount')
        windows: Lista de janelas temporais (dias)
        
    Returns:
        DataFrame com features agregadas
    """
    if windows is None:
        windows = config.get('features.windows', [7, 30])
    
    logger.info(f"Criando agrega√ß√µes para {group_col} sobre {agg_col}")
    
    df = df.copy()
    
    for window in windows:
        df[f'{agg_col}_sum_{window}d'] = (
            df.groupby(group_col)[agg_col]
            .rolling(window=window, min_periods=1)
            .sum()
            .reset_index(level=0, drop=True)
        )
        
        df[f'{agg_col}_mean_{window}d'] = (
            df.groupby(group_col)[agg_col]
            .rolling(window=window, min_periods=1)
            .mean()
            .reset_index(level=0, drop=True)
        )
    
    logger.info(f"Agrega√ß√µes criadas para janelas {windows}")
    return df

def build_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Pipeline completo de feature engineering.
    
    Args:
        df: DataFrame limpo
        
    Returns:
        DataFrame com todas as features
    """
    logger.info("Iniciando pipeline de feature engineering")
    
    df = create_temporal_features(df)
    df = create_aggregation_features(df, 'account_id', 'amount')
    
    logger.info("Feature engineering conclu√≠do")
    return df
```

---

#### Passo 2.4: Refatorar `src/models/`

**`src/models/train.py`** - Treinamento
```python
"""
Treinamento de modelos ML.
Responsabilidade: Treinar, validar e serializar modelos.
"""
import joblib
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from src.config import config
from src.utils.logger import get_logger

logger = get_logger(__name__)

MODEL_REGISTRY = {
    'random_forest': RandomForestClassifier,
    'xgboost': XGBClassifier,
    'lightgbm': LGBMClassifier
}

def get_model(model_name: str = None):
    """
    Instancia modelo com hiperpar√¢metros do config.
    
    Args:
        model_name: Nome do modelo (default: pega do config)
        
    Returns:
        Inst√¢ncia do modelo configurado
    """
    if model_name is None:
        model_name = config.get('model.name', 'xgboost')
    
    model_class = MODEL_REGISTRY.get(model_name)
    if model_class is None:
        raise ValueError(f"Modelo '{model_name}' n√£o encontrado no registro")
    
    params = config.get('model.params', {})
    logger.info(f"Instanciando {model_name} com par√¢metros: {params}")
    
    return model_class(**params)

def train_model(X_train, y_train, model_name: str = None):
    """
    Treina modelo.
    
    Args:
        X_train: Features de treino
        y_train: Target de treino
        model_name: Nome do modelo
        
    Returns:
        Modelo treinado
    """
    logger.info("Iniciando treinamento")
    
    model = get_model(model_name)
    model.fit(X_train, y_train)
    
    logger.info("Treinamento conclu√≠do")
    return model

def save_model(model, filename: str = None):
    """
    Serializa modelo treinado.
    
    Args:
        model: Modelo treinado
        filename: Nome do arquivo (default: pega do config)
    """
    if filename is None:
        filename = config.get('output.model_path', 'models/model.pkl')
    
    filepath = Path(filename)
    filepath.parent.mkdir(parents=True, exist_ok=True)
    
    joblib.dump(model, filepath)
    logger.info(f"Modelo salvo em {filepath}")

def load_model(filename: str = None):
    """Carrega modelo serializado."""
    if filename is None:
        filename = config.get('output.model_path', 'models/model.pkl')
    
    logger.info(f"Carregando modelo de {filename}")
    return joblib.load(filename)
```

**`src/models/predict.py`** - Predi√ß√£o
```python
"""
Predi√ß√£o em produ√ß√£o.
Responsabilidade: Infer√™ncia em novos dados.
"""
import pandas as pd
from src.models.train import load_model
from src.utils.logger import get_logger

logger = get_logger(__name__)

def predict(X, model=None, return_proba: bool = True):
    """
    Faz predi√ß√µes em novos dados.
    
    Args:
        X: Features
        model: Modelo (carrega se None)
        return_proba: Se True, retorna probabilidades
        
    Returns:
        Array de predi√ß√µes ou probabilidades
    """
    if model is None:
        model = load_model()
    
    logger.info(f"Fazendo predi√ß√µes para {len(X)} amostras")
    
    if return_proba and hasattr(model, 'predict_proba'):
        predictions = model.predict_proba(X)[:, 1]
    else:
        predictions = model.predict(X)
    
    return predictions

def predict_batch(df: pd.DataFrame, model=None) -> pd.DataFrame:
    """
    Predi√ß√£o em batch com retorno estruturado.
    
    Args:
        df: DataFrame com features
        model: Modelo treinado
        
    Returns:
        DataFrame com predi√ß√µes e probabilidades
    """
    if model is None:
        model = load_model()
    
    predictions = predict(df, model, return_proba=False)
    probabilities = predict(df, model, return_proba=True)
    
    result = df.copy()
    result['prediction'] = predictions
    result['probability'] = probabilities
    
    return result
```

**`src/models/evaluate.py`** - Avalia√ß√£o
```python
"""
Avalia√ß√£o de modelos: m√©tricas, curvas, relat√≥rios.
Responsabilidade: Computar e reportar performance.
"""
import json
from pathlib import Path
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score, confusion_matrix,
    classification_report
)
from src.utils.logger import get_logger

logger = get_logger(__name__)

def evaluate_model(y_true, y_pred, y_proba=None) -> dict:
    """
    Calcula m√©tricas de classifica√ß√£o.
    
    Args:
        y_true: Labels verdadeiros
        y_pred: Predi√ß√µes
        y_proba: Probabilidades (opcional)
        
    Returns:
        Dicion√°rio com m√©tricas
    """
    logger.info("Calculando m√©tricas de avalia√ß√£o")
    
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred, zero_division=0),
        'recall': recall_score(y_true, y_pred, zero_division=0),
        'f1': f1_score(y_true, y_pred, zero_division=0)
    }
    
    if y_proba is not None:
        metrics['roc_auc'] = roc_auc_score(y_true, y_proba)
        metrics['pr_auc'] = average_precision_score(y_true, y_proba)
    
    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    metrics['confusion_matrix'] = {
        'tn': int(cm[0, 0]),
        'fp': int(cm[0, 1]),
        'fn': int(cm[1, 0]),
        'tp': int(cm[1, 1])
    }
    
    logger.info(f"M√©tricas calculadas: {metrics}")
    return metrics

def save_evaluation_report(metrics: dict, filepath: str = "artifacts/evaluation.json"):
    """Salva relat√≥rio de avalia√ß√£o."""
    Path(filepath).parent.mkdir(parents=True, exist_ok=True)
    
    with open(filepath, 'w') as f:
        json.dump(metrics, f, indent=2)
    
    logger.info(f"Relat√≥rio salvo em {filepath}")

def print_evaluation_summary(metrics: dict):
    """Imprime resumo das m√©tricas."""
    print("\n" + "="*50)
    print("RESUMO DA AVALIA√á√ÉO")
    print("="*50)
    print(f"Acur√°cia:  {metrics['accuracy']:.4f}")
    print(f"Precis√£o:  {metrics['precision']:.4f}")
    print(f"Recall:    {metrics['recall']:.4f}")
    print(f"F1-Score:  {metrics['f1']:.4f}")
    
    if 'roc_auc' in metrics:
        print(f"ROC-AUC:   {metrics['roc_auc']:.4f}")
        print(f"PR-AUC:    {metrics['pr_auc']:.4f}")
    
    print("="*50 + "\n")
```

---

#### Passo 2.5: Criar `src/utils/logger.py`

```python
"""
Logging centralizado para todo o projeto.
Responsabilidade: Configurar e fornecer loggers consistentes.
"""
import logging
import sys
from pathlib import Path

def get_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """
    Cria logger configurado.
    
    Args:
        name: Nome do m√≥dulo (__name__)
        level: N√≠vel de log
        
    Returns:
        Logger configurado
    """
    logger = logging.getLogger(name)
    
    if not logger.handlers:
        logger.setLevel(level)
        
        # Handler para console
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(level)
        
        # Formato
        formatter = logging.Formatter(
            '%(asctime)s | %(name)s | %(levelname)s | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
    
    return logger
```

---

### **FASE 3: ENTRYPOINTS - CLI** (3-4 horas)

#### Passo 3.1: Criar `entrypoints/cli.py` - Interface de Linha de Comando

Vamos usar **Typer** (ou Click) para criar uma CLI profissional e moderna.

```python
#!/usr/bin/env python3
"""
Interface de Linha de Comando (CLI) para o sistema AML.
Ponto de entrada principal para opera√ß√µes via terminal.

Comandos dispon√≠veis:
- train: Treinar modelo
- predict: Fazer predi√ß√µes
- evaluate: Avaliar modelo
- serve: Iniciar servidor API
"""
import typer
from typing import Optional
from pathlib import Path
import pandas as pd

from src.data.loader import load_raw_data, save_processed_data, load_processed_data
from src.data.preprocessing import clean_data, split_train_test
from src.features.engineering import build_features
from src.models.train import train_model, save_model, load_model
from src.models.evaluate import evaluate_model, save_evaluation_report, print_evaluation_summary
from src.models.predict import predict_batch
from src.utils.logger import get_logger

# Criar aplica√ß√£o CLI
app = typer.Typer(
    name="aml-cli",
    help="Sistema de Detec√ß√£o de Lavagem de Dinheiro - Interface de Linha de Comando"
)

logger = get_logger(__name__)

@app.command()
def train(
    data_file: Optional[str] = typer.Option(None, "--data", "-d", help="Arquivo CSV de dados brutos"),
    config_file: Optional[str] = typer.Option("config/pipeline_config.yaml", "--config", "-c", help="Arquivo de configura√ß√£o"),
    model_name: Optional[str] = typer.Option(None, "--model", "-m", help="Nome do modelo (xgboost, lightgbm, random_forest)"),
):
    """
    Treina um modelo de detec√ß√£o de lavagem de dinheiro.
    
    Exemplo:
        python -m entrypoints.cli train --data data/raw/transactions.csv --model xgboost
    """
    typer.secho("\nüöÄ INICIANDO TREINAMENTO DO MODELO\n", fg=typer.colors.GREEN, bold=True)
    
    try:
        # 1. Carregar dados
        typer.echo("üìÇ [1/7] Carregando dados brutos...")
        df = load_raw_data(data_file) if data_file else load_raw_data()
        typer.secho(f"   ‚úì Carregados {len(df)} registros", fg=typer.colors.GREEN)
        
        # 2. Limpeza
        typer.echo("\nüßπ [2/7] Limpando dados...")
        df_clean = clean_data(df)
        typer.secho(f"   ‚úì Dados limpos: {len(df_clean)} registros", fg=typer.colors.GREEN)
        
        # 3. Feature Engineering
        typer.echo("\nüîß [3/7] Criando features...")
        df_features = build_features(df_clean)
        typer.secho(f"   ‚úì Features criadas: {df_features.shape[1]} colunas", fg=typer.colors.GREEN)
        
        # 4. Split
        typer.echo("\n‚úÇÔ∏è  [4/7] Dividindo em treino/teste...")
        X_train, X_test, y_train, y_test = split_train_test(df_features)
        typer.secho(f"   ‚úì Treino: {len(X_train)} | Teste: {len(X_test)}", fg=typer.colors.GREEN)
        
        # Salvar dados processados
        train_data = pd.concat([X_train, y_train], axis=1)
        test_data = pd.concat([X_test, y_test], axis=1)
        save_processed_data(train_data, 'train')
        save_processed_data(test_data, 'test')
        
        # 5. Treinar
        typer.echo("\nüéØ [5/7] Treinando modelo...")
        model = train_model(X_train, y_train, model_name)
        typer.secho(f"   ‚úì Modelo treinado com sucesso", fg=typer.colors.GREEN)
        
        # 6. Avaliar
        typer.echo("\nüìä [6/7] Avaliando modelo...")
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
        
        metrics = evaluate_model(y_test, y_pred, y_proba)
        print_evaluation_summary(metrics)
        
        # 7. Salvar
        typer.echo("\nüíæ [7/7] Salvando artefatos...")
        save_model(model)
        save_evaluation_report(metrics)
        typer.secho(f"   ‚úì Modelo salvo", fg=typer.colors.GREEN)
        
        typer.secho("\n‚úÖ TREINAMENTO CONCLU√çDO COM SUCESSO!\n", fg=typer.colors.GREEN, bold=True)
        
    except Exception as e:
        typer.secho(f"\n‚ùå ERRO: {str(e)}\n", fg=typer.colors.RED, bold=True)
        raise typer.Exit(code=1)

@app.command()
def predict(
    input_file: str = typer.Argument(..., help="Arquivo CSV com dados para predi√ß√£o"),
    output_file: str = typer.Option("predictions.csv", "--output", "-o", help="Arquivo de sa√≠da com predi√ß√µes"),
    model_path: Optional[str] = typer.Option(None, "--model", "-m", help="Caminho do modelo treinado"),
):
    """
    Faz predi√ß√µes em novos dados.
    
    Exemplo:
        python -m entrypoints.cli predict data/new_transactions.csv -o results.csv
    """
    typer.secho("\nüîÆ FAZENDO PREDI√á√ïES\n", fg=typer.colors.BLUE, bold=True)
    
    try:
        # Carregar dados
        typer.echo(f"üìÇ Carregando dados de {input_file}...")
        df = pd.read_csv(input_file)
        typer.secho(f"   ‚úì {len(df)} registros carregados", fg=typer.colors.GREEN)
        
        # Carregar modelo
        typer.echo("\nü§ñ Carregando modelo...")
        model = load_model(model_path) if model_path else load_model()
        typer.secho(f"   ‚úì Modelo carregado", fg=typer.colors.GREEN)
        
        # Feature engineering (voc√™ deve aplicar as mesmas transforma√ß√µes do treino)
        typer.echo("\nüîß Processando features...")
        df_features = build_features(df)
        
        # Predi√ß√£o
        typer.echo("\nüéØ Fazendo predi√ß√µes...")
        results = predict_batch(df_features, model)
        
        # Salvar
        results.to_csv(output_file, index=False)
        typer.secho(f"\n‚úÖ Predi√ß√µes salvas em {output_file}", fg=typer.colors.GREEN, bold=True)
        
        # Estat√≠sticas
        suspicious_count = results['prediction'].sum()
        typer.echo(f"\nüìà Estat√≠sticas:")
        typer.echo(f"   ‚Ä¢ Total de transa√ß√µes: {len(results)}")
        typer.echo(f"   ‚Ä¢ Transa√ß√µes suspeitas: {suspicious_count} ({suspicious_count/len(results)*100:.2f}%)")
        typer.echo(f"   ‚Ä¢ Risco m√©dio: {results['probability'].mean():.4f}")
        
    except Exception as e:
        typer.secho(f"\n‚ùå ERRO: {str(e)}\n", fg=typer.colors.RED, bold=True)
        raise typer.Exit(code=1)

@app.command()
def evaluate(
    test_data: Optional[str] = typer.Option(None, "--test-data", "-t", help="Arquivo de teste (default: usa data/processed/test.pkl)"),
    model_path: Optional[str] = typer.Option(None, "--model", "-m", help="Caminho do modelo"),
):
    """
    Avalia um modelo treinado.
    
    Exemplo:
        python -m entrypoints.cli evaluate --model models/xgboost_model.pkl
    """
    typer.secho("\nüìä AVALIANDO MODELO\n", fg=typer.colors.YELLOW, bold=True)
    
    try:
        # Carregar dados de teste
        if test_data:
            df_test = pd.read_csv(test_data)
        else:
            df_test = load_processed_data('test')
        
        # Separar X e y
        from src.config import config
        target_col = config.get('model.target_column', 'is_laundering')
        X_test = df_test.drop(columns=[target_col])
        y_test = df_test[target_col]
        
        # Carregar modelo
        model = load_model(model_path) if model_path else load_model()
        
        # Predi√ß√£o
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
        
        # Avaliar
        metrics = evaluate_model(y_test, y_pred, y_proba)
        print_evaluation_summary(metrics)
        
        # Salvar relat√≥rio
        save_evaluation_report(metrics, "artifacts/evaluation_report.json")
        typer.secho("\n‚úÖ Relat√≥rio salvo em artifacts/evaluation_report.json", fg=typer.colors.GREEN)
        
    except Exception as e:
        typer.secho(f"\n‚ùå ERRO: {str(e)}\n", fg=typer.colors.RED, bold=True)
        raise typer.Exit(code=1)

@app.command()
def serve(
    host: str = typer.Option("0.0.0.0", "--host", help="Host do servidor"),
    port: int = typer.Option(8000, "--port", "-p", help="Porta do servidor"),
    reload: bool = typer.Option(False, "--reload", help="Auto-reload em desenvolvimento"),
):
    """
    Inicia o servidor API.
    
    Exemplo:
        python -m entrypoints.cli serve --port 8000 --reload
    """
    typer.secho(f"\nüöÄ INICIANDO SERVIDOR API em {host}:{port}\n", fg=typer.colors.MAGENTA, bold=True)
    
    import uvicorn
    uvicorn.run(
        "entrypoints.api:app",
        host=host,
        port=port,
        reload=reload
    )

if __name__ == "__main__":
    app()
```

**Adicionar ao `requirements.txt`:**
```
typer[all]>=0.9.0  # CLI framework moderno
```

**Uso:**
```powershell
# Treinar modelo
python -m entrypoints.cli train --data data/raw/transactions.csv --model xgboost

# Fazer predi√ß√µes
python -m entrypoints.cli predict data/new_data.csv -o predictions.csv

# Avaliar modelo
python -m entrypoints.cli evaluate --model models/my_model.pkl

# Iniciar API
python -m entrypoints.cli serve --port 8000 --reload

# Ver ajuda
python -m entrypoints.cli --help
python -m entrypoints.cli train --help
```

---

### **FASE 4: ENTRYPOINTS - API DE PRODU√á√ÉO** (4-6 horas)

#### Passo 4.1: Criar `entrypoints/api.py` - API FastAPI

**`entrypoints/api.py`**
```python
"""
API de Produ√ß√£o para Sistema AML.
Framework: FastAPI
Features: Auto-documenta√ß√£o, valida√ß√£o, async, type hints
"""
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional
import pandas as pd

from src.models.predict import predict, load_model
from src.monitoring.service import AMLMonitor
from src.utils.logger import get_logger

logger = get_logger(__name__)

# Inicializar app
app = FastAPI(
    title="AML Detection API",
    description="API para detec√ß√£o de lavagem de dinheiro em tempo real",
    version="1.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Carregar modelo na inicializa√ß√£o
model = None
monitor = AMLMonitor()

@app.on_event("startup")
async def startup_event():
    """Carrega modelo ao iniciar."""
    global model
    logger.info("Carregando modelo...")
    model = load_model()
    logger.info("Modelo carregado com sucesso")

# Schemas Pydantic
class Transaction(BaseModel):
    """Schema de uma transa√ß√£o."""
    account_id: str
    amount: float = Field(..., gt=0, description="Valor da transa√ß√£o (deve ser positivo)")
    timestamp: str
    # Adicione outros campos conforme necess√°rio
    
    class Config:
        schema_extra = {
            "example": {
                "account_id": "ACC123456",
                "amount": 15000.50,
                "timestamp": "2025-11-06T14:30:00"
            }
        }

class PredictionResponse(BaseModel):
    """Schema da resposta de predi√ß√£o."""
    transaction_id: Optional[str] = None
    is_suspicious: bool
    risk_score: float = Field(..., ge=0, le=1, description="Probabilidade de lavagem (0-1)")
    risk_level: str = Field(..., description="LOW, MEDIUM, HIGH, CRITICAL")

# Endpoints
@app.get("/")
async def root():
    """Health check simples."""
    return {"status": "online", "service": "AML Detection API"}

@app.get("/health")
async def health_check():
    """
    Endpoint de health check completo.
    Verifica status do modelo e sistema.
    """
    health_report = monitor.get_health_report()
    
    if health_report['status'] == 'critical':
        raise HTTPException(status_code=503, detail="Sistema cr√≠tico")
    
    return health_report

@app.post("/predict", response_model=PredictionResponse)
async def predict_transaction(transaction: Transaction):
    """
    Faz predi√ß√£o para uma transa√ß√£o.
    
    Args:
        transaction: Dados da transa√ß√£o
        
    Returns:
        Resposta com flag de suspeita e score de risco
    """
    try:
        # Converter para DataFrame
        df = pd.DataFrame([transaction.dict()])
        
        # Feature engineering (simplificado - voc√™ deve usar src.features aqui)
        # df = build_features(df)
        
        # Predi√ß√£o
        risk_score = float(predict(df, model, return_proba=True)[0])
        
        # Classificar n√≠vel de risco
        if risk_score < 0.3:
            risk_level = "LOW"
        elif risk_score < 0.6:
            risk_level = "MEDIUM"
        elif risk_score < 0.85:
            risk_level = "HIGH"
        else:
            risk_level = "CRITICAL"
        
        # Monitorar
        monitor.log_prediction(risk_score)
        
        return PredictionResponse(
            transaction_id=transaction.account_id,
            is_suspicious=risk_score > 0.5,
            risk_score=risk_score,
            risk_level=risk_level
        )
    
    except Exception as e:
        logger.error(f"Erro na predi√ß√£o: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/predict/batch")
async def predict_batch(transactions: List[Transaction]):
    """
    Predi√ß√£o em batch para m√∫ltiplas transa√ß√µes.
    
    Args:
        transactions: Lista de transa√ß√µes
        
    Returns:
        Lista de predi√ß√µes
    """
    results = []
    
    for txn in transactions:
        result = await predict_transaction(txn)
        results.append(result)
    
    return results

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### Passo 4.2: Criar `entrypoints/batch.py` - Processamento em Lote

```python
"""
Processamento em lote (batch) para grandes volumes.
Ideal para jobs agendados (Airflow, Cron, GitHub Actions).

Exemplo de uso:
    python -m entrypoints.batch --date 2025-11-06 --input data/transactions_20251106.csv
"""
import argparse
from datetime import datetime
from pathlib import Path
import pandas as pd

from src.data.preprocessing import clean_data
from src.features.engineering import build_features
from src.models.predict import predict_batch, load_model
from src.utils.logger import get_logger

logger = get_logger(__name__)

def process_batch(input_file: str, output_dir: str = "data/predictions", date: str = None):
    """
    Processa um lote de transa√ß√µes e salva predi√ß√µes.
    
    Args:
        input_file: Arquivo CSV com transa√ß√µes
        output_dir: Diret√≥rio de sa√≠da
        date: Data do lote (formato YYYY-MM-DD)
    """
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    
    logger.info(f"Processando batch para data: {date}")
    
    # Carregar dados
    logger.info(f"Carregando {input_file}...")
    df = pd.read_csv(input_file)
    logger.info(f"Carregados {len(df)} registros")
    
    # Preprocessar
    df_clean = clean_data(df)
    df_features = build_features(df_clean)
    
    # Carregar modelo
    model = load_model()
    
    # Predi√ß√£o
    logger.info("Fazendo predi√ß√µes em batch...")
    results = predict_batch(df_features, model)
    
    # Salvar resultados
    output_path = Path(output_dir) / f"predictions_{date}.csv"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    results.to_csv(output_path, index=False)
    
    logger.info(f"Predi√ß√µes salvas em {output_path}")
    
    # Estat√≠sticas
    suspicious = results[results['prediction'] == 1]
    logger.info(f"Total: {len(results)} | Suspeitos: {len(suspicious)} ({len(suspicious)/len(results)*100:.2f}%)")
    
    return output_path

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Processamento em batch AML")
    parser.add_argument("--input", "-i", required=True, help="Arquivo de entrada")
    parser.add_argument("--output", "-o", default="data/predictions", help="Diret√≥rio de sa√≠da")
    parser.add_argument("--date", "-d", help="Data do batch (YYYY-MM-DD)")
    
    args = parser.parse_args()
    process_batch(args.input, args.output, args.date)
```

**Uso:**
```powershell
# Processar batch de hoje
python -m entrypoints.batch --input data/daily/transactions_today.csv

# Processar batch espec√≠fico
python -m entrypoints.batch --input data/historical/2025-11-06.csv --date 2025-11-06 --output results/
```

**Integra√ß√£o com Airflow (exemplo):**
```python
# dags/aml_batch_dag.py
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

dag = DAG(
    'aml_batch_processing',
    start_date=datetime(2025, 11, 1),
    schedule_interval='@daily'
)

process_batch = BashOperator(
    task_id='process_batch',
    bash_command='python -m entrypoints.batch --input data/daily/{{ ds }}.csv --date {{ ds }}',
    dag=dag
)
```

---

**Executar API:**
```powershell
# Via CLI helper
python -m entrypoints.cli serve --reload

# Diretamente
uvicorn entrypoints.api:app --reload

# Produ√ß√£o
uvicorn entrypoints.api:app --host 0.0.0.0 --port 8000 --workers 4
```

**Acessar documenta√ß√£o autom√°tica:**
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

---

### **FASE 5: TESTES E QUALIDADE** (4-6 horas)

#### Passo 5.1: Estrutura de Testes

```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ conftest.py              # Fixtures compartilhados
‚îú‚îÄ‚îÄ test_data_loader.py
‚îú‚îÄ‚îÄ test_preprocessing.py
‚îú‚îÄ‚îÄ test_features.py
‚îú‚îÄ‚îÄ test_models.py
‚îî‚îÄ‚îÄ test_api.py
```

#### Passo 5.2: Exemplo de Testes

**`tests/conftest.py`** - Fixtures
```python
"""
Fixtures compartilhados para testes.
"""
import pytest
import pandas as pd
import numpy as np

@pytest.fixture
def sample_dataframe():
    """DataFrame de exemplo para testes."""
    return pd.DataFrame({
        'account_id': ['A001', 'A002', 'A003'],
        'amount': [100.0, 250.0, 50.0],
        'timestamp': pd.date_range('2025-01-01', periods=3),
        'is_laundering': [0, 1, 0]
    })

@pytest.fixture
def sample_features():
    """Features de exemplo."""
    return pd.DataFrame({
        'feature_1': [1.0, 2.0, 3.0],
        'feature_2': [10.0, 20.0, 30.0]
    })

@pytest.fixture
def sample_labels():
    """Labels de exemplo."""
    return pd.Series([0, 1, 0])
```

**`tests/test_data_loader.py`**
```python
"""
Testes para m√≥dulo de carregamento de dados.
"""
import pytest
from src.data.loader import load_raw_data, load_processed_data

def test_load_raw_data_returns_dataframe():
    """Testa se load_raw_data retorna um DataFrame."""
    # Mock ou use arquivo de teste
    # df = load_raw_data('test_data.csv')
    # assert isinstance(df, pd.DataFrame)
    pass  # Implementar com dados de teste

def test_load_raw_data_not_empty():
    """Testa se dados carregados n√£o est√£o vazios."""
    pass  # Implementar
```

**`tests/test_preprocessing.py`**
```python
"""
Testes para pr√©-processamento.
"""
import pytest
import pandas as pd
from src.data.preprocessing import clean_data, split_train_test

def test_clean_data_removes_duplicates(sample_dataframe):
    """Testa se clean_data remove duplicatas."""
    df_with_dup = pd.concat([sample_dataframe, sample_dataframe.iloc[[0]]])
    df_clean = clean_data(df_with_dup)
    
    assert len(df_clean) == len(sample_dataframe)

def test_split_train_test_returns_four_elements(sample_dataframe):
    """Testa se split retorna 4 elementos."""
    result = split_train_test(sample_dataframe, 'is_laundering')
    
    assert len(result) == 4

def test_split_preserves_total_samples(sample_dataframe):
    """Testa se split preserva n√∫mero total de amostras."""
    X_train, X_test, y_train, y_test = split_train_test(sample_dataframe, 'is_laundering')
    
    total = len(X_train) + len(X_test)
    assert total == len(sample_dataframe)
```

**Executar testes:**
```powershell
# Todos os testes
pytest

# Com coverage
pytest --cov=src --cov-report=html

# Testes espec√≠ficos
pytest tests/test_preprocessing.py -v
```

---

### **FASE 6: CONTAINERIZA√á√ÉO E DEPLOY** (3-4 horas)

#### Passo 6.1: Criar `Dockerfile`

```dockerfile
# Dockerfile
FROM python:3.10-slim

# Vari√°veis de ambiente
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1

# Diret√≥rio de trabalho
WORKDIR /app

# Instalar depend√™ncias do sistema
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copiar requirements
COPY requirements.txt .

# Instalar depend√™ncias Python
RUN pip install --upgrade pip && \
    pip install -r requirements.txt

# Copiar c√≥digo
COPY . .

# Expor porta
EXPOSE 8000

# Comando para iniciar API
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Passo 6.2: Criar `docker-compose.yml`

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    container_name: aml-api
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - ./config:/app/config
    environment:
      - ENV=production
    restart: unless-stopped
  
  dashboard:
    build:
      context: .
      dockerfile: Dockerfile.dashboard
    container_name: aml-dashboard
    ports:
      - "8501:8501"
    depends_on:
      - api
    restart: unless-stopped
```

**Executar:**
```powershell
# Build e start
docker-compose up --build

# Background
docker-compose up -d

# Parar
docker-compose down
```

---

### **FASE 7: DOCUMENTA√á√ÉO E FINALIZA√á√ÉO** (2-3 horas)

#### Passo 7.1: Atualizar `README.md`

```markdown
# AML Project - Sistema de Detec√ß√£o de Lavagem de Dinheiro

Sistema completo de Machine Learning para detec√ß√£o de lavagem de dinheiro, com API de produ√ß√£o, monitoramento e dashboard interativo.

## üöÄ Quick Start

### 1. Instala√ß√£o

```bash
# Clonar reposit√≥rio
git clone https://github.com/gaab-braga/AML_project.git
cd AML_project

# Criar ambiente virtual
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# Instalar depend√™ncias
pip install -r requirements.txt
```

### 2. Preparar Dados

Coloque seus dados brutos em `data/raw/transactions.csv`.

### 3. Treinar Modelo

```bash
python scripts/train_pipeline.py
```

### 4. Iniciar API

```bash
uvicorn api.main:app --reload
```

Acesse: `http://localhost:8000/docs`

### 5. Dashboard

```bash
streamlit run dashboard/app.py
```

Acesse: `http://localhost:8501`

## üìÅ Estrutura do Projeto

```
AML_project/
‚îú‚îÄ‚îÄ entrypoints/      # üéØ Pontos de entrada do sistema
‚îÇ   ‚îú‚îÄ‚îÄ cli.py        # Interface de linha de comando (train, predict, evaluate)
‚îÇ   ‚îú‚îÄ‚îÄ api.py        # API REST (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ batch.py      # Processamento em lote
‚îÇ   ‚îî‚îÄ‚îÄ stream.py     # Processamento em tempo real (opcional)
‚îÇ
‚îú‚îÄ‚îÄ src/              # üîß L√≥gica de neg√≥cio (core)
‚îÇ   ‚îú‚îÄ‚îÄ data/         # Carregamento e pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ features/     # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ models/       # Treinamento, predi√ß√£o, avalia√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ explainability/ # SHAP e interpretabilidade
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/   # Monitoramento de produ√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ utils/        # Utilit√°rios (logger, config, etc)
‚îÇ
‚îú‚îÄ‚îÄ config/           # ‚öôÔ∏è Configura√ß√µes (YAML)
‚îú‚îÄ‚îÄ data/             # üìä Dados (n√£o versionados)
‚îú‚îÄ‚îÄ models/           # ü§ñ Modelos treinados (n√£o versionados)
‚îú‚îÄ‚îÄ artifacts/        # üìà M√©tricas e relat√≥rios
‚îú‚îÄ‚îÄ notebooks/        # üìì Explora√ß√£o e documenta√ß√£o
‚îú‚îÄ‚îÄ scripts/          # üõ†Ô∏è Scripts auxiliares (setup, export)
‚îú‚îÄ‚îÄ tests/            # ‚úÖ Testes unit√°rios
‚îî‚îÄ‚îÄ dashboard/        # üì± Dashboard Streamlit (opcional)
```

## üõ†Ô∏è Desenvolvimento

### Executar Testes

```bash
pytest
pytest --cov=src --cov-report=html
```

### Linting e Formata√ß√£o

```bash
# Formatar c√≥digo
black src/ tests/

# Lint
flake8 src/
```

### Docker

```bash
# Build
docker-compose build

# Run
docker-compose up -d

# Logs
docker-compose logs -f
```

## üìä Notebooks

1. `01_Data_Ingestion_EDA.ipynb` - An√°lise explorat√≥ria
2. `02_IBM_Benchmark.ipynb` - Benchmark com IBM MultiGNN
3. `03_Model_Selection_Tuning.ipynb` - Sele√ß√£o e tuning
4. `04_Ensemble_Modeling.ipynb` - Ensemble e calibra√ß√£o
5. `05_Model_Interpretation.ipynb` - SHAP e explicabilidade
6. `06_Robustness_Validation.ipynb` - Valida√ß√£o de robustez
7. `07_Executive_Summary.ipynb` - Resumo executivo

## üîß Configura√ß√£o

Edite `config/pipeline_config.yaml` para personalizar:
- Caminhos de dados
- Hiperpar√¢metros do modelo
- Thresholds de decis√£o
- Configura√ß√µes de valida√ß√£o

## üìà Performance

- **ROC-AUC:** 0.99
- **PR-AUC:** 0.39
- **Recall @ Top 1%:** 0.85
- **Lat√™ncia API:** <50ms (p95)

## ü§ù Contribuindo

1. Fork o projeto
2. Crie branch: `git checkout -b feature/nova-feature`
3. Commit: `git commit -am 'Add nova feature'`
4. Push: `git push origin feature/nova-feature`
5. Pull Request

## üìù Licen√ßa

MIT License

## üë§ Autor

Gabriel Braga - [@gaab-braga](https://github.com/gaab-braga)
```

---

## üìã Checklist Final de Refatora√ß√£o

### Estrutura de Diret√≥rios
- [ ] `data/` organizado (raw/, processed/)
- [ ] `models/` limpo (apenas artefatos finais)
- [ ] `src/` modular e enxuto (6 subm√≥dulos principais)
- [ ] `entrypoints/` criado (cli.py, api.py, batch.py)
- [ ] `scripts/` minimalista (apenas auxiliares)
- [ ] `tests/` com cobertura b√°sica
- [ ] `config/` consolidado

### C√≥digo
- [ ] Todo c√≥digo de processamento em `src/data/`
- [ ] Feature engineering em `src/features/`
- [ ] Treino/predi√ß√£o/avalia√ß√£o em `src/models/`
- [ ] Logging centralizado em `src/utils/logger.py`
- [ ] Configura√ß√µes carregadas via `src/config.py`
- [ ] Zero duplica√ß√£o entre notebooks e `src/`

### Notebooks
- [ ] Notebooks importam de `src/` (n√£o reimplementam)
- [ ] Focados em an√°lise e visualiza√ß√£o
- [ ] Documenta√ß√£o clara com markdown

### Scripts
- [ ] `train_pipeline.py` funcional
- [ ] Scripts com argumentos de linha de comando
- [ ] Nomes descritivos e objetivos

### API
- [ ] Migrado para FastAPI
- [ ] Schemas Pydantic para valida√ß√£o
- [ ] Health checks funcionais
- [ ] Documenta√ß√£o autom√°tica (/docs)

### Qualidade
- [ ] Testes b√°sicos implementados
- [ ] `.gitignore` completo
- [ ] `requirements.txt` atualizado
- [ ] README.md atualizado

### Deploy
- [ ] `Dockerfile` funcional
- [ ] `docker-compose.yml` configurado
- [ ] Vari√°veis de ambiente documentadas

---

## üéØ M√©tricas de Sucesso

Ap√≥s a refatora√ß√£o, voc√™ deve conseguir:

1. **Executar pipeline completo com 1 comando:**
   ```powershell
   python -m entrypoints.cli train
   ```

2. **Fazer predi√ß√µes com 1 comando:**
   ```powershell
   python -m entrypoints.cli predict data.csv -o predictions.csv
   ```

3. **Iniciar API em produ√ß√£o com 1 comando:**
   ```powershell
   python -m entrypoints.cli serve --port 8000
   # ou
   docker-compose up -d
   ```

4. **Processar batch agendado:**
   ```powershell
   python -m entrypoints.batch --input daily_data.csv --date 2025-11-06
   ```

5. **Modificar hiperpar√¢metros sem tocar no c√≥digo:**
   - Editar `config/pipeline_config.yaml`
   - Re-executar: `python -m entrypoints.cli train`

6. **Adicionar nova feature em 1 arquivo:**
   - Editar `src/features/engineering.py`
   - Fun√ß√£o √© automaticamente usada por TODOS os entrypoints

7. **Reproduzir resultados em qualquer m√°quina:**
   - Clone repo
   - `pip install -r requirements.txt`
   - `python -m entrypoints.cli train`

---

## üö® Anti-Patterns a Evitar

### ‚ùå N√ÉO FA√áA:
1. **C√≥digo duplicado** entre notebooks e `src/`
2. **Hardcoding** de caminhos, par√¢metros, thresholds
3. **Notebooks gigantes** (>500 linhas de c√≥digo)
4. **Fun√ß√µes com >50 linhas** sem refatora√ß√£o
5. **Classes com m√∫ltiplas responsabilidades**
6. **Import relativos** confusos (`from ../../utils`)
7. **Logs com `print()`** ao inv√©s de logging apropriado
8. **Secrets no c√≥digo** (API keys, passwords)

### ‚úÖ FA√áA:
1. **Fun√ß√£o √∫nica por responsabilidade**
2. **Configura√ß√µes em YAML**
3. **Notebooks importam de `src/`**
4. **Type hints** em fun√ß√µes
5. **Docstrings** em fun√ß√µes p√∫blicas
6. **Logging estruturado**
7. **Testes para l√≥gica cr√≠tica**
8. **Versionamento sem√¢ntico** de modelos

---

## üìÖ Timeline Estimado

| Fase | Descri√ß√£o | Tempo | Prioridade |
|------|-----------|-------|------------|
| 1 | Limpeza e organiza√ß√£o | 2-3h | üî¥ ALTA |
| 2 | Refatora√ß√£o de `src/` | 8-12h | üî¥ ALTA |
| 3 | Entrypoints - CLI | 3-4h | üî¥ ALTA |
| 4 | Entrypoints - API & Batch | 4-6h | üü° M√âDIA |
| 5 | Testes | 4-6h | üü° M√âDIA |
| 6 | Docker/Deploy | 3-4h | üü¢ BAIXA |
| 7 | Documenta√ß√£o | 2-3h | üü° M√âDIA |
| **TOTAL** | | **26-38h** | |

**Recomenda√ß√£o:** Execute as fases em ordem. Priorize Fases 1-3 antes de avan√ßar.

---

## üéì Recursos Adicionais

### Leitura Recomendada
- [Clean Code (Robert C. Martin)](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882)
- [Python Best Practices](https://realpython.com/tutorials/best-practices/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [MLOps Principles (Google)](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

### Ferramentas √öteis
- **Formata√ß√£o:** `black`, `isort`
- **Linting:** `flake8`, `pylint`
- **Type Checking:** `mypy`
- **Testing:** `pytest`, `pytest-cov`
- **API Testing:** `httpx`, `pytest-asyncio`

---

## üí° Dicas Finais

1. **Comece pequeno:** Refatore um m√≥dulo por vez, teste, commit.
2. **Teste frequentemente:** N√£o acumule mudan√ßas. Teste a cada refatora√ß√£o.
3. **Git √© seu amigo:** Commits pequenos e frequentes. Use branches.
4. **Documenta√ß√£o √© c√≥digo:** README e docstrings s√£o t√£o importantes quanto o c√≥digo.
5. **Performance vem depois:** Primeiro fa√ßa funcionar, depois otimize.
6. **Pe√ßa feedback:** Code review √© essencial para qualidade.

---

## üèÅ Conclus√£o

Este roadmap transforma seu projeto de notebooks acad√™micos em um sistema profissional de ML. O resultado final ser√°:

- ‚úÖ **Limpo:** Estrutura intuitiva, c√≥digo leg√≠vel
- ‚úÖ **Modular:** Componentes reutiliz√°veis e desacoplados
- ‚úÖ **Test√°vel:** Cobertura de testes, CI/CD ready
- ‚úÖ **Deploy√°vel:** API em produ√ß√£o, containerizado
- ‚úÖ **Manuten√≠vel:** F√°cil de estender e debugar

**Lembre-se:** "Perfei√ß√£o √© atingida n√£o quando n√£o h√° mais nada a adicionar, mas quando n√£o h√° mais nada a remover." - Antoine de Saint-Exup√©ry

Boa refatora√ß√£o! üöÄ

---

**Vers√£o:** 1.0.0  
**Data:** Novembro 2025  
**Autor:** GitHub Copilot + Gabriel Braga  
**Status:** READY FOR IMPLEMENTATION
