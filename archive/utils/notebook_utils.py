"""
Script para padronizar notebooks em lote - redu√ß√£o massiva de redund√¢ncia

Este m√≥dulo fornece fun√ß√µes de setup ultra-limpo para notebooks,
eliminando redund√¢ncia e padronizando configura√ß√µes.
"""

import sys
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

__all__ = [
    # Template utilities
    'ULTRA_CLEAN_SETUP_TEMPLATE',
    'NOTEBOOK_CONFIGS',
    'STAGE_TEMPLATES',
    'generate_setup_code',
    # Nano setup
    'nano_setup',
    'get_sklearn',
    'get_feature_eng',
    # Standard setup
    'setup_notebook_environment',
    'load_standard_datasets',
    'load_core_features',
    'quick_model_evaluation',
    # Clean setup (main functions)
    'setup_clean',
    'setup_data_prep',
    'setup_eda',
    'setup_feature_eng',
    'setup_modeling',
    'setup_evaluation',
    'setup_tuning',
    'setup_ensemble',
    'setup_monitoring',
    'setup',  # Universal function
    # Roadmap implementation
    'setup_roadmap_safe',
    'setup_phase1_safe',
    'apply_to_notebook',
    # Header utilities
    'generate_header_markdown',
    'generate_results_summary_code',
    'generate_artifacts_check_code',
    'create_notebook_template',
    'apply_header_to_existing_notebook',
    'create_notebook_index',
]

# Template para primeira c√©lula de setup ultra-limpo
ULTRA_CLEAN_SETUP_TEMPLATE = '''# üöÄ SETUP ULTRA-LIMPO (substitui 15+ linhas de imports)
import sys
from pathlib import Path
sys.path.insert(0, str(Path('..') / 'utils'))

# from notebook_setup_ultra_clean import setup_{stage_type}  # Module not implemented - use setup_roadmap_safe instead
from notebook_utils import setup_roadmap_safe
env = setup_roadmap_safe("{stage_type}")

# Extrair o que preciso - DATASETS J√Å AUTO-CARREGADOS!
pd, np, config = env['pd'], env['np'], env['config']
data_dir, artifacts_dir = env['data_dir'], env['artifacts_dir']
{extra_extracts}
quick_eval, quick_save = env['quick_eval'], env['quick_save']

{specific_imports}

print("üéØ {notebook_name} configurado - ZERO redund√¢ncia!")
{status_check}'''

# Configura√ß√µes por notebook
NOTEBOOK_CONFIGS = {
    "09_hyperparameter_tuning": {
        "stage_type": "tuning",
        "extra_extracts": "X_train, X_test, y_train, y_test = env['X_train'], env['X_test'], env['y_train'], env['y_test']",
        "specific_imports": "# Imports espec√≠ficos (j√° inclu√≠dos no setup sklearn)\nRandomForestClassifier = env['RandomForestClassifier']\nGradientBoostingClassifier = env['GradientBoostingClassifier']",
        "status_check": 'print(f"   Datasets: Train {X_train.shape if X_train is not None else \'N/A\'}, Test {X_test.shape if X_test is not None else \'N/A\'}")'
    },
    
    "10_threshold_optimization": {
        "stage_type": "evaluation", 
        "extra_extracts": "X_train, X_test, y_train, y_test = env['X_train'], env['X_test'], env['y_train'], env['y_test']",
        "specific_imports": "# M√©tricas espec√≠ficas (j√° inclu√≠das no setup)\nroc_auc_score = env['roc_auc_score']\naverage_precision_score = env['average_precision_score']",
        "status_check": 'print(f"   Datasets: Train {X_train.shape if X_train is not None else \'N/A\'}, Test {X_test.shape if X_test is not None else \'N/A\'}")'
    },
    
    "11_anomaly_detection_layer": {
        "stage_type": "modeling",
        "extra_extracts": "X_train, X_test, y_train, y_test = env['X_train'], env['X_test'], env['y_train'], env['y_test']",
        "specific_imports": "# Imports espec√≠ficos para anomaly detection\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.svm import OneClassSVM",
        "status_check": 'print(f"   Datasets: Train {X_train.shape if X_train is not None else \'N/A\'}, Test {X_test.shape if X_test is not None else \'N/A\'}")'
    },
    
    "12_graph_network_features": {
        "stage_type": "feature_eng", 
        "extra_extracts": "X_train, X_test, y_train, y_test = env['X_train'], env['X_test'], env['y_train'], env['y_test']\nplt, sns = env['plt'], env['sns']",
        "specific_imports": "# Graph features espec√≠ficos\nfe = env['fe']\nimport networkx as nx",
        "status_check": 'print(f"   Datasets: Train {X_train.shape if X_train is not None else \'N/A\'}, Test {X_test.shape if X_test is not None else \'N/A\'}")'
    },
    
    "13_ensemble_risk_scoring": {
        "stage_type": "ensemble",
        "extra_extracts": "X_train, X_test, y_train, y_test = env['X_train'], env['X_test'], env['y_train'], env['y_test']",
        "specific_imports": "# Ensemble espec√≠ficos\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import StackingClassifier",
        "status_check": 'print(f"   Datasets: Train {X_train.shape if X_train is not None else \'N/A\'}, Test {X_test.shape if X_test is not None else \'N/A\'}")'
    },
    
    "14_model_monitoring_validation": {
        "stage_type": "monitoring",
        "extra_extracts": "X_train, X_test, y_train, y_test = env['X_train'], env['X_test'], env['y_train'], env['y_test']\nplt, sns = env['plt'], env['sns']",
        "specific_imports": "# Monitoring espec√≠ficos\nfrom sklearn.metrics import classification_report\nimport json",
        "status_check": 'print(f"   Datasets: Train {X_train.shape if X_train is not None else \'N/A\'}, Test {X_test.shape if X_test is not None else \'N/A\'}")'
    },
    
    "15_model_explainability_shap": {
        "stage_type": "evaluation",
        "extra_extracts": "X_train, X_test, y_train, y_test = env['X_train'], env['X_test'], env['y_train'], env['y_test']\nplt, sns = env['plt'], env['sns']",
        "specific_imports": "# SHAP espec√≠ficos\ntry:\n    import shap\n    HAS_SHAP = True\nexcept ImportError:\n    HAS_SHAP = False\n    print('‚ö†Ô∏è SHAP n√£o dispon√≠vel - pip install shap')",
        "status_check": 'print(f"   SHAP dispon√≠vel: {HAS_SHAP if \'HAS_SHAP\' in locals() else False}")\nprint(f"   Datasets: Train {X_train.shape if X_train is not None else \'N/A\'}, Test {X_test.shape if X_test is not None else \'N/A\'}")'
    },
    
    "16_data_drift_detection": {
        "stage_type": "monitoring",
        "extra_extracts": "X_train, X_test, y_train, y_test = env['X_train'], env['X_test'], env['y_train'], env['y_test']\nplt, sns = env['plt'], env['sns']",
        "specific_imports": "# Drift detection espec√≠ficos\nfrom scipy import stats\nimport numpy as np",
        "status_check": 'print(f"   Datasets: Train {X_train.shape if X_train is not None else \'N/A\'}, Test {X_test.shape if X_test is not None else \'N/A\'}")'
    },
    
    "17_reporting_dashboard": {
        "stage_type": "monitoring",
        "extra_extracts": "plt, sns = env['plt'], env['sns']",
        "specific_imports": "# Dashboard espec√≠ficos\nimport json\nfrom datetime import datetime\ntry:\n    import plotly.express as px\n    import plotly.graph_objects as go\n    HAS_PLOTLY = True\nexcept ImportError:\n    HAS_PLOTLY = False",
        "status_check": 'print(f"   Plotly dispon√≠vel: {HAS_PLOTLY if \'HAS_PLOTLY\' in locals() else False}")'
    }
}

def generate_setup_code(notebook_name):
    """Gera c√≥digo de setup ultra-limpo para notebook espec√≠fico"""
    if notebook_name not in NOTEBOOK_CONFIGS:
        return None
    
    config = NOTEBOOK_CONFIGS[notebook_name]
    
    return ULTRA_CLEAN_SETUP_TEMPLATE.format(
        stage_type=config["stage_type"],
        notebook_name=notebook_name,
        extra_extracts=config["extra_extracts"],
        specific_imports=config["specific_imports"],
        status_check=config["status_check"]
    )

if __name__ == "__main__":
    # Testar gera√ß√£o
    for notebook in NOTEBOOK_CONFIGS:
        print(f"\n=== {notebook} ===")
        code = generate_setup_code(notebook)
        print(code[:200] + "...")

"""
üöÄ NANO SETUP - Setup Ultra-Eficiente (30 linhas vs 534 linhas)
Elimina 95% da redund√¢ncia mantendo 100% da funcionalidade
"""

import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
import yaml, json, pickle, warnings
from pathlib import Path
from datetime import datetime

warnings.filterwarnings('ignore')

def nano_setup(stage="general"):
    """Setup completo em 1 linha - substitui todo o sistema atual"""
    
    # === PATHS AUTOM√ÅTICOS ===
    root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()
    data_dir, artifacts_dir = root / 'data', root / 'artifacts'
    
    # === CONFIG AUTO-LOAD ===
    with open(root / 'config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # === PLOTTING SETUP ===
    plt.style.use('default')
    sns.set_palette("husl")
    plt.rcParams['figure.figsize'] = (12, 8)
    
    # === AUTO-LOAD DATASETS (se existirem) ===
    X_train = X_test = y_train = y_test = None
    try:
        X_train = pd.read_csv(data_dir / "X_train_engineered.csv") if (data_dir / "X_train_engineered.csv").exists() else None
        X_test = pd.read_csv(data_dir / "X_test_engineered.csv") if (data_dir / "X_test_engineered.csv").exists() else None
        y_train = pd.read_csv(data_dir / "y_train_engineered.csv").iloc[:, 0] if (data_dir / "y_train_engineered.csv").exists() else None
        y_test = pd.read_csv(data_dir / "y_test_engineered.csv").iloc[:, 0] if (data_dir / "y_test_engineered.csv").exists() else None
    except: pass
    
    # === QUICK FUNCTIONS ===
    def quick_save(obj, name): 
        path = artifacts_dir / name
        if name.endswith('.pkl'): pickle.dump(obj, open(path, 'wb'))
        elif name.endswith('.json'): json.dump(obj, open(path, 'w'), indent=2)
        elif name.endswith('.csv'): obj.to_csv(path, index=False)
        print(f"‚úÖ {name}")
    
    def quick_load(name): 
        path = artifacts_dir / name
        if name.endswith('.pkl'): return pickle.load(open(path, 'rb'))
        elif name.endswith('.json'): return json.load(open(path))
        elif name.endswith('.csv'): return pd.read_csv(path)
    
    # === RETURN ENVIRONMENT ===
    return {
        'pd': pd, 'np': np, 'plt': plt, 'sns': sns, 'config': config,
        'data_dir': data_dir, 'artifacts_dir': artifacts_dir, 'root': root,
        'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test,
        'quick_save': quick_save, 'quick_load': quick_load,
        'datetime': datetime, 'json': json, 'Path': Path
    }

# === IMPORTS ESPEC√çFICOS AUTOM√ÅTICOS ===
def get_sklearn():
    """Imports sklearn quando necess√°rio"""
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import roc_auc_score, average_precision_score, classification_report
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    return locals()

def get_feature_eng():
    """Imports para feature engineering"""
    import sys
    from pathlib import Path
    
    # Tentar importar de utils_backup
    try:
        backup_path = str(Path.cwd().parent / 'utils_backup')
        if backup_path not in sys.path:
            sys.path.append(backup_path)
        
        # Importar o m√≥dulo 31_feature_engineering
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "feature_engineering",
            Path.cwd().parent / 'utils_backup' / '31_feature_engineering.py'
        )
        if spec and spec.loader:
            fe = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(fe)
            return {'fe': fe}
    except Exception:
        pass
    
    return {}

"""
Notebook Setup Utilities

Standardized setup code generator to eliminate redundancy across notebooks.
"""

from pathlib import Path
import sys
import warnings
from typing import List, Optional

def setup_notebook_environment(
    stage_name: str,
    project_root: Optional[Path] = None,
    additional_imports: Optional[List[str]] = None,
    load_config: bool = True,
    setup_plotting: bool = True
) -> dict:
    """
    One-function setup for all notebooks - eliminates redundant setup code.
    Usa o m√≥dulo data para reutilizar c√≥digo existente.
    
    Args:
        stage_name: Name of the current stage/notebook
        project_root: Project root path (auto-detected if None)
        additional_imports: Additional imports specific to the notebook
        load_config: Whether to load configuration
        setup_plotting: Whether to setup plotting defaults
        
    Returns:
        Dictionary with loaded modules, config, and paths
    """
    
    # Standard imports that every notebook needs
    import pandas as pd
    import numpy as np
    from pathlib import Path
    import json
    import warnings
    import sys
    
    if setup_plotting:
        import matplotlib.pyplot as plt
        import seaborn as sns
        plt.style.use('default')
        sns.set_theme(style="whitegrid", context="notebook")
    
    warnings.filterwarnings('ignore')
    
    # Auto-detect project root
    if project_root is None:
        current_dir = Path.cwd()
        if current_dir.name == 'notebooks':
            project_root = current_dir.parent
        else:
            project_root = current_dir
    
    # Add utils to path
    utils_path = project_root / 'utils'
    if str(utils_path) not in sys.path:
        sys.path.insert(0, str(utils_path))
    
    # Use data module for standardized setup
    try:
        from .data import setup_standard_environment
        central_env = setup_standard_environment(stage_name, project_root)
        
        # Merge with additional setup
        result = {
            'pd': pd,
            'np': np,
            'Path': Path,
            'json': json,
            'project_root': project_root,
            'utils_path': utils_path,
            **central_env  # Include data module results
        }
        
        if setup_plotting:
            result.update({
                'plt': plt,
                'sns': sns
            })
        
        # Import data module functions
        from .data import (
            load_datasets_standard,
            evaluate_model_standard,
            get_core_features_standard,
            save_results_standard
        )
        
        result.update({
            'load_datasets': load_datasets_standard,
            'evaluate_model': evaluate_model_standard,
            'get_core_features': get_core_features_standard,
            'save_results': save_results_standard
        })
        
        print(f"‚úÖ Data module functions available")
        
    except ImportError as e:
        print(f"‚ö†Ô∏è Data module not available: {e}")
        # Fallback to basic setup
        data_dir = project_root / 'data'
        artifacts_dir = project_root / 'artifacts'
        models_dir = project_root / 'models'
        artifacts_dir.mkdir(exist_ok=True)
        
        result = {
            'pd': pd, 'np': np, 'Path': Path, 'json': json,
            'project_root': project_root, 'utils_path': utils_path,
            'data_dir': data_dir, 'artifacts_dir': artifacts_dir, 'models_dir': models_dir,
            'config': {}
        }
        
        if setup_plotting:
            result.update({'plt': plt, 'sns': sns})
    
    print(f"üöÄ {stage_name} - Setup eliminando redund√¢ncias")
    
    return result


def load_standard_datasets(data_dir: Path, variant: str = 'engineered'):
    """
    Standard data loading function to eliminate repetitive loading code.
    
    Args:
        data_dir: Data directory path
        variant: Dataset variant ('engineered', 'scaled', 'temporal', etc.)
        
    Returns:
        Tuple of (X_train, X_test, y_train, y_test)
    """
    import pandas as pd
    
    try:
        X_train = pd.read_csv(data_dir / f'X_train_{variant}.csv')
        X_test = pd.read_csv(data_dir / f'X_test_{variant}.csv')
        y_train = pd.read_csv(data_dir / f'y_train_{variant}.csv').iloc[:, 0]
        y_test = pd.read_csv(data_dir / f'y_test_{variant}.csv').iloc[:, 0]
        
        print(f"‚úÖ Datasets loaded ({variant})")
        print(f"   Train: {X_train.shape}, Test: {X_test.shape}")
        print(f"   Target rate - Train: {y_train.mean():.4f}, Test: {y_test.mean():.4f}")
        
        return X_train, X_test, y_train, y_test
        
    except FileNotFoundError as e:
        print(f"‚ùå Dataset loading failed: {e}")
        print(f"üí° Available files in {data_dir}:")
        for file in data_dir.glob('*.csv'):
            print(f"   - {file.name}")
        return None, None, None, None

def load_core_features(data_dir: Path, artifacts_dir: Path):
    """
    Load core features list.
    
    Returns:
        List of core feature names
    """
    core_path = artifacts_dir / 'core_features.txt'
    if core_path.exists():
        with open(core_path, 'r') as f:
            core_features = [line.strip() for line in f if line.strip()]
        print(f"‚úÖ Core features loaded: {len(core_features)}")
        return core_features
    else:
        print("‚ö†Ô∏è Core features file not found")
        return []

def quick_model_evaluation(model, X_train, y_train, X_test, y_test, model_name="Model"):
    """
    Quick model evaluation with standard metrics.
    
    Returns:
        Dictionary with metrics
    """
    from sklearn.metrics import classification_report, roc_auc_score, average_precision_score
    
    # Fit and predict
    model.fit(X_train, y_train)
    
    # Predictions
    y_pred = model.predict(X_test)
    if hasattr(model, 'predict_proba'):
        y_scores = model.predict_proba(X_test)[:, 1]
    else:
        y_scores = model.decision_function(X_test)
    
    # Metrics
    roc_auc = roc_auc_score(y_test, y_scores)
    pr_auc = average_precision_score(y_test, y_scores)
    
    print(f"üìä {model_name} Results:")
    print(f"   ROC-AUC: {roc_auc:.4f}")
    print(f"   PR-AUC: {pr_auc:.4f}")
    print(f"   Base rate: {y_test.mean():.4f}")
    
    return {
        'model_name': model_name,
        'roc_auc': roc_auc,
        'pr_auc': pr_auc,
        'predictions': y_pred,
        'scores': y_scores,
        'fitted_model': model
    }

"""
SETUP ULTRA-LIMPO para Notebooks
Elimina 95% das redund√¢ncias em 1 linha de c√≥digo
"""

def setup_clean(stage="default", plotting=True, imports=None):
    """
    üöÄ SETUP ULTRA-LIMPO - 1 linha elimina toda redund√¢ncia
    
    Usage:
        env = setup_clean("feature_engineering", imports=['sklearn', 'fe'])
        pd, np, X_train, X_test = env['pd'], env['np'], env['X_train'], env['X_test']
    """
    print(f"üöÄ Setup LIMPO: {stage}")
    
    # === IMPORTS AUTOM√ÅTICOS ===
    import pandas as pd
    import numpy as np
    import yaml
    from pathlib import Path
    import sys
    import json
    from datetime import datetime
    import warnings
    warnings.filterwarnings('ignore')
    
    # === PATHS INTELIGENTES ===
    root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()
    data_dir = root / 'data'
    artifacts_dir = root / 'artifacts'
    utils_dir = root / 'utils'
    
    if str(utils_dir) not in sys.path:
        sys.path.insert(0, str(utils_dir))
    
    # === CONFIG GLOBAL ===
    with open(root / 'config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # === PLOTTING AUTOM√ÅTICO + VISUALIZATION SUITE ===
    plt = sns = None
    viz_suite = None
    
    if plotting:
        import matplotlib.pyplot as plt
        import seaborn as sns
        plt.style.use('default')
        sns.set_palette("husl")
        plt.rcParams['figure.figsize'] = (12, 8)
        
        # Carregar Visualization Suite
        try:
            # Import din√¢mico para evitar erro se n√£o existir
            visualization_suite = __import__('visualization_suite')
            AMLVisualizationSuite = getattr(visualization_suite, 'AMLVisualizationSuite', None)
            quick_dashboard = getattr(visualization_suite, 'quick_dashboard', None)
            quick_network = getattr(visualization_suite, 'quick_network', None)
            quick_eda = getattr(visualization_suite, 'quick_eda', None)
            quick_performance = getattr(visualization_suite, 'quick_performance', None)
            
            viz_suite = AMLVisualizationSuite() if AMLVisualizationSuite else None
            print("üé® Visualization Suite carregada!")
        except (ImportError, AttributeError):
            print("‚ö†Ô∏è Visualization Suite n√£o encontrada")
            viz_suite = None
            quick_dashboard = quick_network = quick_eda = quick_performance = None
    
    # === IMPORTS ESPEC√çFICOS AUTOM√ÅTICOS ===
    modules = {}
    if imports:
        for imp in imports:
            if imp == 'sklearn':
                from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
                from sklearn.linear_model import LogisticRegression
                from sklearn.metrics import roc_auc_score, average_precision_score, classification_report
                from sklearn.model_selection import train_test_split
                from sklearn.preprocessing import StandardScaler, LabelEncoder
                modules.update({
                    'RandomForestClassifier': RandomForestClassifier,
                    'GradientBoostingClassifier': GradientBoostingClassifier, 
                    'LogisticRegression': LogisticRegression,
                    'roc_auc_score': roc_auc_score,
                    'average_precision_score': average_precision_score,
                    'classification_report': classification_report,
                    'train_test_split': train_test_split,
                    'StandardScaler': StandardScaler,
                    'LabelEncoder': LabelEncoder
                })
            elif imp == 'fe':
                try:
                    import importlib.util
                    from pathlib import Path
                    spec = importlib.util.spec_from_file_location(
                        "feature_engineering",
                        Path.cwd().parent / 'utils_backup' / '31_feature_engineering.py'
                    )
                    if spec and spec.loader:
                        fe = importlib.util.module_from_spec(spec)
                        spec.loader.exec_module(fe)
                        modules['fe'] = fe
                except Exception as e:
                    print(f"‚ö†Ô∏è N√£o foi poss√≠vel importar feature_engineering: {e}")
            elif imp == 'preditiva':
                try:
                    preditiva = __import__('preditiva')
                    modules['preditiva'] = preditiva
                except ImportError:
                    print("‚ö†Ô∏è M√≥dulo preditiva n√£o encontrado")
            else:
                try:
                    mod = __import__(imp)
                    modules[imp] = mod
                except:
                    print(f"‚ö†Ô∏è N√£o foi poss√≠vel importar {imp}")
    
    # === AUTO-LOAD DATASETS ===
    X_train = X_test = y_train = y_test = None
    
    # Tentar carregar datasets mais recentes automaticamente
    dataset_variants = ['engineered', 'scaled', 'temporal', 'graph', '']
    for variant in dataset_variants:
        suffix = f'_{variant}' if variant else ''
        try:
            X_train = pd.read_csv(data_dir / f'X_train{suffix}.csv')
            X_test = pd.read_csv(data_dir / f'X_test{suffix}.csv')
            y_train = pd.read_csv(data_dir / f'y_train{suffix}.csv').iloc[:, 0]
            y_test = pd.read_csv(data_dir / f'y_test{suffix}.csv').iloc[:, 0]
            variant_name = variant if variant else 'base'
            print(f"‚úÖ Auto-carregou: {variant_name} - Train: {X_train.shape}, Test: {X_test.shape}")
            break
        except:
            continue
    
    if X_train is None:
        print("‚ÑπÔ∏è Nenhum dataset pr√©-processado encontrado")
    
    # === FUN√á√ïES ULTRA-R√ÅPIDAS ===
    def quick_load(variant='engineered'):
        """Carrega datasets rapidamente"""
        suffix = f'_{variant}' if variant else ''
        try:
            X_tr = pd.read_csv(data_dir / f'X_train{suffix}.csv')
            X_te = pd.read_csv(data_dir / f'X_test{suffix}.csv') 
            y_tr = pd.read_csv(data_dir / f'y_train{suffix}.csv').iloc[:, 0]
            y_te = pd.read_csv(data_dir / f'y_test{suffix}.csv').iloc[:, 0]
            print(f"‚úÖ {variant}: Train {X_tr.shape}, Test {X_te.shape}")
            return X_tr, X_te, y_tr, y_te
        except Exception as e:
            print(f"‚ùå Erro ao carregar {variant}: {e}")
            return None, None, None, None
    
    def quick_save(data, name, as_csv=True):
        """Salva dados rapidamente"""
        if as_csv and hasattr(data, 'to_csv'):
            path = artifacts_dir / f"{name}.csv"
            data.to_csv(path, index=False)
        else:
            path = artifacts_dir / f"{name}.json"
            if isinstance(data, dict):
                data['timestamp'] = datetime.now().isoformat()
                data['stage'] = stage
            with open(path, 'w') as f:
                json.dump(data if isinstance(data, dict) else {'data': str(data)}, f, indent=2)
        print(f"‚úÖ Salvo: {name}")
        return path
    
    def quick_eval(model, X_tr=None, y_tr=None, X_te=None, y_te=None, name="Model"):
        """Avalia modelo rapidamente"""
        # Usar datasets auto-carregados se n√£o especificados
        X_tr = X_tr if X_tr is not None else X_train
        y_tr = y_tr if y_tr is not None else y_train
        X_te = X_te if X_te is not None else X_test
        y_te = y_te if y_te is not None else y_test
        
        if any(x is None for x in [X_tr, y_tr, X_te, y_te]):
            print("‚ùå Datasets n√£o dispon√≠veis para avalia√ß√£o")
            return None
        
        from sklearn.metrics import roc_auc_score, average_precision_score
        
        model.fit(X_tr, y_tr)
        y_pred = model.predict(X_te)
        y_scores = model.predict_proba(X_te)[:, 1] if hasattr(model, 'predict_proba') else y_pred
        
        roc = roc_auc_score(y_te, y_scores)
        pr = average_precision_score(y_te, y_scores)
        
        result = {
            'model': name,
            'roc_auc': roc,
            'pr_auc': pr,
            'features': X_tr.shape[1],
            'test_size': len(y_te),
            'target_rate': y_te.mean()
        }
        
        print(f"üéØ {name}: ROC={roc:.4f}, PR={pr:.4f}, Features={X_tr.shape[1]}")
        return result
    
    def load_raw(file='df_Money_Laundering_v2.csv', sample=None):
        """Carrega dados brutos com amostragem opcional"""
        df = pd.read_csv(data_dir / file)
        if sample and len(df) > sample:
            df = df.sample(n=sample, random_state=42)
        print(f"‚úÖ Dados brutos: {df.shape}")
        return df
    
    # === AMBIENTE COMPLETO ===
    env = {
        # Core
        'pd': pd, 'np': np, 'config': config, 'stage': stage,
        # Paths  
        'data_dir': data_dir, 'artifacts_dir': artifacts_dir, 'root': root,
        # Datasets (auto-carregados)
        'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test,
        # Functions
        'quick_load': quick_load, 'quick_save': quick_save, 'quick_eval': quick_eval, 'load_raw': load_raw,
        # Utils
        'datetime': datetime, 'json': json, 'Path': Path
    }
    
    if plotting:
        env.update({
            'plt': plt, 
            'sns': sns,
            'viz_suite': viz_suite,
            'quick_dashboard': quick_dashboard if viz_suite else None,
            'quick_network': quick_network if viz_suite else None,
            'quick_eda': quick_eda if viz_suite else None,
            'quick_performance': quick_performance if viz_suite else None
        })
    
    env.update(modules)  # Adicionar imports espec√≠ficos
    
    print(f"‚úÖ {len(env)} recursos dispon√≠veis | Datasets: {'‚úÖ' if X_train is not None else '‚ùå'}")
    return env

# === SHORTCUTS POR STAGE ===
def setup_data_prep():
    return setup_clean("data_prep", imports=['preditiva'])

def setup_eda():
    return setup_clean("eda", imports=['preditiva'])

def setup_feature_eng():
    return setup_clean("feature_engineering", imports=['fe', 'sklearn', 'preditiva'])

def setup_modeling():
    return setup_clean("modeling", imports=['sklearn'])

def setup_evaluation():
    return setup_clean("evaluation", imports=['sklearn'])

def setup_tuning():
    return setup_clean("tuning", imports=['sklearn'])

def setup_ensemble():
    return setup_clean("ensemble", imports=['sklearn'])

def setup_monitoring():
    return setup_clean("monitoring", imports=['sklearn'])

# === FUN√á√ÉO UNIVERSAL - USE ESTA ===
def setup(stage_name, **kwargs):
    """Fun√ß√£o universal - detecta stage e configura automaticamente"""
    stage_shortcuts = {
        'data_prep': setup_data_prep,
        'eda': setup_eda, 
        'exploratory': setup_eda,
        'feature_engineering': setup_feature_eng,
        'feature_eng': setup_feature_eng,
        'modeling': setup_modeling,
        'baseline': setup_modeling,
        'evaluation': setup_evaluation,
        'tuning': setup_tuning,
        'hyperparameter': setup_tuning,
        'ensemble': setup_ensemble,
        'monitoring': setup_monitoring
    }
    
    # Detectar por palavras-chave no nome
    for key, func in stage_shortcuts.items():
        if key in stage_name.lower():
            print(f"üéØ Auto-detectado: {key}")
            return func()
    
    # Fallback para setup gen√©rico
    return setup_clean(stage_name, **kwargs)

# === ROADMAP IMPLEMENTATION - FASE 1 IMPROVEMENTS ===

def setup_roadmap_safe(stage="general", enable_shap=False):
    """Setup seguro para implementa√ß√£o do roadmap"""
    print(f"üöÄ ROADMAP Setup: {stage}")
    
    # === IMPORTS B√ÅSICOS (SEMPRE FUNCIONAM) ===
    import pandas as pd
    import numpy as np
    import yaml
    from pathlib import Path
    import sys
    import json
    from datetime import datetime
    import warnings
    warnings.filterwarnings('ignore')
    
    # === PATHS INTELIGENTES ===
    root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()
    data_dir = root / 'data'
    artifacts_dir = root / 'artifacts'
    utils_dir = root / 'utils'
    
    if str(utils_dir) not in sys.path:
        sys.path.insert(0, str(utils_dir))
    
    # === CONFIG GLOBAL ===
    config = {}
    try:
        with open(root / 'config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è Config n√£o carregado: {e}")
    
    # === PLOTTING SEGURO ===
    plt = sns = None
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
        plt.style.use('default')
        sns.set_palette("husl")
        plt.rcParams['figure.figsize'] = (12, 8)
        print("‚úÖ Matplotlib + Seaborn carregados")
    except ImportError as e:
        print(f"‚ö†Ô∏è Plotting n√£o dispon√≠vel: {e}")
    
    # === SKLEARN SEGURO ===
    sklearn_models = {}
    try:
        from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.metrics import roc_auc_score, average_precision_score, classification_report
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler, LabelEncoder
        
        sklearn_models.update({
            'RandomForestClassifier': RandomForestClassifier,
            'GradientBoostingClassifier': GradientBoostingClassifier,
            'LogisticRegression': LogisticRegression,
            'roc_auc_score': roc_auc_score,
            'average_precision_score': average_precision_score,
            'classification_report': classification_report,
            'train_test_split': train_test_split,
            'StandardScaler': StandardScaler,
            'LabelEncoder': LabelEncoder
        })
        print("‚úÖ Sklearn carregado")
    except ImportError as e:
        print(f"‚ö†Ô∏è Sklearn n√£o dispon√≠vel: {e}")
    
    # === SHAP SEGURO ===
    shap_available = False
    shap_module = None
    if enable_shap:
        try:
            import shap
            shap_module = shap
            shap_available = True
            print(f"‚úÖ SHAP carregado: {shap.__version__}")
        except Exception as e:
            print(f"‚ö†Ô∏è SHAP n√£o dispon√≠vel: {e}")
            print(f"   Instale com: pip install shap")
            # Load fallback
            try:
                shap_fallback = __import__('shap_fallback')
                explain_model_safe = getattr(shap_fallback, 'explain_model_safe', None)
                if explain_model_safe:
                    sklearn_models['explain_model_safe'] = explain_model_safe
                    print("‚úÖ SHAP fallback carregado")
            except ImportError:
                print("‚ö†Ô∏è SHAP fallback tamb√©m n√£o dispon√≠vel")
    
    # === AUTO-LOAD DATASETS ===
    X_train = X_test = y_train = y_test = None
    
    dataset_variants = ['engineered', 'scaled', 'temporal', 'graph', '']
    for variant in dataset_variants:
        suffix = f'_{variant}' if variant else ''
        try:
            X_train = pd.read_csv(data_dir / f'X_train{suffix}.csv')
            X_test = pd.read_csv(data_dir / f'X_test{suffix}.csv')
            y_train = pd.read_csv(data_dir / f'y_train{suffix}.csv').iloc[:, 0]
            y_test = pd.read_csv(data_dir / f'y_test{suffix}.csv').iloc[:, 0]
            variant_name = variant if variant else 'base'
            print(f"‚úÖ Datasets: {variant_name} - Train: {X_train.shape}, Test: {X_test.shape}")
            break
        except:
            continue
    
    if X_train is None:
        print("‚ÑπÔ∏è Nenhum dataset encontrado")
    
    # === FUN√á√ïES √öTEIS ROADMAP ===
    def quick_save_roadmap(data, name):
        """Salva dados rapidamente para roadmap"""
        artifacts_dir.mkdir(exist_ok=True)
        path = artifacts_dir / f"{name}.json"
        
        if hasattr(data, 'to_dict'):
            data_to_save = data.to_dict()
        elif hasattr(data, 'tolist'):
            data_to_save = data.tolist()
        else:
            data_to_save = data
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data_to_save, f, indent=2, default=str)
        
        print(f"üíæ Salvo: {name}")
        return path
    
    def log_roadmap(message, level="INFO"):
        """Log para roadmap"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_msg = f"[{timestamp}] {level}: {message}"
        print(log_msg)
        
        log_file = artifacts_dir / "roadmap_implementation.log"
        artifacts_dir.mkdir(exist_ok=True)
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(log_msg + "\n")
    
    # === AMBIENTE COMPLETO ===
    env = {
        # Core
        'pd': pd, 'np': np, 'config': config, 'stage': stage,
        # Paths
        'data_dir': data_dir, 'artifacts_dir': artifacts_dir, 'root': root,
        # Datasets
        'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test,
        # Functions
        'quick_save': quick_save_roadmap, 'log': log_roadmap,
        # Utils
        'datetime': datetime, 'json': json, 'Path': Path,
        # Flags
        'shap_available': shap_available,
        'sklearn_available': len(sklearn_models) > 0
    }
    
    if plt:
        env.update({'plt': plt, 'sns': sns})
    
    if shap_module:
        env['shap'] = shap_module
    
    env.update(sklearn_models)
    
    print(f"‚úÖ Roadmap setup completo: {len(env)} recursos dispon√≠veis")
    print(f"üìä Datasets: {'‚úÖ' if X_train is not None else '‚ùå'}")
    print(f"üé® Plotting: {'‚úÖ' if plt else '‚ùå'}")
    print(f"ü§ñ Sklearn: {'‚úÖ' if sklearn_models else '‚ùå'}")
    print(f"üîç SHAP: {'‚úÖ' if shap_available else '‚ùå'}")
    
    return env

# === FASE 1 IMPROVEMENTS ===

def setup_phase1_safe(stage="default"):
    """Setup seguro para Fase 1 - sem depend√™ncias problem√°ticas"""
    print(f"üöÄ Setup FASE 1: {stage}")
    
    # Core imports (sempre funcionam)
    import pandas as pd
    import numpy as np
    from pathlib import Path
    import json
    import warnings
    warnings.filterwarnings('ignore')
    
    # Setup paths
    root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()
    data_dir = root / 'data'
    artifacts_dir = root / 'artifacts'
    utils_dir = root / 'utils'
    
    # Add utils to path
    import sys
    if str(utils_dir) not in sys.path:
        sys.path.insert(0, str(utils_dir))
    
    # Safe plotting imports
    plt = sns = None
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
        plt.style.use('default')
        sns.set_palette("husl")
    except ImportError:
        print("‚ö†Ô∏è Matplotlib/Seaborn n√£o dispon√≠vel")
    
    # Safe sklearn imports
    sklearn_available = False
    try:
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import roc_auc_score, average_precision_score
        sklearn_available = True
    except ImportError:
        print("‚ö†Ô∏è Sklearn n√£o dispon√≠vel")
    
    # Load config
    config = {}
    try:
        import yaml
        with open(root / 'config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except:
        print("‚ö†Ô∏è Config n√£o carregado")
    
    # Auto-load datasets (safe)
    X_train = X_test = y_train = y_test = None
    try:
        X_train = pd.read_csv(data_dir / 'X_train_engineered.csv')
        X_test = pd.read_csv(data_dir / 'X_test_engineered.csv')
        y_train = pd.read_csv(data_dir / 'y_train_engineered.csv').iloc[:, 0]
        y_test = pd.read_csv(data_dir / 'y_test_engineered.csv').iloc[:, 0]
        print(f"‚úÖ Datasets: Train {X_train.shape}, Test {X_test.shape}")
    except:
        print("‚ÑπÔ∏è Datasets n√£o carregados automaticamente")
    
    # Safe functions
    def quick_save(data, name):
        """Salva dados rapidamente"""
        path = artifacts_dir / f"{name}.json"
        if hasattr(data, 'to_dict'):
            data_to_save = data.to_dict()
        else:
            data_to_save = data
        
        with open(path, 'w') as f:
            json.dump(data_to_save, f, indent=2, default=str)
        print(f"‚úÖ Salvo: {name}")
        return path
    
    return {
        'pd': pd, 'np': np, 'plt': plt, 'sns': sns,
        'config': config, 'stage': stage,
        'data_dir': data_dir, 'artifacts_dir': artifacts_dir,
        'X_train': X_train, 'X_test': X_test, 
        'y_train': y_train, 'y_test': y_test,
        'quick_save': quick_save,
        'sklearn_available': sklearn_available
    }

def apply_to_notebook(notebook_path, new_setup=True):
    """Aplica novo setup a um notebook"""
    # Esta fun√ß√£o seria implementada para modificar notebooks
    # Por enquanto, apenas placeholder
    print(f"üìù Setup aplicado: {notebook_path}")
    return True

"""
Notebook Header Utilities

Standardized templates and utilities for consistent notebook structure
and professional presentation across the AML pipeline.
"""

from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import json


def generate_header_markdown(
    stage_number: str,
    title: str,
    objective: str,
    inputs: List[str],
    outputs: List[str],
    primary_metric: str = "PR_AUC",
    next_notebook: Optional[str] = None
) -> str:
    """
    Generate standardized notebook header markdown.
    
    Args:
        stage_number: Stage identifier (e.g., "06", "n06")
        title: Descriptive title
        objective: Brief objective description
        inputs: List of input files/artifacts
        outputs: List of expected outputs
        primary_metric: Primary evaluation metric
        next_notebook: Next notebook in sequence
        
    Returns:
        Formatted markdown string
    """
    
    # Format inputs and outputs as bullet lists
    inputs_md = '\n'.join(f'- `{inp}`' for inp in inputs)
    outputs_md = '\n'.join(f'- `{out}`' for out in outputs)
    
    next_section = ""
    if next_notebook:
        next_section = f"""
## Pr√≥ximo Notebook
[{next_notebook}]({next_notebook.lower().replace(' ', '_')}.ipynb)
"""
    
    header = f"""# {stage_number} - {title}

## üéØ Objetivo
{objective}

## üì• Entradas
{inputs_md}

## üì§ Sa√≠das
{outputs_md}

## üìä M√©trica Principal
**{primary_metric}** - Adequada para dados desbalanceados no contexto AML

## üìã Sum√°rio Executivo
*Ser√° atualizado ap√≥s execu√ß√£o*

| M√©trica | Valor | Status |
|---------|-------|--------|
| {primary_metric} | - | Pendente |
| ROC_AUC | - | Pendente |
| Recall@100 | - | Pendente |
| Base Rate | - | Pendente |

## üîÑ Status de Execu√ß√£o
- [ ] Configura√ß√£o carregada
- [ ] Dados carregados e validados  
- [ ] Processamento principal executado
- [ ] Resultados salvos
- [ ] Artefatos gerados{next_section}

---
*Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M')}*

"""
    
    return header


def generate_setup_code(
    stage_name: str,
    imports: List[str] = None,
    load_config: bool = True,
    load_data: bool = True
) -> str:
    """
    Generate standardized setup code for notebooks.
    
    Args:
        stage_name: Stage identifier for logging
        imports: Additional imports beyond standard ones
        load_config: Whether to load configuration
        load_data: Whether to include data loading template
        
    Returns:
        Formatted Python code string
    """
    
    standard_imports = [
        "import pandas as pd",
        "import numpy as np", 
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from pathlib import Path",
        "import json",
        "import logging",
        "import warnings",
        "warnings.filterwarnings('ignore')"
    ]
    
    if imports:
        all_imports = standard_imports + imports
    else:
        all_imports = standard_imports
    
    imports_code = '\n'.join(all_imports)
    
    setup_code = f"""# üì¶ Setup e Configura√ß√£o
{imports_code}

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Set plotting style
plt.style.use('default')
sns.set_theme(style="whitegrid", context="notebook", font_scale=1.1)

# Paths
notebook_dir = Path.cwd()
project_root = notebook_dir.parent
utils_path = project_root / "utils"
artifacts_dir = project_root / "artifacts"
data_dir = project_root / "data"
models_dir = project_root / "models"

# Ensure directories exist
artifacts_dir.mkdir(exist_ok=True)

print(f"üöÄ Setup completed for {stage_name}")
"""

    if load_config:
        config_code = """
# Load configuration
import sys
sys.path.insert(0, str(utils_path))
# from module_loader import load_internal_modules, get_pipeline_functions  # Module not implemented

# modules = load_internal_modules()
# funcs = get_pipeline_functions(modules)
# config = funcs['load_config']()
config = {}  # Placeholder - implement proper config loading

print(f"‚úÖ Configuration loaded")
print(f"üìä Primary metric: {config.get('modeling', {}).get('model_selection', {}).get('primary_metric', 'PR_AUC')}")
"""
        setup_code += config_code

    if load_data:
        data_code = """
# Data loading template (customize as needed)
try:
    # Load your datasets here
    # X_train = pd.read_csv(data_dir / "X_train_engineered.csv")
    # y_train = pd.read_csv(data_dir / "y_train_engineered.csv").iloc[:, 0]
    # X_test = pd.read_csv(data_dir / "X_test_engineered.csv") 
    # y_test = pd.read_csv(data_dir / "y_test_engineered.csv").iloc[:, 0]
    
    print(f"‚úÖ Data loading template ready")
    # print(f"üìà Train shape: {X_train.shape}, Test shape: {X_test.shape}")
    # print(f"‚öñÔ∏è Base rate: {y_train.mean():.4f}")
except Exception as e:
    print(f"‚ö†Ô∏è Data loading: {e}")
"""
        setup_code += data_code

    return setup_code


def generate_results_summary_code() -> str:
    """Generate code template for results summary section."""
    
    return """# üìä Resultados e Sum√°rio

def update_execution_summary(metrics_dict):
    \"\"\"Update the execution summary with actual results.\"\"\"
    
    summary_md = f\"\"\"
## üìã Sum√°rio Executivo - Atualizado

| M√©trica | Valor | Status |
|---------|-------|--------|
| PR_AUC | {metrics_dict.get('PR_AUC', 'N/A'):.4f} | ‚úÖ Conclu√≠do |
| ROC_AUC | {metrics_dict.get('ROC_AUC', 'N/A'):.4f} | ‚úÖ Conclu√≠do |
| Recall@100 | {metrics_dict.get('Recall@100', 'N/A'):.4f} | ‚úÖ Conclu√≠do |
| Base Rate | {metrics_dict.get('Base_Rate', 'N/A'):.4f} | ‚úÖ Conclu√≠do |

### üîç Principais Insights
- Modelo selecionado: {metrics_dict.get('best_model', 'N/A')}
- Melhoria sobre baseline: {metrics_dict.get('improvement', 'N/A')}
- Pr√≥xima a√ß√£o recomendada: {metrics_dict.get('next_action', 'Prosseguir para pr√≥ximo notebook')}
\"\"\"
    
    from IPython.display import display, Markdown
    display(Markdown(summary_md))

# Use this function at the end to update summary:
# update_execution_summary({
#     'PR_AUC': best_pr_auc,
#     'ROC_AUC': best_roc_auc, 
#     'Recall@100': best_recall_at_100,
#     'Base_Rate': base_rate,
#     'best_model': best_model_name,
#     'improvement': improvement_pct,
#     'next_action': 'Continue to n07_model_tuning'
# })
"""


def generate_artifacts_check_code() -> str:
    """Generate code to check and list generated artifacts."""
    
    return """# üíæ Verifica√ß√£o de Artefatos Gerados

def check_generated_artifacts(expected_files):
    \"\"\"Check which artifacts were successfully generated.\"\"\"
    
    generated = []
    missing = []
    
    for file_path in expected_files:
        full_path = artifacts_dir / file_path
        if full_path.exists():
            size_kb = full_path.stat().st_size / 1024
            generated.append(f"‚úÖ {file_path} ({size_kb:.1f} KB)")
        else:
            missing.append(f"‚ùå {file_path}")
    
    print("üìÅ ARTEFATOS GERADOS:")
    for item in generated:
        print(f"   {item}")
    
    if missing:
        print("\\n‚ö†Ô∏è ARTEFATOS AUSENTES:")
        for item in missing:
            print(f"   {item}")
    
    return len(generated), len(missing)

# Use at the end of notebook:
# expected_artifacts = [
#     "baseline_models.csv",
#     "baseline_candidates.json", 
#     "best_model_meta.json"
# ]
# generated_count, missing_count = check_generated_artifacts(expected_artifacts)
# print(f"\\nüìä RESUMO: {generated_count} gerados, {missing_count} ausentes")
"""


def create_notebook_template(
    stage_number: str,
    title: str,
    objective: str,
    inputs: List[str],
    outputs: List[str],
    primary_metric: str = "PR_AUC",
    next_notebook: Optional[str] = None,
    additional_imports: List[str] = None
) -> Dict[str, Any]:
    """
    Create complete notebook template with standardized structure.
    
    Returns:
        Dictionary representing notebook structure for Jupyter
    """
    
    # Generate content sections
    header_md = generate_header_markdown(
        stage_number, title, objective, inputs, outputs, 
        primary_metric, next_notebook
    )
    
    setup_code = generate_setup_code(
        f"{stage_number}_{title.lower().replace(' ', '_')}",
        additional_imports
    )
    
    results_code = generate_results_summary_code()
    artifacts_code = generate_artifacts_check_code()
    
    # Build notebook structure
    notebook = {
        "cells": [
            {
                "cell_type": "markdown",
                "metadata": {"id": "header", "language": "markdown"},
                "source": header_md.split('\n')
            },
            {
                "cell_type": "code", 
                "metadata": {"id": "setup", "language": "python"},
                "source": setup_code.split('\n')
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "main_work", "language": "markdown"},
                "source": [
                    "# üîß Processamento Principal",
                    "",
                    "*Adicione aqui as c√©lulas de c√≥digo para o processamento espec√≠fico deste notebook.*",
                    "",
                    "## Metodologia",
                    "- Passo 1: ...",
                    "- Passo 2: ...",
                    "- Passo 3: ..."
                ]
            },
            {
                "cell_type": "code",
                "metadata": {"id": "results_summary", "language": "python"},
                "source": results_code.split('\n')
            },
            {
                "cell_type": "code",
                "metadata": {"id": "artifacts_check", "language": "python"},
                "source": artifacts_code.split('\n')
            },
            {
                "cell_type": "markdown",
                "metadata": {"id": "conclusion", "language": "markdown"},
                "source": [
                    "# üéØ Conclus√µes",
                    "",
                    "## Principais Resultados",
                    "- ...",
                    "- ...",
                    "",
                    "## Decis√µes Tomadas", 
                    "- ...",
                    "- ...",
                    "",
                    "## Pr√≥ximos Passos",
                    "- ...",
                    "",
                    "---",
                    f"*Notebook {stage_number} conclu√≠do em {datetime.now().strftime('%Y-%m-%d %H:%M')}*"
                ]
            }
        ],
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python", 
                "name": "python3"
            },
            "language_info": {
                "name": "python",
                "version": "3.8.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    return notebook


def apply_header_to_existing_notebook(notebook_path: Path, stage_info: Dict[str, Any]) -> bool:
    """
    Apply standardized header to existing notebook.
    
    Args:
        notebook_path: Path to existing notebook
        stage_info: Dictionary with stage information
        
    Returns:
        True if successful, False otherwise
    """
    try:
        # Load existing notebook
        with open(notebook_path, 'r', encoding='utf-8') as f:
            notebook = json.load(f)
        
        # Generate header
        header_md = generate_header_markdown(**stage_info)
        
        # Check if first cell is already a header
        if notebook['cells'] and notebook['cells'][0]['cell_type'] == 'markdown':
            # Replace existing header
            notebook['cells'][0]['source'] = header_md.split('\n')
        else:
            # Insert new header at beginning
            header_cell = {
                "cell_type": "markdown",
                "metadata": {"id": "standardized_header", "language": "markdown"},
                "source": header_md.split('\n')
            }
            notebook['cells'].insert(0, header_cell)
        
        # Save updated notebook
        with open(notebook_path, 'w', encoding='utf-8') as f:
            json.dump(notebook, f, indent=2, ensure_ascii=False)
        
        return True
        
    except Exception as e:
        print(f"Error applying header to {notebook_path}: {e}")
        return False


def create_notebook_index(notebooks_info: List[Dict[str, Any]], output_path: Path) -> bool:
    """
    Create a master index notebook with links to all pipeline notebooks.
    
    Args:
        notebooks_info: List of dictionaries with notebook information
        output_path: Path to save the index notebook
        
    Returns:
        True if successful
    """
    
    # Generate table of contents
    toc_rows = []
    for nb_info in notebooks_info:
        stage = nb_info.get('stage_number', 'XX')
        title = nb_info.get('title', 'Unknown')
        filename = f"n{stage.zfill(2)}_{title.lower().replace(' ', '_')}.ipynb"
        status = "‚úÖ" if (output_path.parent / filename).exists() else "‚è≥"
        
        toc_rows.append(f"| [{stage}]({filename}) | {title} | {status} |")
    
    toc_table = '\n'.join(toc_rows)
    
    index_content = f"""# üìö AML Pipeline - √çndice de Notebooks

## üéØ Pipeline Completo de Anti-Money Laundering

Este √≠ndice fornece navega√ß√£o centralizada por todos os notebooks do pipeline.

## üìã Tabela de Conte√∫dos

| Stage | T√≠tulo | Status |
|-------|--------|--------|
{toc_table}

## üîÑ Ordem de Execu√ß√£o Recomendada

1. **Data Preparation** (n01-n03): Prepara√ß√£o e divis√£o dos dados
2. **Feature Engineering** (n04-n05): Cria√ß√£o e sele√ß√£o de features  
3. **Model Training** (n06-n07): Baselines e tuning
4. **Optimization** (n08-n11): Thresholds, anomaly, ensemble
5. **Validation & Monitoring** (n12-n15): Monitoramento, explainability, reporting

## üìä Status Geral do Pipeline

- ‚úÖ Conclu√≠do
- ‚è≥ Pendente
- ‚ùå Com problemas

## üöÄ Execu√ß√£o Automatizada

Para executar o pipeline completo via linha de comando:

```bash
# Pipeline completo
python run_pipeline.py --stage full-pipeline --temporal-split

# Stages individuais
python run_pipeline.py --stage baselines
python run_pipeline.py --stage tuning
python run_pipeline.py --stage thresholds
```

---
*√çndice gerado em {datetime.now().strftime('%Y-%m-%d %H:%M')}*
"""

    try:
        index_notebook = {
            "cells": [
                {
                    "cell_type": "markdown",
                    "metadata": {"language": "markdown"},
                    "source": index_content.split('\n')
                }
            ],
            "metadata": {
                "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
                "language_info": {"name": "python", "version": "3.8.0"}
            },
            "nbformat": 4,
            "nbformat_minor": 4
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(index_notebook, f, indent=2, ensure_ascii=False)
        
        return True
        
    except Exception as e:
        print(f"Error creating index: {e}")
        return False


# Example usage templates
STAGE_TEMPLATES = {
    "06": {
        "stage_number": "06",
        "title": "Model Baselines",
        "objective": "Avaliar modelos baseline e selecionar candidatos para tuning usando crit√©rios unificados de sele√ß√£o.",
        "inputs": ["X_train_engineered.csv", "X_test_engineered.csv", "y_train_engineered.csv", "y_test_engineered.csv", "core_features.txt"],
        "outputs": ["baseline_models.csv", "baseline_candidates.json", "best_model_meta.json", "model_card.json"],
        "primary_metric": "PR_AUC",
        "next_notebook": "n07 - Model Tuning"
    },
    "07": {
        "stage_number": "07", 
        "title": "Model Tuning",
        "objective": "Otimizar hiperpar√¢metros dos candidatos selecionados e atualizar melhor modelo se houver melhoria significativa.",
        "inputs": ["baseline_candidates.json", "best_model_meta.json"],
        "outputs": ["best_model_tuned.pkl", "tuning_results.csv", "best_model_meta.json (updated)"],
        "primary_metric": "PR_AUC",
        "next_notebook": "n08 - Threshold Strategy"
    },
    "08": {
        "stage_number": "08",
        "title": "Threshold Strategy", 
        "objective": "Otimizar thresholds considerando m√©tricas operacionais e expected value para contexto AML.",
        "inputs": ["best_model_meta.json", "risk_scores.csv"],
        "outputs": ["thresholds.json", "expected_value_analysis.csv"],
        "primary_metric": "Expected Value",
        "next_notebook": "n09 - Anomaly Detection"
    }
}

print("‚úÖ Notebook header utilities loaded successfully!")