{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19db39a0",
   "metadata": {},
   "source": [
    "# 🚀 Integração Notebooks ↔ Produção\n",
    "\n",
    "## Solução para Workflow Eficiente: Notebooks que Salvam Modelos para Produção\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  NOTEBOOK → PRODUÇÃO SEM RETRAINING INEFICIENTE           │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "![Workflow](https://img.shields.io/badge/Workflow-Optimized-green)\n",
    "![Efficiency](https://img.shields.io/badge/Efficiency-Maximized-blue)\n",
    "![Integration](https://img.shields.io/badge/Integration-Seamless-success)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **PROBLEMA IDENTIFICADO**\n",
    "\n",
    "Atualmente, o workflow força **duplicação de esforço**:\n",
    "1. **Notebooks**: Experimentam e descobrem melhores modelos\n",
    "2. **train.py**: Retreina os mesmos modelos para produção\n",
    "\n",
    "### ✅ **SOLUÇÃO IMPLEMENTADA**\n",
    "\n",
    "Este notebook demonstra como **notebooks podem salvar modelos diretamente para produção**, eliminando retraining desnecessário.\n",
    "\n",
    "---\n",
    "\n",
    "### 📋 **WORKFLOW OTIMIZADO**\n",
    "\n",
    "```\n",
    "Notebook Experimentation → Model Training → Direct Save → Production\n",
    "                                      ↓\n",
    "                             Sem retraining no train.py!\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfcb4887",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     sys.path.append(\u001b[38;5;28mstr\u001b[39m(project_root))\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Import project utilities\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_artifact, save_trained_model_for_production\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FraudMetrics\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, GradientBoostingClassifier\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SETUP: IMPORTS E CONFIGURAÇÃO\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import project utilities\n",
    "from utils.data import load_artifact, save_trained_model_for_production\n",
    "from utils.modeling import FraudMetrics\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "print(\"✅ Setup completo!\")\n",
    "print(f\"📁 Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CARREGAR DADOS PREPARADOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"📊 Carregando dados preparados...\")\n",
    "\n",
    "# Carregar dados preparados pelo notebook de feature engineering\n",
    "try:\n",
    "    X_train = load_artifact(project_root / \"artifacts\" / \"X_train_temporal_clean.parquet\")\n",
    "    y_train = load_artifact(project_root / \"artifacts\" / \"y_train_processed.parquet\")['target']\n",
    "    X_test = load_artifact(project_root / \"artifacts\" / \"X_test_temporal_clean.parquet\")\n",
    "    y_test = load_artifact(project_root / \"artifacts\" / \"y_test_processed.parquet\")['target']\n",
    "\n",
    "    print(\"✅ Dados carregados com sucesso!\")\n",
    "    print(f\"📈 Train: {X_train.shape[0]:,} amostras, {X_train.shape[1]} features\")\n",
    "    print(f\"🧪 Test: {X_test.shape[0]:,} amostras, {X_test.shape[1]} features\")\n",
    "    print(\".1%\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro carregando dados: {e}\")\n",
    "    print(\"Execute primeiro o notebook 01_feature_engineering.ipynb\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TREINAMENTO DE MODELOS NO NOTEBOOK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"🤖 Iniciando treinamento de modelos...\")\n",
    "\n",
    "# Definir modelos para testar\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Treinar e avaliar modelos\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🏋️ Treinando {name}...\")\n",
    "\n",
    "    # Treinar modelo\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Avaliar no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calcular métricas\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Cross-validation para robustez\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "\n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'roc_auc_test': roc_auc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "\n",
    "    print(\".4f\"    print(\".4f\"    print(\".4f\"\n",
    "# Selecionar melhor modelo\n",
    "best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['roc_auc_test'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "best_score = model_results[best_model_name]['roc_auc_test']\n",
    "\n",
    "print(f\"\\n🏆 Melhor modelo: {best_model_name} (ROC-AUC: {best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a2eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SALVAR MODELO DIRETAMENTE PARA PRODUÇÃO (SEM RETRAINING!)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"💾 Salvando modelo treinado diretamente para produção...\")\n",
    "\n",
    "# Metadados do modelo\n",
    "model_metadata = {\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'notebook_version': 'integrated_workflow_v1.0',\n",
    "    'data_version': 'temporal_clean_v2.0',\n",
    "    'hyperparameters': {\n",
    "        'n_estimators': getattr(best_model, 'n_estimators', None),\n",
    "        'max_depth': getattr(best_model, 'max_depth', None),\n",
    "        'learning_rate': getattr(best_model, 'learning_rate', None),\n",
    "        'random_state': getattr(best_model, 'random_state', None)\n",
    "    },\n",
    "    'performance': {\n",
    "        'roc_auc_test': model_results[best_model_name]['roc_auc_test'],\n",
    "        'cv_mean': model_results[best_model_name]['cv_mean'],\n",
    "        'cv_std': model_results[best_model_name]['cv_std']\n",
    "    },\n",
    "    'features_used': list(X_train.columns),\n",
    "    'target_distribution': y_train.value_counts().to_dict()\n",
    "}\n",
    "\n",
    "# Salvar modelo usando a nova função\n",
    "save_result = save_trained_model_for_production(\n",
    "    model=best_model,\n",
    "    model_name=f\"fraud_detection_{best_model_name.lower()}\",\n",
    "    experiment_id=f\"notebook_integration_{datetime.now().strftime('%Y%m%d')}\",\n",
    "    metadata=model_metadata\n",
    ")\n",
    "\n",
    "print(\"\n",
    "✅ Modelo salvo com sucesso!\"print(f\"📁 Caminho: {save_result['model_path']}\")\n",
    "print(f\"📄 Metadata: {save_result['metadata_path']}\")\n",
    "print(f\"🧪 Experiment ID: {save_result['experiment_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PROMOVER PARA PRODUÇÃO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"🚀 Promovendo modelo para produção...\")\n",
    "\n",
    "# Comando para promover o modelo (usando o novo fluxo centralizado)\n",
    "promotion_command = save_result['promotion_command']\n",
    "\n",
    "print(\"Execute o seguinte comando no terminal para promover:\")\n",
    "print(f\"🔧 {promotion_command}\")\n",
    "print()\n",
    "print(\"Ou liste modelos disponíveis primeiro:\")\n",
    "print(f\"🔧 python src/modeling/train.py --list_notebook_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3076d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VERIFICAÇÃO: CARREGAR E TESTAR MODELO SALVO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"🔍 Verificando modelo salvo...\")\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Carregar modelo salvo\n",
    "with open(save_result['model_path'], 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Carregar metadata\n",
    "with open(save_result['metadata_path'], 'r') as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "\n",
    "print(\"✅ Modelo carregado com sucesso!\")\n",
    "print(f\"📊 Tipo: {type(loaded_model).__name__}\")\n",
    "print(f\"🎯 ROC-AUC salvo: {loaded_metadata['performance']['roc_auc_test']:.4f}\")\n",
    "\n",
    "# Testar predições\n",
    "test_predictions = loaded_model.predict(X_test[:10])\n",
    "test_probabilities = loaded_model.predict_proba(X_test[:10])\n",
    "\n",
    "print(f\"🧪 Teste de predição: {len(test_predictions)} amostras\")\n",
    "print(f\"📈 Probabilidades shape: {test_probabilities.shape}\")\n",
    "\n",
    "print(\"\\n✅ Verificação completa - modelo pronto para produção!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97295b37",
   "metadata": {},
   "source": [
    "# 🎉 **WORKFLOW OTIMIZADO CONCLUÍDO!**\n",
    "\n",
    "## 📊 **RESUMO DA SOLUÇÃO**\n",
    "\n",
    "### ❌ **Antes (Ineficiente)**\n",
    "```\n",
    "Notebook Experimentation → Descobrir Melhor Modelo\n",
    "                                      ↓\n",
    "train.py → Retreinar Mesmo Modelo → Produção\n",
    "```\n",
    "\n",
    "### ✅ **Agora (Otimizado)**\n",
    "```\n",
    "Notebook Experimentation → Treinar Modelo → Salvar Direto → Produção\n",
    "                                      ↓\n",
    "                         Sem retraining desnecessário!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 **COMO USAR EM SEUS NOTEBOOKS**\n",
    "\n",
    "### **1. Após treinar seu modelo:**\n",
    "```python\n",
    "from utils.data import save_trained_model_for_production\n",
    "\n",
    "# Seu modelo treinado\n",
    "best_model = ...\n",
    "\n",
    "# Salvar diretamente para produção\n",
    "save_result = save_trained_model_for_production(\n",
    "    model=best_model,\n",
    "    model_name=\"meu_modelo_fraud\",\n",
    "    experiment_id=\"exp_001\",\n",
    "    metadata={'roc_auc': 0.95, 'features': list(X_train.columns)}\n",
    ")\n",
    "```\n",
    "\n",
    "### **2. Promover para produção:**\n",
    "```bash\n",
    "python src/modeling/train.py --promote_trained artifacts/models/meu_modelo_fraud.pkl\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 **PRÓXIMOS PASSOS**\n",
    "\n",
    "1. **Integre em seus notebooks** de modelagem\n",
    "2. **Use quando quiser pular retraining** desnecessário\n",
    "3. **Mantenha train.py** para casos onde retraining é necessário\n",
    "4. **Documente** qual abordagem usar em cada cenário\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 **BENEFÍCIOS**\n",
    "\n",
    "- ⚡ **Velocidade**: Sem retraining desnecessário\n",
    "- 🎯 **Precisão**: Mesmo modelo, mesmas métricas\n",
    "- 🔄 **Flexibilidade**: Escolha entre notebook direto ou train.py\n",
    "- 📊 **Rastreabilidade**: Metadata completa preservada\n",
    "- 🛡️ **Produção**: Modelos prontos para deployment imediato\n",
    "\n",
    "**Fim do workflow otimizado! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
