{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d98d64a",
   "metadata": {},
   "source": [
    "# Teste de Treinamento Otimizado - Sem Duplicatas\n",
    "\n",
    "Teste isolado para verificar se os prints de treinamento estão otimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d9db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração otimizada carregada!\n"
     ]
    }
   ],
   "source": [
    "# Configuração COMPLETA de logging silenciado\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Desabilitar TODOS os logs\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "logging.getLogger().handlers.clear()\n",
    "\n",
    "for name in ['src', 'sklearn', 'xgboost', 'lightgbm', 'pandas', 'numpy']:\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.CRITICAL)\n",
    "    logger.handlers.clear()\n",
    "    logger.propagate = False\n",
    "\n",
    "# Função print_model_summary otimizada\n",
    "def print_model_summary(model_name, eval_results, training_time):\n",
    "    \"\"\"Imprime resumo profissional sem duplicatas\"\"\"\n",
    "    roc_auc = eval_results.get('roc_auc', 0.0)\n",
    "    pr_auc = eval_results.get('pr_auc', 0.0)\n",
    "    recall = eval_results.get('recall', 0.0)\n",
    "    precision = eval_results.get('precision', 0.0)\n",
    "    f1 = eval_results.get('f1', 0.0)\n",
    "    threshold = eval_results.get('optimal_threshold', 0.5)\n",
    "    \n",
    "    print(f\"✅ {model_name.upper()} - {training_time:.1f}s\")\n",
    "    print(f\"   ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f} | Threshold: {threshold:.3f}\")\n",
    "    print(f\"   Recall: {recall:.4f} | Precision: {precision:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "print(\"Configuração otimizada carregada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f393e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports realizados com sucesso!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup e imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path('..').resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.modeling.train_individual_models import train_xgboost_model\n",
    "from src.features.aml_plotting import *\n",
    "\n",
    "print(\"Imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671cfb1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\artifacts\\\\features_processed.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m artifacts_dir = Path(\u001b[33m'\u001b[39m\u001b[33m../artifacts\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m features_pkl = artifacts_dir / \u001b[33m'\u001b[39m\u001b[33mfeatures_processed.pkl\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_pkl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mis_fraud\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m X = df.drop(\u001b[33m'\u001b[39m\u001b[33mis_fraud\u001b[39m\u001b[33m'\u001b[39m, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafeb\\anaconda3\\envs\\aml\\Lib\\site-packages\\joblib\\numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\artifacts\\\\features_processed.pkl'"
     ]
    }
   ],
   "source": [
    "   \"source\": [\n",
    "    \"# Carregar dados\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"artifacts_dir = Path('c:/Users/gafeb/OneDrive/Desktop/lavagem_dev/artifacts')\\n\",\n",
    "    \"features_pkl = artifacts_dir / 'features_processed.pkl'\\n\",\n",
    "    \"\\n\",\n",
    "    \"df = joblib.load(features_pkl)\\n\",\n",
    "    \"y = df['is_fraud']\\n\",\n",
    "    \"X = df.drop('is_fraud', axis=1)\\n\",\n",
    "    \"numeric_cols = X.select_dtypes(include=[np.number]).columns\\n\",\n",
    "    \"X = X[numeric_cols]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Dados carregados: {X.shape[0]:,} amostras, {X.shape[1]} features\\\")\"\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8812e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração simples para teste\n",
    "config = {\n",
    "    'models': {\n",
    "        'xgboost': {\n",
    "            'model_type': 'xgb',\n",
    "            'params': {\n",
    "                'n_estimators': 10,\n",
    "                'max_depth': 3,\n",
    "                'learning_rate': 0.1,\n",
    "                'random_state': 42,\n",
    "                'verbosity': 0,\n",
    "                'n_jobs': 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Configuração de teste criada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b92f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTE DE TREINAMENTO - XGBoost\n",
    "import time\n",
    "\n",
    "print(\"=== INICIANDO TREINAMENTO XGBOOST ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = train_xgboost_model(\n",
    "    X=X[:1000],  # Usar apenas 1000 amostras para teste rápido\n",
    "    y=y[:1000],\n",
    "    config=config,\n",
    "    artifacts_dir=artifacts_dir,\n",
    "    force_retrain=True,  # Forçar retreinamento\n",
    "    enable_gpu=False\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "if 'model_name' in results and results['model_name'] == 'xgboost':\n",
    "    eval_results = results['evaluation_results']\n",
    "    print_model_summary('XGBoost', eval_results, training_time)\n",
    "else:\n",
    "    print(\"Falha no treinamento\")\n",
    "\n",
    "print(\"=== TREINAMENTO CONCLUÍDO ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
