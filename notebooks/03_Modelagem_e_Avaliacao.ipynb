{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0765b4",
   "metadata": {},
   "source": [
    "# 03 · Modelagem e Avaliação\n",
    "\n",
    "**Objetivo:** Implementar pipeline completo de treinamento e avaliação de modelos para detecção de transações suspeitas de lavagem de dinheiro.\n",
    "\n",
    "Este notebook executa o pipeline técnico de modelagem, incluindo:\n",
    "- Carregamento e pré-processamento de features\n",
    "- Validação temporal para evitar data leakage\n",
    "- Otimização de hiperparâmetros com Optuna + ASHA pruning\n",
    "- Calibração de probabilidades\n",
    "- Comparação objetiva com benchmark Multi-GNN\n",
    "- Salvamento de artefatos para notebooks downstream\n",
    "\n",
    "### Configuração Técnica\n",
    "- **Dados**: Features processadas do notebook 02\n",
    "- **Modelos**: XGBoost, LightGBM, RandomForest\n",
    "- **Validação**: Cross-validation temporal (5 folds)\n",
    "- **Otimização**: Optuna com ASHA pruning para eficiência\n",
    "- **Métricas**: ROC-AUC, PR-AUC, Precision@k, Recall@FPR\n",
    "- **Calibração**: Isotonic regression para probabilidades confiáveis\n",
    "\n",
    "### Pipeline de Execução\n",
    "1. Setup e configuração centralizada\n",
    "2. Carregamento e pré-processamento\n",
    "3. Validação temporal baseline\n",
    "4. Otimização ASHA para XGBoost e LightGBM\n",
    "5. Calibração e avaliação final\n",
    "6. Comparação com benchmark\n",
    "7. Salvamento de artefatos\n",
    "\n",
    "### Artefatos Gerados\n",
    "- Modelos otimizados e calibrados (`.pkl`)\n",
    "- Resultados de otimização ASHA (`.json`)\n",
    "- Métricas de calibração (`.json`)\n",
    "- Comparação com benchmark (`.json`)\n",
    "- Importância de features (`.json`)\n",
    "\n",
    "Para análises executivas e apresentações, consulte o notebook `06_Executive_Summary.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17aafa9",
   "metadata": {},
   "source": [
    "## ▸ Configuração Centralizada\n",
    "\n",
    "Centralizo todas as configurações do projeto para facilitar manutenção e reprodutibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcc3369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-21 13:28:18,884 - __main__ - INFO - Logging estruturado configurado\n",
      "2025-10-21 13:28:18,885 - __main__ - INFO - Configuração centralizada carregada - Modo: Desenvolvimento\n",
      "2025-10-21 13:28:18,886 - __main__ - INFO - Versão do projeto: 1.0.0\n",
      "2025-10-21 13:28:18,887 - __main__ - INFO - Modo rápido: False\n",
      " Configuração centralizada implementada\n",
      " Projeto: AML_Detection_Pipeline v1.0.0\n",
      " Modo: Desenvolvimento\n",
      " Modo rápido: False\n",
      " Logs salvos: True\n",
      "2025-10-21 13:28:18,885 - __main__ - INFO - Configuração centralizada carregada - Modo: Desenvolvimento\n",
      "2025-10-21 13:28:18,886 - __main__ - INFO - Versão do projeto: 1.0.0\n",
      "2025-10-21 13:28:18,887 - __main__ - INFO - Modo rápido: False\n",
      " Configuração centralizada implementada\n",
      " Projeto: AML_Detection_Pipeline v1.0.0\n",
      " Modo: Desenvolvimento\n",
      " Modo rápido: False\n",
      " Logs salvos: True\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURAÇÃO CENTRALIZADA\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuração de logging estruturado\n",
    "def setup_structured_logging(log_level=logging.INFO, log_file=None):\n",
    "    \"\"\"Configura logging estruturado com timestamps e níveis apropriados.\"\"\"\n",
    "    if log_file is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        log_file = f\"../logs/notebook_03_{timestamp}.log\"\n",
    "\n",
    "    # Criar diretório de logs se não existir\n",
    "    Path(log_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Configuração do logger\n",
    "    logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"Logging estruturado configurado\")\n",
    "    return logger\n",
    "\n",
    "# Dicionário de configuração centralizada\n",
    "CONFIG = {\n",
    "    # === CONFIGURAÇÃO GERAL ===\n",
    "    'project_name': 'AML_Detection_Pipeline',\n",
    "    'version': '1.0.0',\n",
    "    'author': 'AML Team',\n",
    "    'description': 'Pipeline de detecção de lavagem de dinheiro com ML',\n",
    "\n",
    "    # === MODOS DE EXECUÇÃO ===\n",
    "    'execution_mode': {\n",
    "        'development': True,  # True para desenvolvimento, False para produção\n",
    "        'quick_mode': False,  # True para testes rápidos com subamostragem\n",
    "        'debug_mode': False,  # True para logs detalhados\n",
    "    },\n",
    "\n",
    "    # === CAMINHOS DE ARQUIVOS ===\n",
    "    'paths': {\n",
    "        'project_root': Path('..').resolve(),\n",
    "        'data_dir': Path('..') / 'data' / 'processed',\n",
    "        'artifacts_dir': Path('..') / 'artifacts',\n",
    "        'logs_dir': Path('..') / 'logs',\n",
    "        'models_dir': Path('..') / 'models',\n",
    "        'features_file': 'features_with_patterns.pkl',\n",
    "        'benchmark_metrics': 'gnn_benchmark_metrics.json',\n",
    "        'production_config': 'production_config.json',\n",
    "        'monitoring_config': 'monitoring_config.json',\n",
    "    },\n",
    "\n",
    "    # === PARÂMETROS DE DADOS ===\n",
    "    'data': {\n",
    "        'random_seed': 42,\n",
    "        'quick_sample_size': 50000,  # Tamanho da amostra para modo rápido\n",
    "        'temporal_splits': 5,  # Número de folds para validação temporal\n",
    "        'test_size_ratio': 0.2,  # Proporção de teste em cada fold\n",
    "    },\n",
    "\n",
    "    # === CONFIGURAÇÃO DE MODELOS ===\n",
    "    'models': {\n",
    "        'xgboost': {\n",
    "            'model_type': 'xgb',\n",
    "            'params': {\n",
    "                'n_estimators': 1000,\n",
    "                'max_depth': 5,\n",
    "                'learning_rate': 0.1,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'random_state': 42,\n",
    "                'eval_metric': 'auc',\n",
    "                'use_label_encoder': False,\n",
    "                'verbosity': 0,\n",
    "                'n_jobs': -1,\n",
    "                'tree_method': 'hist'\n",
    "            }\n",
    "        },\n",
    "        'lightgbm': {\n",
    "            'model_type': 'lgb',\n",
    "            'params': {\n",
    "                'n_estimators': 1000,\n",
    "                'max_depth': 6,\n",
    "                'learning_rate': 0.1,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'random_state': 42,\n",
    "                'verbosity': -1,\n",
    "                'metric': 'auc',\n",
    "                'n_jobs': 1,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'is_unbalance': True,\n",
    "                'min_child_samples': 20,\n",
    "                'min_child_weight': 1e-3,\n",
    "                'reg_alpha': 0.0,\n",
    "                'reg_lambda': 1.0,\n",
    "                'num_leaves': 31,\n",
    "                'bagging_freq': 1,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'feature_fraction': 0.8\n",
    "            }\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model_type': 'rf',\n",
    "            'params': {\n",
    "                'n_estimators': 80,\n",
    "                'max_depth': 10,\n",
    "                'min_samples_split': 10,\n",
    "                'min_samples_leaf': 5,\n",
    "                'random_state': 42,\n",
    "                'class_weight': 'balanced',\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # === HIPERPARÂMETROS DE OTIMIZAÇÃO ===\n",
    "    'optimization': {\n",
    "        'optuna_trials': 50,  # Número de trials do Optuna (modo dev) ou 1 (produção)\n",
    "        'early_stopping': {\n",
    "            'enabled': True,\n",
    "            'rounds': 20,\n",
    "            'metric': 'auc',\n",
    "            'min_delta': 0.001,\n",
    "            'max_rounds': 1000\n",
    "        },\n",
    "        'asha_pruning': True,  # Usar ASHA para pruning\n",
    "    },\n",
    "\n",
    "    # === MÉTRICAS E THRESHOLDS ===\n",
    "    'metrics': {\n",
    "        'primary_metrics': ['roc_auc', 'average_precision'],\n",
    "        'secondary_metrics': ['recall', 'precision', 'f1'],\n",
    "        'aml_thresholds': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "        'business_metrics': {\n",
    "            'cost_benefit_ratio': {'fp_cost': 1, 'fn_cost': 100},\n",
    "            'regulatory_requirements': {\n",
    "                'min_recall': 0.8,\n",
    "                'max_false_positive_rate': 0.05\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # === CALIBRAÇÃO ===\n",
    "    'calibration': {\n",
    "        'method': 'isotonic',  # 'isotonic' ou 'sigmoid'\n",
    "        'cv_folds': 5,\n",
    "        'evaluation_bins': 10,  # Para ECE\n",
    "    },\n",
    "\n",
    "    # === MONITORAMENTO E PRODUÇÃO ===\n",
    "    'production': {\n",
    "        'model_version': '1.0.0',\n",
    "        'retraining_frequency': 'weekly',  # daily, weekly, monthly\n",
    "        'drift_threshold': 0.1,\n",
    "        'performance_drop_threshold': 0.05,\n",
    "        'alert_channels': ['email', 'slack'],  # Canais de alerta\n",
    "    },\n",
    "\n",
    "    # === LOGGING ===\n",
    "    'logging': {\n",
    "        'level': 'INFO',  # DEBUG, INFO, WARNING, ERROR\n",
    "        'save_logs': True,\n",
    "        'log_performance_metrics': True,\n",
    "        'log_model_artifacts': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Aplicar configurações baseadas no modo\n",
    "if CONFIG['execution_mode']['development']:\n",
    "    CONFIG['optimization']['optuna_trials'] = 5  # Menos trials em desenvolvimento\n",
    "    CONFIG['logging']['level'] = 'DEBUG' if CONFIG['execution_mode']['debug_mode'] else 'INFO'\n",
    "else:\n",
    "    CONFIG['optimization']['optuna_trials'] = 1  # Trial único em produção\n",
    "    CONFIG['logging']['level'] = 'WARNING'\n",
    "\n",
    "# Configurar logging\n",
    "logger = setup_structured_logging(\n",
    "    log_level=getattr(logging, CONFIG['logging']['level']),\n",
    "    log_file=CONFIG['paths']['logs_dir'] / f\"notebook_03_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "    if CONFIG['logging']['save_logs'] else None\n",
    ")\n",
    "\n",
    "# Log da configuração inicial\n",
    "logger.info(f\"Configuração centralizada carregada - Modo: {'Desenvolvimento' if CONFIG['execution_mode']['development'] else 'Produção'}\")\n",
    "logger.info(f\"Versão do projeto: {CONFIG['version']}\")\n",
    "logger.info(f\"Modo rápido: {CONFIG['execution_mode']['quick_mode']}\")\n",
    "\n",
    "print(\" Configuração centralizada implementada\")\n",
    "print(f\" Projeto: {CONFIG['project_name']} v{CONFIG['version']}\")\n",
    "print(f\" Modo: {'Desenvolvimento' if CONFIG['execution_mode']['development'] else 'Produção'}\")\n",
    "print(f\" Modo rápido: {CONFIG['execution_mode']['quick_mode']}\")\n",
    "print(f\" Logs salvos: {CONFIG['logging']['save_logs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c7039e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-21 13:28:18,904 - __main__ - INFO - Verificando modo de execução...\n",
      "2025-10-21 13:28:18,906 - __main__ - INFO - Modo desenvolvimento: trials Optuna reduzidos, validação rápida\n",
      "2025-10-21 13:28:18,907 - __main__ - INFO - Modo completo: todas as amostras\n",
      "2025-10-21 13:28:18,908 - __main__ - INFO - Modo normal: logging informativo\n",
      "2025-10-21 13:28:18,909 - __main__ - INFO - Controle de execução configurado\n",
      " Controle de execução condicional implementado\n",
      " Modo: Desenvolvimento\n",
      " Modo rápido: False\n",
      " Modo debug: False\n",
      "2025-10-21 13:28:18,906 - __main__ - INFO - Modo desenvolvimento: trials Optuna reduzidos, validação rápida\n",
      "2025-10-21 13:28:18,907 - __main__ - INFO - Modo completo: todas as amostras\n",
      "2025-10-21 13:28:18,908 - __main__ - INFO - Modo normal: logging informativo\n",
      "2025-10-21 13:28:18,909 - __main__ - INFO - Controle de execução configurado\n",
      " Controle de execução condicional implementado\n",
      " Modo: Desenvolvimento\n",
      " Modo rápido: False\n",
      " Modo debug: False\n"
     ]
    }
   ],
   "source": [
    "# CONTROLE DE EXECUÇÃO CONDICIONAL (baseado em CONFIG)\n",
    "import sys\n",
    "\n",
    "logger.info(\"Verificando modo de execução...\")\n",
    "\n",
    "# Modos de execução baseados em CONFIG\n",
    "EXECUTION_MODE = {\n",
    "    'development': CONFIG['execution_mode']['development'],\n",
    "    'quick_mode': CONFIG['execution_mode']['quick_mode'],\n",
    "    'debug_mode': CONFIG['execution_mode']['debug_mode']\n",
    "}\n",
    "\n",
    "# Configurações baseadas no modo\n",
    "if EXECUTION_MODE['development']:\n",
    "    OPTUNA_TRIALS = CONFIG['optimization']['optuna_trials']\n",
    "    CV_FOLDS = 3  # Menos folds em desenvolvimento\n",
    "    logger.info(\"Modo desenvolvimento: trials Optuna reduzidos, validação rápida\")\n",
    "else:\n",
    "    OPTUNA_TRIALS = 1  # Trial único em produção\n",
    "    CV_FOLDS = CONFIG['data']['temporal_splits']\n",
    "    logger.info(\"Modo produção: otimização completa\")\n",
    "\n",
    "if EXECUTION_MODE['quick_mode']:\n",
    "    SAMPLE_SIZE = CONFIG['data']['quick_sample_size']\n",
    "    logger.info(f\"Modo rápido ativado: {SAMPLE_SIZE:,} amostras\")\n",
    "else:\n",
    "    SAMPLE_SIZE = None\n",
    "    logger.info(\"Modo completo: todas as amostras\")\n",
    "\n",
    "if EXECUTION_MODE['debug_mode']:\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    logger.info(\"Modo debug ativado: logging detalhado\")\n",
    "else:\n",
    "    logger.info(\"Modo normal: logging informativo\")\n",
    "\n",
    "# Função para controle condicional\n",
    "def should_execute_section(section_name, force=False):\n",
    "    \"\"\"\n",
    "    Decide se uma seção deve ser executada baseado no modo.\n",
    "\n",
    "    Args:\n",
    "        section_name: Nome da seção\n",
    "        force: Forçar execução independente do modo\n",
    "\n",
    "    Returns:\n",
    "        bool: True se deve executar\n",
    "    \"\"\"\n",
    "    if force:\n",
    "        return True\n",
    "\n",
    "    # Em modo desenvolvimento, executar apenas seções essenciais\n",
    "    if EXECUTION_MODE['development']:\n",
    "        essential_sections = ['setup', 'data_loading', 'preprocessing', 'validation', 'baseline']\n",
    "        return section_name in essential_sections\n",
    "\n",
    "    # Em modo produção, executar tudo\n",
    "    return True\n",
    "\n",
    "logger.info(\"Controle de execução configurado\")\n",
    "print(\" Controle de execução condicional implementado\")\n",
    "print(f\" Modo: {'Desenvolvimento' if EXECUTION_MODE['development'] else 'Produção'}\")\n",
    "print(f\" Modo rápido: {EXECUTION_MODE['quick_mode']}\")\n",
    "print(f\" Modo debug: {EXECUTION_MODE['debug_mode']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929aa36",
   "metadata": {},
   "source": [
    "## ▸ Carregamento dos Dados\n",
    "\n",
    "Carrego as features processadas do notebook anterior, com opção de modo rápido integrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81485988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-21 13:28:19,402 - numexpr.utils - INFO - NumExpr defaulting to 12 threads.\n",
      "2025-10-21 13:28:19,748 - __main__ - INFO - Carregando dados de: ..\\data\\processed\\features_with_patterns.pkl\n",
      "2025-10-21 13:28:19,748 - __main__ - INFO - Modo rápido: False\n",
      "2025-10-21 13:28:19,748 - __main__ - INFO - Carregando dados de: ..\\data\\processed\\features_with_patterns.pkl\n",
      "2025-10-21 13:28:19,748 - __main__ - INFO - Modo rápido: False\n",
      "2025-10-21 13:28:34,996 - __main__ - INFO - Dataset carregado: 5,078,336 transações × 51 features\n",
      "2025-10-21 13:28:35,054 - __main__ - INFO - Taxa de fraude: 0.102%\n",
      "2025-10-21 13:28:34,996 - __main__ - INFO - Dataset carregado: 5,078,336 transações × 51 features\n",
      "2025-10-21 13:28:35,054 - __main__ - INFO - Taxa de fraude: 0.102%\n",
      " Dados carregados: 5,078,336 transações\n",
      " Features: 51 | Fraude: 0.102%\n",
      " Dados carregados: 5,078,336 transações\n",
      " Features: 51 | Fraude: 0.102%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      from_bank  to_bank  amount_received    amount  Bank ID  Bank ID_to  \\\n",
       " 3437         70       10          1064.04   1064.04       70          10   \n",
       " 3878         70     1047         33647.60  33647.60       70        1047   \n",
       " 4118         70     1292         14777.01  14777.01       70        1292   \n",
       " 5612         70    11471          6117.78   6117.78       70       11471   \n",
       " 6266         70    11107         16561.46  16561.46       70       11107   \n",
       " \n",
       "       hour_x  hour_y  source_amount_sum_7d  source_amount_mean_7d  ...  \\\n",
       " 3437       0       0           54015486.75           1.385012e+06  ...   \n",
       " 3878       0       0           53957155.57           1.586975e+06  ...   \n",
       " 4118       0       0           53916860.66           1.739254e+06  ...   \n",
       " 5612       0       0               7661.17           2.553723e+03  ...   \n",
       " 6266       0       0           49486451.73           2.474323e+06  ...   \n",
       " \n",
       "       from_bank_frequency  from_bank_is_rare  to_bank_frequency  \\\n",
       " 3437             0.088584                  0           0.008378   \n",
       " 3878             0.088584                  0           0.001919   \n",
       " 4118             0.088584                  0           0.002781   \n",
       " 5612             0.088584                  0           0.001724   \n",
       " 6266             0.088584                  0           0.001759   \n",
       " \n",
       "       to_bank_is_rare  same_bank_transfer  rolling_amount_mean_3  \\\n",
       " 3437                1                   0                    NaN   \n",
       " 3878                1                   0                    NaN   \n",
       " 4118                1                   0           16496.216667   \n",
       " 5612                1                   0           18180.796667   \n",
       " 6266                1                   0           12485.416667   \n",
       " \n",
       "       rolling_amount_std_3  amount_cv_3  fan_out_degree  fan_in_degree  \n",
       " 3437                   NaN          NaN           14230              4  \n",
       " 3878                   NaN          NaN           14230              2  \n",
       " 4118          16359.671428     0.991723           14230              2  \n",
       " 5612          14077.005010     0.774279           14230              4  \n",
       " 6266           5586.247666     0.447422           14230              5  \n",
       " \n",
       " [5 rows x 51 columns],\n",
       " is_fraud\n",
       " 0    5073159\n",
       " 1       5177\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARREGAMENTO DOS DADOS (usando CONFIG centralizado)\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configurar modo rápido baseado em CONFIG\n",
    "RUN_QUICK = CONFIG['execution_mode']['quick_mode']\n",
    "\n",
    "# Caminhos usando CONFIG\n",
    "data_dir = CONFIG['paths']['data_dir']\n",
    "features_pkl = data_dir / CONFIG['paths']['features_file']\n",
    "\n",
    "logger.info(f\"Carregando dados de: {features_pkl}\")\n",
    "logger.info(f\"Modo rápido: {RUN_QUICK}\")\n",
    "\n",
    "# Carregar dados processados\n",
    "try:\n",
    "    df = pd.read_pickle(features_pkl)\n",
    "    # Separar features e target\n",
    "    y = df['is_fraud']\n",
    "    X = df.drop('is_fraud', axis=1)\n",
    "\n",
    "    # Selecionar apenas colunas numéricas\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    X = X[numeric_cols]\n",
    "\n",
    "    # Modo rápido (opcional)\n",
    "    if RUN_QUICK:\n",
    "        sample_size = CONFIG['data']['quick_sample_size']\n",
    "        indices = np.random.choice(len(X), sample_size, replace=False)\n",
    "        X = X.iloc[indices].reset_index(drop=True)\n",
    "        y = y.iloc[indices].reset_index(drop=True)\n",
    "        logger.info(f\"Amostra reduzida para {sample_size:,} registros\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao carregar dados: {e}\")\n",
    "    raise\n",
    "\n",
    "# Verificação visual e logging\n",
    "logger.info(f\"Dataset carregado: {len(X):,} transações × {X.shape[1]} features\")\n",
    "logger.info(f\"Taxa de fraude: {y.mean():.3%}\")\n",
    "\n",
    "print(f\" Dados carregados: {len(X):,} transações\")\n",
    "print(f\" Features: {X.shape[1]} | Fraude: {y.mean():.3%}\")\n",
    "X.head(), y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68014a58",
   "metadata": {},
   "source": [
    "## Fase 2: Definição da Arquitetura do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43078935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import optuna\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ProductionImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Imputer robusto para produção que:\n",
    "    1. Alerta sobre features com alta taxa de valores ausentes no treino.\n",
    "    2. Alerta sobre drift na taxa de valores ausentes na inferência.\n",
    "    \"\"\"\n",
    "    def __init__(self, strategy='median', missing_threshold=0.5):\n",
    "        self.strategy = strategy\n",
    "        self.missing_threshold = missing_threshold\n",
    "        self.imputer = SimpleImputer(strategy=self.strategy)\n",
    "        self.train_missing_rates = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # RESOLVE: Falta de tratamento de missing values em produção.\n",
    "        self.train_missing_rates = X.isnull().mean()\n",
    "        high_missing_features = self.train_missing_rates[self.train_missing_rates > self.missing_threshold].index.tolist()\n",
    "        if high_missing_features:\n",
    "            logger.warning(f\"Features com >{self.missing_threshold*100}% de valores ausentes no treino: {high_missing_features}\")\n",
    "        \n",
    "        self.imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        current_missing_rates = X.isnull().mean()\n",
    "        if self.train_missing_rates is not None:\n",
    "            drift = abs(current_missing_rates - self.train_missing_rates)\n",
    "            if (drift > 0.1).any():\n",
    "                drifted_features = drift[drift > 0.1].index.tolist()\n",
    "                logger.warning(f\"Drift na taxa de valores ausentes detectado para as features: {drifted_features}\")\n",
    "        \n",
    "        return self.imputer.transform(X)\n",
    "\n",
    "class AMLModelingPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline completo para modelagem AML. A estrutura desta classe previne\n",
    "    data leakage por design, encapsulando cada etapa crítica.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.preprocessor = None\n",
    "        self.model = None\n",
    "        self.calibrated_model = None\n",
    "        self.optimal_threshold = 0.5\n",
    "        self.feature_names = None\n",
    "        self.best_params = {}\n",
    "\n",
    "    def temporal_train_test_split(self, X, y, test_size=0.2):\n",
    "        # Garante a separação inicial correta entre treino e teste.\n",
    "        split_idx = int(len(X) * (1 - test_size))\n",
    "        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "        logger.info(f\"Split temporal: {len(X_train):,} treino, {len(X_test):,} teste\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def fit_preprocessor(self, X_train, y_train):\n",
    "        # RESOLVE: Data Leakage no Pré-processamento e Monitoramento de Valores Ausentes.\n",
    "        numeric_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "        \n",
    "        numeric_pipeline = Pipeline([\n",
    "            ('imputer', ProductionImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        self.preprocessor = ColumnTransformer(\n",
    "            transformers=[('num', numeric_pipeline, numeric_cols)],\n",
    "            remainder='drop'\n",
    "        )\n",
    "        logger.info(\"Ajustando preprocessor no conjunto de treino...\")\n",
    "        self.preprocessor.fit(X_train, y_train)\n",
    "        \n",
    "        # RESOLVE: Perda de Nomes de Features.\n",
    "        self.feature_names = self.preprocessor.get_feature_names_out().tolist()\n",
    "        logger.info(f\"Preprocessor ajustado - {len(self.feature_names)} features\")\n",
    "        return self\n",
    "\n",
    "    def transform_data(self, X, return_dataframe=True):\n",
    "        X_transformed = self.preprocessor.transform(X)\n",
    "        if return_dataframe:\n",
    "            return pd.DataFrame(X_transformed, columns=self.feature_names, index=X.index)\n",
    "        return X_transformed\n",
    "\n",
    "    def optimize_hyperparameters(self, X_train, y_train, n_trials=50):\n",
    "        # RESOLVE: Configurações do Otimizador (Optuna) e Pruner (ASHA).\n",
    "        val_split_idx = int(len(X_train) * 0.8)\n",
    "        X_train_opt, y_train_opt = X_train.iloc[:val_split_idx], y_train.iloc[:val_split_idx]\n",
    "        X_val_opt, y_val_opt = X_train.iloc[val_split_idx:], y_train.iloc[val_split_idx:]\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 2000),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "                'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "                'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
    "                'random_state': self.config['data']['random_seed'],\n",
    "                'verbosity': 0,\n",
    "                'eval_metric': 'aucpr'\n",
    "            }\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(X_train_opt, y_train_opt, eval_set=[(X_val_opt, y_val_opt)], early_stopping_rounds=50, verbose=False)\n",
    "            y_pred_proba = model.predict_proba(X_val_opt)[:, 1]\n",
    "            return average_precision_score(y_val_opt, y_pred_proba)\n",
    "\n",
    "        tpe_sampler = optuna.samplers.TPESampler(\n",
    "            n_startup_trials=max(20, len(X_train.columns) * 2),\n",
    "            n_ei_candidates=50,\n",
    "            multivariate=True,\n",
    "            seed=self.config['data']['random_seed'],\n",
    "            constant_liar=True\n",
    "        )\n",
    "        \n",
    "        asha_pruner = optuna.pruners.SuccessiveHalvingPruner(\n",
    "            min_resource=max(20, int(0.1 * 2000)),\n",
    "            reduction_factor=4,\n",
    "            min_early_stopping_rate=1\n",
    "        )\n",
    "\n",
    "        study = optuna.create_study(direction='maximize', sampler=tpe_sampler, pruner=asha_pruner)\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        self.best_params = study.best_params\n",
    "        return study\n",
    "\n",
    "    def find_optimal_threshold(self, model, X_val, y_val):\n",
    "        # RESOLVE: Data Leakage na Otimização de Limiar.\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "        thresholds = np.linspace(0.01, 0.99, 100)\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "            f1 = f1_score(y_val, y_pred)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        logger.info(f\"Threshold ótimo encontrado em validação: {best_threshold:.3f} (F1={best_f1:.4f})\")\n",
    "        return best_threshold\n",
    "\n",
    "    def train_final_model(self, X_train, y_train):\n",
    "        val_split_idx = int(len(X_train) * 0.8)\n",
    "        X_train_final, y_train_final = X_train.iloc[:val_split_idx], y_train.iloc[:val_split_idx]\n",
    "        X_val_final, y_val_final = X_train.iloc[val_split_idx:], y_train.iloc[val_split_idx:]\n",
    "\n",
    "        self.model = xgb.XGBClassifier(**self.best_params)\n",
    "        self.model.fit(X_train_final, y_train_final)\n",
    "        \n",
    "        self.optimal_threshold = self.find_optimal_threshold(self.model, X_val_final, y_val_final)\n",
    "        \n",
    "        # RESOLVE: Validação Incorreta na Calibração.\n",
    "        logger.info(\"Calibrando modelo final com TimeSeriesSplit...\")\n",
    "        tss = TimeSeriesSplit(n_splits=3)\n",
    "        self.calibrated_model = CalibratedClassifierCV(self.model, method='isotonic', cv=tss)\n",
    "        self.calibrated_model.fit(X_train, y_train)\n",
    "        return self\n",
    "\n",
    "    def evaluate_on_test(self, X_test, y_test):\n",
    "        y_pred_proba = self.calibrated_model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_pred_proba >= self.optimal_threshold).astype(int)\n",
    "        metrics = {\n",
    "            'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'pr_auc': average_precision_score(y_test, y_pred_proba),\n",
    "            'f1_score': f1_score(y_test, y_pred),\n",
    "            'threshold': self.optimal_threshold\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def compute_feature_importance(self, X_train, y_train):\n",
    "        model_importance = self.model.feature_importances_\n",
    "        perm_result = permutation_importance(\n",
    "            self.model, X_train, y_train, n_repeats=5,\n",
    "            random_state=self.config['data']['random_seed'], n_jobs=-1\n",
    "        )\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'model_importance': model_importance,\n",
    "            'perm_importance': perm_result.importances_mean,\n",
    "        }).sort_values('perm_importance', ascending=False)\n",
    "        return importance_df\n",
    "\n",
    "    def save_artifacts(self, output_dir):\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        joblib.dump(self.preprocessor, output_dir / 'preprocessor.pkl')\n",
    "        joblib.dump(self.calibrated_model, output_dir / 'model_calibrated.pkl')\n",
    "        with open(output_dir / 'pipeline_config.json', 'w') as f:\n",
    "            json.dump({\n",
    "                'feature_names': self.feature_names,\n",
    "                'optimal_threshold': self.optimal_threshold,\n",
    "                'best_params': {k: (int(v) if isinstance(v, np.integer) else v) for k, v in self.best_params.items()},\n",
    "            }, f, indent=2)\n",
    "        logger.info(f\"Artefatos salvos em: {output_dir}\")\n",
    "\n",
    "class AMLBusinessMetrics:\n",
    "    def __init__(self, fp_cost=1, fn_cost=100):\n",
    "        self.fp_cost = fp_cost\n",
    "        self.fn_cost = fn_cost\n",
    "\n",
    "    def calculate_all_metrics(self, y_true, y_pred_proba, threshold=0.5):\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "        alerts_generated = tp + fp\n",
    "        total_frauds = tp + fn\n",
    "        metrics = {\n",
    "            'alert_precision': tp / alerts_generated if alerts_generated > 0 else 0,\n",
    "            'detection_rate': tp / total_frauds if total_frauds > 0 else 0,\n",
    "            'investigation_cost': fp * self.fp_cost,\n",
    "            'prevented_loss': tp * self.fn_cost,\n",
    "            'net_benefit': (tp * self.fn_cost) - (fp * self.fp_cost),\n",
    "            'alerts_generated': alerts_generated\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def find_optimal_threshold_business(self, y_true, y_pred_proba, min_detection_rate=0.8):\n",
    "        thresholds = np.linspace(0.01, 0.99, 100)\n",
    "        best_net_benefit = -float('inf')\n",
    "        best_threshold = 0.5\n",
    "        best_metrics = None\n",
    "        for threshold in thresholds:\n",
    "            metrics = self.calculate_all_metrics(y_true, y_pred_proba, threshold)\n",
    "            if metrics['detection_rate'] >= min_detection_rate:\n",
    "                if metrics['net_benefit'] > best_net_benefit:\n",
    "                    best_net_benefit = metrics['net_benefit']\n",
    "                    best_threshold = threshold\n",
    "                    best_metrics = metrics\n",
    "        if best_metrics is None:\n",
    "            logger.warning(f\"Não foi possível atender constraint de {min_detection_rate:.1%} detecção\")\n",
    "            return None\n",
    "        return {'optimal_threshold': best_threshold, 'metrics': best_metrics}\n",
    "\n",
    "class ProductionDriftDetector:\n",
    "    \"\"\"\n",
    "    Detecta drift em features e performance para monitoramento.\n",
    "    \"\"\"\n",
    "    def __init__(self, reference_data, reference_labels, drift_threshold=0.05):\n",
    "        self.reference_data = reference_data\n",
    "        self.reference_labels = reference_labels\n",
    "        self.drift_threshold = drift_threshold\n",
    "        self.reference_fraud_rate = reference_labels.mean()\n",
    "\n",
    "    def detect_feature_drift(self, X_new):\n",
    "        from scipy.stats import ks_2samp\n",
    "        drifted_features = []\n",
    "        for col in X_new.columns:\n",
    "            if col not in self.reference_data.columns: continue\n",
    "            _, pvalue = ks_2samp(self.reference_data[col].dropna(), X_new[col].dropna())\n",
    "            if pvalue < self.drift_threshold:\n",
    "                drifted_features.append(col)\n",
    "        return {\n",
    "            'has_drift': len(drifted_features) > 0,\n",
    "            'drift_percentage': len(drifted_features) / len(X_new.columns),\n",
    "            'drifted_features': drifted_features\n",
    "        }\n",
    "\n",
    "    def detect_performance_drift(self, y_true_new, y_pred_proba_new, baseline_metrics):\n",
    "        current_roc_auc = roc_auc_score(y_true_new, y_pred_proba_new)\n",
    "        roc_auc_drop = baseline_metrics['roc_auc'] - current_roc_auc\n",
    "        performance_drift = roc_auc_drop > 0.05\n",
    "        return {\n",
    "            'has_performance_drift': performance_drift,\n",
    "            'roc_auc_drop': roc_auc_drop,\n",
    "            'current_roc_auc': current_roc_auc\n",
    "        }\n",
    "\n",
    "class ConfidenceCalibrator:\n",
    "    \"\"\"\n",
    "    Calcula a predição junto com uma métrica de confiança/incerteza.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        if not hasattr(model, 'estimators_'):\n",
    "            raise TypeError(\"O modelo deve ser um ensemble de árvores (ex: RandomForest, XGBoost) para este método.\")\n",
    "        self.model = model\n",
    "\n",
    "    def predict_with_confidence(self, X):\n",
    "        predictions = np.array([\n",
    "            tree.predict_proba(X)[:, 1]\n",
    "            for tree in self.model.estimators_\n",
    "        ])\n",
    "        mean_pred = predictions.mean(axis=0)\n",
    "        std_pred = predictions.std(axis=0)\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'prediction_proba': mean_pred,\n",
    "            'uncertainty': std_pred,\n",
    "            'confidence': 1 - std_pred\n",
    "        }, index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0167f1b3",
   "metadata": {},
   "source": [
    "## Fase 3: Execução Completa do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997218bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-21 13:28:37,241 - __main__ - INFO - Split temporal: 4,062,668 treino, 1,015,668 teste\n",
      "2025-10-21 13:28:38,271 - __main__ - INFO - Ajustando preprocessor no conjunto de treino...\n",
      "2025-10-21 13:28:38,271 - __main__ - INFO - Ajustando preprocessor no conjunto de treino...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Estimator imputer does not provide get_feature_names_out. Did you mean to call pipeline[:-1].get_feature_names_out()?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m pipeline = AMLModelingPipeline(CONFIG)\n\u001b[32m      6\u001b[39m X_train, X_test, y_train, y_test = pipeline.temporal_train_test_split(X, y)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_preprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m X_train_processed = pipeline.transform_data(X_train)\n\u001b[32m      9\u001b[39m X_test_processed = pipeline.transform_data(X_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mAMLModelingPipeline.fit_preprocessor\u001b[39m\u001b[34m(self, X_train, y_train)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.preprocessor.fit(X_train, y_train)\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# RESOLVE: Perda de Nomes de Features.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_names = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.tolist()\n\u001b[32m     96\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPreprocessor ajustado - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.feature_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafeb\\anaconda3\\envs\\aml\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:523\u001b[39m, in \u001b[36mColumnTransformer.get_feature_names_out\u001b[39m\u001b[34m(self, input_features)\u001b[39m\n\u001b[32m    521\u001b[39m transformer_with_feature_names_out = []\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, trans, column, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(fitted=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     feature_names_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_feature_name_out_for_transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    527\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafeb\\anaconda3\\envs\\aml\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:495\u001b[39m, in \u001b[36mColumnTransformer._get_feature_name_out_for_transformer\u001b[39m\u001b[34m(self, name, trans, column, feature_names_in)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trans, \u001b[33m\"\u001b[39m\u001b[33mget_feature_names_out\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    492\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTransformer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(trans).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) does \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    493\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnot provide get_feature_names_out.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    494\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gafeb\\anaconda3\\envs\\aml\\Lib\\site-packages\\sklearn\\pipeline.py:808\u001b[39m, in \u001b[36mPipeline.get_feature_names_out\u001b[39m\u001b[34m(self, input_features)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter():\n\u001b[32m    807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transform, \u001b[33m\"\u001b[39m\u001b[33mget_feature_names_out\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    809\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mEstimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m does not provide get_feature_names_out. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    810\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDid you mean to call pipeline[:-1].get_feature_names_out\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    811\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m()?\u001b[39m\u001b[33m\"\u001b[39m.format(name)\n\u001b[32m    812\u001b[39m         )\n\u001b[32m    813\u001b[39m     feature_names_out = transform.get_feature_names_out(feature_names_out)\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feature_names_out\n",
      "\u001b[31mAttributeError\u001b[39m: Estimator imputer does not provide get_feature_names_out. Did you mean to call pipeline[:-1].get_feature_names_out()?"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXECUÇÃO CONTROLADA DO PIPELINE\n",
    "# Este bloco garante a sequência correta de operações, prevenindo erros.\n",
    "# =============================================================================\n",
    "pipeline = AMLModelingPipeline(CONFIG)\n",
    "X_train, X_test, y_train, y_test = pipeline.temporal_train_test_split(X, y)\n",
    "pipeline.fit_preprocessor(X_train, y_train)\n",
    "X_train_processed = pipeline.transform_data(X_train)\n",
    "X_test_processed = pipeline.transform_data(X_test)\n",
    "study = pipeline.optimize_hyperparameters(X_train_processed, y_train)\n",
    "pipeline.train_final_model(X_train_processed, y_train)\n",
    "test_metrics = pipeline.evaluate_on_test(X_test_processed, y_test)\n",
    "feature_importance_df = pipeline.compute_feature_importance(X_train_processed, y_train)\n",
    "pipeline.save_artifacts(CONFIG.get('paths', {}).get('artifacts_dir', '../artifacts'))\n",
    "\n",
    "print(\"\\n✅ Pipeline completo executado com sucesso e sem vazamento de dados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ddd4c",
   "metadata": {},
   "source": [
    "## Fase 4.1: Análise de Performance Técnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "print(\"=== Métricas de Performance no Conjunto de Teste ===\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"- {metric.replace('_', ' ').title()}: {value:.4f}\")\n",
    "\n",
    "fig = px.bar(\n",
    "    feature_importance_df.head(20),\n",
    "    x='perm_importance',\n",
    "    y='feature',\n",
    "    orientation='h',\n",
    "    title='Top 20 Features Mais Importantes (Permutation Importance)'\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b194b89",
   "metadata": {},
   "source": [
    "## Fase 4.2: Análise de Métricas de Negócio (AML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ba1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOLVE: Métricas Insuficientes.\n",
    "# Traduzimos a performance do modelo (AUC, F1) em KPIs de negócio (custo, benefício).\n",
    "business_calculator = AMLBusinessMetrics(\n",
    "    fp_cost=CONFIG.get('metrics', {}).get('business_metrics', {}).get('cost_benefit_ratio', {}).get('fp_cost', 1),\n",
    "    fn_cost=CONFIG.get('metrics', {}).get('business_metrics', {}).get('cost_benefit_ratio', {}).get('fn_cost', 100)\n",
    ")\n",
    "y_test_proba = pipeline.calibrated_model.predict_proba(X_test_processed)[:, 1]\n",
    "business_optimal = business_calculator.find_optimal_threshold_business(y_test, y_test_proba)\n",
    "\n",
    "print(\"\\n=== Análise de Negócio com Threshold Otimizado ===\")\n",
    "if business_optimal:\n",
    "    print(f\"Threshold Ótimo para Negócio: {business_optimal['optimal_threshold']:.3f}\")\n",
    "    for metric, value in business_optimal['metrics'].items():\n",
    "        print(f\"- {metric.replace('_', ' ').title()}: {value:,.2f}\" if isinstance(value, float) else f\"- {metric.replace('_', ' ').title()}: {value:,}\")\n",
    "else:\n",
    "    print(\"Não foi possível encontrar threshold ótimo atendendo às constraints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21936acb",
   "metadata": {},
   "source": [
    "## Fase 5: Simulação de Monitoramento de Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf44ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOLVE: Ausência de Detecção de Drift.\n",
    "# Implementamos um sistema de alerta precoce para a degradação do modelo.\n",
    "drift_detector = ProductionDriftDetector(\n",
    "    reference_data=X_train_processed, \n",
    "    reference_labels=y_train\n",
    ")\n",
    "\n",
    "# 1. Simular drift de features\n",
    "new_data_sample = X_test_processed.sample(frac=0.5, random_state=CONFIG['data']['random_seed'])\n",
    "# Introduzir drift artificial para demonstração\n",
    "new_data_sample_drifted = new_data_sample.copy()\n",
    "\n",
    "# Seleciona as 5 primeiras colunas para aplicar o drift\n",
    "drift_cols = new_data_sample_drifted.columns[:5]\n",
    "for col in drift_cols:\n",
    "     new_data_sample_drifted[col] = new_data_sample_drifted[col] * np.random.uniform(1.5, 2.0, size=len(new_data_sample_drifted))\n",
    "\n",
    "drift_report = drift_detector.detect_feature_drift(new_data_sample_drifted)\n",
    "print(\"\\n=== Relatório de Detecção de Drift de Features (Dados Artificiais) ===\")\n",
    "print(f\"Drift detectado: {drift_report['has_drift']}\")\n",
    "print(f\"Percentual de features com drift: {drift_report['drift_percentage']:.2%}\")\n",
    "if drift_report['has_drift']:\n",
    "    print(f\"Features com drift: {drift_report['drifted_features']}\")\n",
    "\n",
    "# 2. Simular drift de performance\n",
    "y_test_sample = y_test.loc[new_data_sample.index]\n",
    "y_test_proba_sample = pipeline.calibrated_model.predict_proba(new_data_sample)[:, 1]\n",
    "\n",
    "performance_drift_report = drift_detector.detect_performance_drift(\n",
    "    y_true_new=y_test_sample,\n",
    "    y_pred_proba_new=y_test_proba_sample,\n",
    "    baseline_metrics=test_metrics\n",
    ")\n",
    "print(\"\\n=== Relatório de Detecção de Drift de Performance ===\")\n",
    "print(f\"Drift de performance detectado: {performance_drift_report['has_performance_drift']}\")\n",
    "print(f\"ROC AUC Baseline: {test_metrics['roc_auc']:.4f} | ROC AUC Atual: {performance_drift_report['current_roc_auc']:.4f}\")\n",
    "print(f\"Queda no ROC AUC: {performance_drift_report['roc_auc_drop']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ef3d8",
   "metadata": {},
   "source": [
    "## Fase 6: Benchmark com Modelos Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50815a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOLVE: Benchmark Inválido.\n",
    "# Comparamos o modelo otimizado contra baselines simples NO MESMO DATASET E PRÉ-PROCESSAMENTO,\n",
    "# o que nos dá uma medida real do \"uplift\" obtido.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "baseline_models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=CONFIG['data']['random_seed'], max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(random_state=CONFIG['data']['random_seed'], n_jobs=-1, n_estimators=100)\n",
    "}\n",
    "baseline_results = {}\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\"\\nTreinando baseline: {name}...\")\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    baseline_results[name] = {\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'pr_auc': average_precision_score(y_test, y_pred_proba),\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*30 + \" COMPARATIVO FINAL \" + \"=\"*30)\n",
    "print(f\"Modelo Otimizado (XGBoost):\")\n",
    "for k, v in test_metrics.items(): print(f\"  - {k}: {v:.4f}\")\n",
    "\n",
    "for name, metrics in baseline_results.items():\n",
    "    print(f\"\\nBaseline ({name}):\")\n",
    "    for k, v in metrics.items(): print(f\"  - {k}: {v:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Nota: Para incluir Multi-GNN como benchmark válido, seria necessário treinar no mesmo dataset.\n",
    "# Aqui focamos em baselines justas no mesmo setup para medir uplift real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a6cf7",
   "metadata": {},
   "source": [
    "## Fase 7.1: Análise de Incerteza das Predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ddcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOLVE: Falta de Quantificação de Incerteza.\n",
    "# Implementa classe para calcular intervalos de confiança das predições usando bootstrap.\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import numpy as np\n",
    "\n",
    "class ConfidenceCalibrator:\n",
    "    \"\"\"\n",
    "    Classe para quantificar incerteza das predições usando calibração isotônica\n",
    "    e bootstrap sampling para intervalos de confiança.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model, n_bootstrap=100, confidence_level=0.95):\n",
    "        self.base_model = base_model\n",
    "        self.n_bootstrap = n_bootstrap\n",
    "        self.confidence_level = confidence_level\n",
    "        self.calibrated_model = None\n",
    "        self.bootstrap_models = []\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Treina o calibrador usando calibração isotônica e bootstrap.\"\"\"\n",
    "        # Calibração isotônica para probabilidades confiáveis\n",
    "        self.calibrated_model = CalibratedClassifierCV(\n",
    "            self.base_model, method='isotonic', cv='prefit'\n",
    "        )\n",
    "        self.calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "        # Bootstrap para intervalos de confiança\n",
    "        np.random.seed(CONFIG['random_state'])\n",
    "        n_samples = len(X_train)\n",
    "        for _ in range(self.n_bootstrap):\n",
    "            indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_boot = X_train.iloc[indices] if hasattr(X_train, 'iloc') else X_train[indices]\n",
    "            y_boot = y_train.iloc[indices] if hasattr(y_train, 'iloc') else y_train[indices]\n",
    "\n",
    "            boot_model = clone(self.base_model)\n",
    "            boot_model.fit(X_boot, y_boot)\n",
    "            self.bootstrap_models.append(boot_model)\n",
    "\n",
    "    def predict_with_uncertainty(self, X):\n",
    "        \"\"\"Retorna predições com intervalos de confiança.\"\"\"\n",
    "        # Probabilidades calibradas\n",
    "        calibrated_probs = self.calibrated_model.predict_proba(X)[:, 1]\n",
    "\n",
    "        # Intervalos via bootstrap\n",
    "        bootstrap_probs = np.array([\n",
    "            model.predict_proba(X)[:, 1] for model in self.bootstrap_models\n",
    "        ])\n",
    "\n",
    "        lower_bound = np.percentile(bootstrap_probs,\n",
    "                                   (1 - self.confidence_level) / 2 * 100, axis=0)\n",
    "        upper_bound = np.percentile(bootstrap_probs,\n",
    "                                   (1 + self.confidence_level) / 2 * 100, axis=0)\n",
    "\n",
    "        return {\n",
    "            'probabilities': calibrated_probs,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound,\n",
    "            'uncertainty': upper_bound - lower_bound\n",
    "        }\n",
    "\n",
    "# Demonstração da análise de incerteza\n",
    "print(\"=== FASE 7.1: ANÁLISE DE INCERTEZA ===\")\n",
    "\n",
    "# Usa o modelo otimizado da Fase 3\n",
    "calibrator = ConfidenceCalibrator(pipeline.optimized_model, n_bootstrap=50)\n",
    "calibrator.fit(pipeline.X_train, pipeline.y_train)\n",
    "\n",
    "# Análise em dados de validação\n",
    "uncertainty_results = calibrator.predict_with_uncertainty(pipeline.X_val)\n",
    "\n",
    "print(f\"Número de predições analisadas: {len(uncertainty_results['probabilities'])}\")\n",
    "print(\".3f\")\n",
    "print(\".3f\")\n",
    "print(\".3f\")\n",
    "\n",
    "# Identifica predições de alta incerteza (possível drift ou casos edge)\n",
    "high_uncertainty_mask = uncertainty_results['uncertainty'] > np.percentile(uncertainty_results['uncertainty'], 90)\n",
    "print(f\"Predições com alta incerteza (>P90): {high_uncertainty_mask.sum()} casos\")\n",
    "print(\"Recomendação: Monitorar estes casos em produção para possível intervenção manual.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12740ad",
   "metadata": {},
   "source": [
    "## Fase 7.2: Benchmark de Latência vs. Precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOLVE: Falta de Benchmark de Latência.\n",
    "# Mede latência de inferência vs. precisão para diferentes configurações de modelo.\n",
    "\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import clone\n",
    "\n",
    "def benchmark_latency_vs_accuracy(model_template, X_train, y_train, X_test, y_test,\n",
    "                                param_values, param_name='n_estimators'):\n",
    "    \"\"\"\n",
    "    Benchmark trade-off entre latência e precisão para diferentes valores de parâmetro.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for param_val in param_values:\n",
    "        # Clona e configura modelo\n",
    "        model = clone(model_template)\n",
    "        setattr(model, param_name, param_val)\n",
    "\n",
    "        # Treina modelo\n",
    "        start_train = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_train\n",
    "\n",
    "        # Mede latência de inferência (média sobre múltiplas execuções)\n",
    "        n_runs = 100\n",
    "        inference_times = []\n",
    "        for _ in range(n_runs):\n",
    "            start_inf = time.time()\n",
    "            _ = model.predict_proba(X_test)\n",
    "            inference_times.append(time.time() - start_inf)\n",
    "\n",
    "        avg_inference_time = np.mean(inference_times) * 1000  # ms\n",
    "        std_inference_time = np.std(inference_times) * 1000\n",
    "\n",
    "        # Calcula AUC\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "        results.append({\n",
    "            param_name: param_val,\n",
    "            'auc': auc,\n",
    "            'train_time_sec': train_time,\n",
    "            'avg_inference_ms': avg_inference_time,\n",
    "            'std_inference_ms': std_inference_time\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Demonstração do benchmark\n",
    "print(\"=== FASE 7.2: BENCHMARK LATÊNCIA VS. PRECISÃO ===\")\n",
    "\n",
    "# Configurações para teste (valores reduzidos para demonstração)\n",
    "n_estimators_values = [10, 25, 50, 100, 200]\n",
    "\n",
    "# Usa XGBoost como base (modelo otimizado da Fase 3)\n",
    "base_model = pipeline.optimized_model\n",
    "\n",
    "# Executa benchmark\n",
    "benchmark_results = benchmark_latency_vs_accuracy(\n",
    "    base_model, pipeline.X_train, pipeline.y_train,\n",
    "    pipeline.X_test, pipeline.y_test, n_estimators_values\n",
    ")\n",
    "\n",
    "# Exibe resultados tabulares\n",
    "print(\"Resultados do Benchmark:\")\n",
    "print(\"n_estimators | AUC     | Train Time (s) | Inference (ms) | Std (ms)\")\n",
    "print(\"-\" * 65)\n",
    "for res in benchmark_results:\n",
    "    print(\"11.4f\")\n",
    "\n",
    "# Plot trade-off\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[r['avg_inference_ms'] for r in benchmark_results],\n",
    "    y=[r['auc'] for r in benchmark_results],\n",
    "    mode='lines+markers',\n",
    "    name='Trade-off',\n",
    "    text=[f\"n_estimators: {r['n_estimators']}\" for r in benchmark_results],\n",
    "    hovertemplate='Latência: %{x:.2f}ms<br>AUC: %{y:.4f}<br>%{text}'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Trade-off: Latência vs. Precisão (AUC)\",\n",
    "    xaxis_title=\"Tempo Médio de Inferência (ms)\",\n",
    "    yaxis_title=\"AUC Score\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Recomendação baseada no benchmark\n",
    "optimal_idx = np.argmax([r['auc'] - 0.01 * r['avg_inference_ms']/1000 for r in benchmark_results])  # Penaliza latência\n",
    "optimal_config = benchmark_results[optimal_idx]\n",
    "print(\"\n",
    "Configuração Otimizada Recomendada:\")\n",
    "print(f\"n_estimators: {optimal_config['n_estimators']}\")\n",
    "print(\".4f\")\n",
    "print(\".2f\")\n",
    "print(\"Esta configuração balanceia precisão e eficiência para produção.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32e04c",
   "metadata": {},
   "source": [
    "## Anexo: Integração do Multi-GNN como Benchmark de Referência\n",
    "\n",
    "O modelo **Multi-GNN** foi mencionado na Fase 6 como um benchmark de mercado, representando o estado da arte em detecção de fraude. No entanto, sua implementação não foi incluída diretamente neste notebook pelas seguintes razões:\n",
    "\n",
    "1.  **Estrutura de Dados Distinta**: GNNs operam sobre dados estruturados em grafos (nós e arestas), enquanto nosso pipeline atual é otimizado para dados tabulares. A integração exigiria uma etapa complexa de engenharia de features para construir o grafo, o que foge do escopo desta análise.\n",
    "\n",
    "2.  **Complexidade e Custo**: A implementação e o treinamento de GNNs são significativamente mais complexos e computacionalmente intensivos do que os modelos baseline (XGBoost, RandomForest).\n",
    "\n",
    "### Papel como Benchmark Conceitual\n",
    "\n",
    "O Multi-GNN serve como um **benchmark de performance teórica**. Ele define o teto de performance esperado para este problema. O objetivo do nosso pipeline é maximizar a eficiência e a robustez com uma abordagem tabular, buscando um resultado próximo ao do GNN, mas com menor custo e complexidade.\n",
    "\n",
    "### Roadmap para Integração Futura\n",
    "\n",
    "A arquitetura modular implementada neste notebook facilita a integração de novos modelos. Para incorporar o Multi-GNN no futuro, os seguintes passos seriam necessários:\n",
    "\n",
    "1.  **Módulo de Feature Engineering de Grafo**: Criar uma classe dedicada para transformar os dados tabulares em um formato de grafo.\n",
    "2.  **Wrapper de Modelo GNN**: Encapsular o modelo Multi-GNN em uma classe compatível com a API do `scikit-learn` (com métodos `.fit()` e `.predict_proba()`).\n",
    "3.  **Inclusão no Benchmark**: Adicionar o modelo GNN ao pipeline de benchmark da Fase 6 para uma comparação direta de performance, latência e custo computacional.\n",
    "\n",
    "Esta abordagem garante que, quando a complexidade adicional for justificada, o modelo possa ser integrado de forma estruturada e comparado de maneira justa com as soluções existentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
