{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0765b4",
   "metadata": {},
   "source": [
    "# 03 · Modelagem e Avaliação\n",
    "\n",
    "**Objetivo:** Implementar pipeline completo de treinamento e avaliação de modelos para detecção de transações suspeitas de lavagem de dinheiro.\n",
    "\n",
    "Este notebook executa o pipeline técnico de modelagem, incluindo:\n",
    "- Carregamento e pré-processamento de features\n",
    "- Validação temporal para evitar data leakage\n",
    "- Otimização de hiperparâmetros com Optuna + ASHA pruning\n",
    "- Calibração de probabilidades\n",
    "- Comparação objetiva com benchmark Multi-GNN\n",
    "- Salvamento de artefatos para notebooks downstream\n",
    "\n",
    "### Configuração Técnica\n",
    "- **Dados**: Features processadas do notebook 02\n",
    "- **Modelos**: XGBoost, LightGBM, RandomForest\n",
    "- **Validação**: Cross-validation temporal (5 folds)\n",
    "- **Otimização**: Optuna com ASHA pruning para eficiência\n",
    "- **Métricas**: ROC-AUC, PR-AUC, Precision@k, Recall@FPR\n",
    "- **Calibração**: Isotonic regression para probabilidades confiáveis\n",
    "\n",
    "### Pipeline de Execução\n",
    "1. Setup e configuração centralizada\n",
    "2. Carregamento e pré-processamento\n",
    "3. Validação temporal baseline\n",
    "4. Otimização ASHA para XGBoost e LightGBM\n",
    "5. Calibração e avaliação final\n",
    "6. Comparação com benchmark\n",
    "7. Salvamento de artefatos\n",
    "\n",
    "### Artefatos Gerados\n",
    "- Modelos otimizados e calibrados (`.pkl`)\n",
    "- Resultados de otimização ASHA (`.json`)\n",
    "- Métricas de calibração (`.json`)\n",
    "- Comparação com benchmark (`.json`)\n",
    "- Importância de features (`.json`)\n",
    "\n",
    "Para análises executivas e apresentações, consulte o notebook `06_Executive_Summary.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17aafa9",
   "metadata": {},
   "source": [
    "## ▸ Configuração Centralizada\n",
    "\n",
    "Centralizo todas as configurações do projeto para facilitar manutenção e reprodutibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfcc3369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-21 08:55:58,887 - __main__ - INFO - Logging estruturado configurado\n",
      "2025-10-21 08:55:58,887 - __main__ - INFO - Configuração centralizada carregada - Modo: Desenvolvimento\n",
      "2025-10-21 08:55:58,893 - __main__ - INFO - Versão do projeto: 1.0.0\n",
      "2025-10-21 08:55:58,895 - __main__ - INFO - Modo rápido: False\n",
      " Configuração centralizada implementada\n",
      " Projeto: AML_Detection_Pipeline v1.0.0\n",
      "2025-10-21 08:55:58,887 - __main__ - INFO - Configuração centralizada carregada - Modo: Desenvolvimento\n",
      "2025-10-21 08:55:58,893 - __main__ - INFO - Versão do projeto: 1.0.0\n",
      "2025-10-21 08:55:58,895 - __main__ - INFO - Modo rápido: False\n",
      " Configuração centralizada implementada\n",
      " Projeto: AML_Detection_Pipeline v1.0.0\n",
      " Modo: Desenvolvimento\n",
      " Modo rápido: False\n",
      " Logs salvos: True\n",
      " Modo: Desenvolvimento\n",
      " Modo rápido: False\n",
      " Logs salvos: True\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURAÇÃO CENTRALIZADA\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuração de logging estruturado\n",
    "def setup_structured_logging(log_level=logging.INFO, log_file=None):\n",
    "    \"\"\"Configura logging estruturado com timestamps e níveis apropriados.\"\"\"\n",
    "    if log_file is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        log_file = f\"../logs/notebook_03_{timestamp}.log\"\n",
    "\n",
    "    # Criar diretório de logs se não existir\n",
    "    Path(log_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Configuração do logger\n",
    "    logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"Logging estruturado configurado\")\n",
    "    return logger\n",
    "\n",
    "# Dicionário de configuração centralizada\n",
    "CONFIG = {\n",
    "    # === CONFIGURAÇÃO GERAL ===\n",
    "    'project_name': 'AML_Detection_Pipeline',\n",
    "    'version': '1.0.0',\n",
    "    'author': 'AML Team',\n",
    "    'description': 'Pipeline de detecção de lavagem de dinheiro com ML',\n",
    "\n",
    "    # === MODOS DE EXECUÇÃO ===\n",
    "    'execution_mode': {\n",
    "        'development': True,  # True para desenvolvimento, False para produção\n",
    "        'quick_mode': False,  # True para testes rápidos com subamostragem\n",
    "        'debug_mode': False,  # True para logs detalhados\n",
    "    },\n",
    "\n",
    "    # === CAMINHOS DE ARQUIVOS ===\n",
    "    'paths': {\n",
    "        'project_root': Path('..').resolve(),\n",
    "        'data_dir': Path('..') / 'data' / 'processed',\n",
    "        'artifacts_dir': Path('..') / 'artifacts',\n",
    "        'logs_dir': Path('..') / 'logs',\n",
    "        'models_dir': Path('..') / 'models',\n",
    "        'features_file': 'features_with_patterns.pkl',\n",
    "        'benchmark_metrics': 'gnn_benchmark_metrics.json',\n",
    "        'production_config': 'production_config.json',\n",
    "        'monitoring_config': 'monitoring_config.json',\n",
    "    },\n",
    "\n",
    "    # === PARÂMETROS DE DADOS ===\n",
    "    'data': {\n",
    "        'random_seed': 42,\n",
    "        'quick_sample_size': 50000,  # Tamanho da amostra para modo rápido\n",
    "        'temporal_splits': 5,  # Número de folds para validação temporal\n",
    "        'test_size_ratio': 0.2,  # Proporção de teste em cada fold\n",
    "    },\n",
    "\n",
    "    # === CONFIGURAÇÃO DE MODELOS ===\n",
    "    'models': {\n",
    "        'xgboost': {\n",
    "            'model_type': 'xgb',\n",
    "            'params': {\n",
    "                'n_estimators': 1000,\n",
    "                'max_depth': 5,\n",
    "                'learning_rate': 0.1,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'random_state': 42,\n",
    "                'eval_metric': 'auc',\n",
    "                'use_label_encoder': False,\n",
    "                'verbosity': 0,\n",
    "                'n_jobs': -1,\n",
    "                'tree_method': 'hist'\n",
    "            }\n",
    "        },\n",
    "        'lightgbm': {\n",
    "            'model_type': 'lgb',\n",
    "            'params': {\n",
    "                'n_estimators': 1000,\n",
    "                'max_depth': 6,\n",
    "                'learning_rate': 0.1,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'random_state': 42,\n",
    "                'verbosity': -1,\n",
    "                'metric': 'auc',\n",
    "                'n_jobs': 1,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'is_unbalance': True,\n",
    "                'min_child_samples': 20,\n",
    "                'min_child_weight': 1e-3,\n",
    "                'reg_alpha': 0.0,\n",
    "                'reg_lambda': 1.0,\n",
    "                'num_leaves': 31,\n",
    "                'bagging_freq': 1,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'feature_fraction': 0.8\n",
    "            }\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model_type': 'rf',\n",
    "            'params': {\n",
    "                'n_estimators': 80,\n",
    "                'max_depth': 10,\n",
    "                'min_samples_split': 10,\n",
    "                'min_samples_leaf': 5,\n",
    "                'random_state': 42,\n",
    "                'class_weight': 'balanced',\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # === HIPERPARÂMETROS DE OTIMIZAÇÃO ===\n",
    "    'optimization': {\n",
    "        'optuna_trials': 50,  # Número de trials do Optuna (modo dev) ou 1 (produção)\n",
    "        'early_stopping': {\n",
    "            'enabled': True,\n",
    "            'rounds': 20,\n",
    "            'metric': 'auc',\n",
    "            'min_delta': 0.001,\n",
    "            'max_rounds': 1000\n",
    "        },\n",
    "        'asha_pruning': True,  # Usar ASHA para pruning\n",
    "    },\n",
    "\n",
    "    # === MÉTRICAS E THRESHOLDS ===\n",
    "    'metrics': {\n",
    "        'primary_metrics': ['roc_auc', 'average_precision'],\n",
    "        'secondary_metrics': ['recall', 'precision', 'f1'],\n",
    "        'aml_thresholds': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "        'business_metrics': {\n",
    "            'cost_benefit_ratio': {'fp_cost': 1, 'fn_cost': 100},\n",
    "            'regulatory_requirements': {\n",
    "                'min_recall': 0.8,\n",
    "                'max_false_positive_rate': 0.05\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # === CALIBRAÇÃO ===\n",
    "    'calibration': {\n",
    "        'method': 'isotonic',  # 'isotonic' ou 'sigmoid'\n",
    "        'cv_folds': 5,\n",
    "        'evaluation_bins': 10,  # Para ECE\n",
    "    },\n",
    "\n",
    "    # === MONITORAMENTO E PRODUÇÃO ===\n",
    "    'production': {\n",
    "        'model_version': '1.0.0',\n",
    "        'retraining_frequency': 'weekly',  # daily, weekly, monthly\n",
    "        'drift_threshold': 0.1,\n",
    "        'performance_drop_threshold': 0.05,\n",
    "        'alert_channels': ['email', 'slack'],  # Canais de alerta\n",
    "    },\n",
    "\n",
    "    # === LOGGING ===\n",
    "    'logging': {\n",
    "        'level': 'INFO',  # DEBUG, INFO, WARNING, ERROR\n",
    "        'save_logs': True,\n",
    "        'log_performance_metrics': True,\n",
    "        'log_model_artifacts': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Aplicar configurações baseadas no modo\n",
    "if CONFIG['execution_mode']['development']:\n",
    "    CONFIG['optimization']['optuna_trials'] = 5  # Menos trials em desenvolvimento\n",
    "    CONFIG['logging']['level'] = 'DEBUG' if CONFIG['execution_mode']['debug_mode'] else 'INFO'\n",
    "else:\n",
    "    CONFIG['optimization']['optuna_trials'] = 1  # Trial único em produção\n",
    "    CONFIG['logging']['level'] = 'WARNING'\n",
    "\n",
    "# Configurar logging\n",
    "logger = setup_structured_logging(\n",
    "    log_level=getattr(logging, CONFIG['logging']['level']),\n",
    "    log_file=CONFIG['paths']['logs_dir'] / f\"notebook_03_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "    if CONFIG['logging']['save_logs'] else None\n",
    ")\n",
    "\n",
    "# Log da configuração inicial\n",
    "logger.info(f\"Configuração centralizada carregada - Modo: {'Desenvolvimento' if CONFIG['execution_mode']['development'] else 'Produção'}\")\n",
    "logger.info(f\"Versão do projeto: {CONFIG['version']}\")\n",
    "logger.info(f\"Modo rápido: {CONFIG['execution_mode']['quick_mode']}\")\n",
    "\n",
    "print(\" Configuração centralizada implementada\")\n",
    "print(f\" Projeto: {CONFIG['project_name']} v{CONFIG['version']}\")\n",
    "print(f\" Modo: {'Desenvolvimento' if CONFIG['execution_mode']['development'] else 'Produção'}\")\n",
    "print(f\" Modo rápido: {CONFIG['execution_mode']['quick_mode']}\")\n",
    "print(f\" Logs salvos: {CONFIG['logging']['save_logs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c7039e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-21 08:55:58,928 - __main__ - INFO - Verificando modo de execução...\n",
      "2025-10-21 08:55:58,931 - __main__ - INFO - Modo desenvolvimento: trials Optuna reduzidos, validação rápida\n",
      "2025-10-21 08:55:58,931 - __main__ - INFO - Modo desenvolvimento: trials Optuna reduzidos, validação rápida\n",
      "2025-10-21 08:55:58,933 - __main__ - INFO - Modo completo: todas as amostras\n",
      "2025-10-21 08:55:58,937 - __main__ - INFO - Modo normal: logging informativo\n",
      "2025-10-21 08:55:58,940 - __main__ - INFO - Controle de execução configurado\n",
      "2025-10-21 08:55:58,933 - __main__ - INFO - Modo completo: todas as amostras\n",
      "2025-10-21 08:55:58,937 - __main__ - INFO - Modo normal: logging informativo\n",
      "2025-10-21 08:55:58,940 - __main__ - INFO - Controle de execução configurado\n",
      " Controle de execução condicional implementado\n",
      " Modo: Desenvolvimento\n",
      " Modo rápido: False\n",
      " Modo debug: False\n",
      " Controle de execução condicional implementado\n",
      " Modo: Desenvolvimento\n",
      " Modo rápido: False\n",
      " Modo debug: False\n"
     ]
    }
   ],
   "source": [
    "# CONTROLE DE EXECUÇÃO CONDICIONAL (baseado em CONFIG)\n",
    "import sys\n",
    "\n",
    "logger.info(\"Verificando modo de execução...\")\n",
    "\n",
    "# Modos de execução baseados em CONFIG\n",
    "EXECUTION_MODE = {\n",
    "    'development': CONFIG['execution_mode']['development'],\n",
    "    'quick_mode': CONFIG['execution_mode']['quick_mode'],\n",
    "    'debug_mode': CONFIG['execution_mode']['debug_mode']\n",
    "}\n",
    "\n",
    "# Configurações baseadas no modo\n",
    "if EXECUTION_MODE['development']:\n",
    "    OPTUNA_TRIALS = CONFIG['optimization']['optuna_trials']\n",
    "    CV_FOLDS = 3  # Menos folds em desenvolvimento\n",
    "    logger.info(\"Modo desenvolvimento: trials Optuna reduzidos, validação rápida\")\n",
    "else:\n",
    "    OPTUNA_TRIALS = 1  # Trial único em produção\n",
    "    CV_FOLDS = CONFIG['data']['temporal_splits']\n",
    "    logger.info(\"Modo produção: otimização completa\")\n",
    "\n",
    "if EXECUTION_MODE['quick_mode']:\n",
    "    SAMPLE_SIZE = CONFIG['data']['quick_sample_size']\n",
    "    logger.info(f\"Modo rápido ativado: {SAMPLE_SIZE:,} amostras\")\n",
    "else:\n",
    "    SAMPLE_SIZE = None\n",
    "    logger.info(\"Modo completo: todas as amostras\")\n",
    "\n",
    "if EXECUTION_MODE['debug_mode']:\n",
    "    logging.getLogger().setLevel(logging.DEBUG)\n",
    "    logger.info(\"Modo debug ativado: logging detalhado\")\n",
    "else:\n",
    "    logger.info(\"Modo normal: logging informativo\")\n",
    "\n",
    "# Função para controle condicional\n",
    "def should_execute_section(section_name, force=False):\n",
    "    \"\"\"\n",
    "    Decide se uma seção deve ser executada baseado no modo.\n",
    "\n",
    "    Args:\n",
    "        section_name: Nome da seção\n",
    "        force: Forçar execução independente do modo\n",
    "\n",
    "    Returns:\n",
    "        bool: True se deve executar\n",
    "    \"\"\"\n",
    "    if force:\n",
    "        return True\n",
    "\n",
    "    # Em modo desenvolvimento, executar apenas seções essenciais\n",
    "    if EXECUTION_MODE['development']:\n",
    "        essential_sections = ['setup', 'data_loading', 'preprocessing', 'validation', 'baseline']\n",
    "        return section_name in essential_sections\n",
    "\n",
    "    # Em modo produção, executar tudo\n",
    "    return True\n",
    "\n",
    "logger.info(\"Controle de execução configurado\")\n",
    "print(\" Controle de execução condicional implementado\")\n",
    "print(f\" Modo: {'Desenvolvimento' if EXECUTION_MODE['development'] else 'Produção'}\")\n",
    "print(f\" Modo rápido: {EXECUTION_MODE['quick_mode']}\")\n",
    "print(f\" Modo debug: {EXECUTION_MODE['debug_mode']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c929aa36",
   "metadata": {},
   "source": [
    "## ▸ Carregamento dos Dados\n",
    "\n",
    "Carrego as features processadas do notebook anterior, com opção de modo rápido integrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81485988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados carregados: 5,078,336 transações\n",
      " Features: 51 | Fraude: 0.102%\n",
      "\n",
      " Features: 51 | Fraude: 0.102%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      from_bank  to_bank  amount_received    amount  Bank ID  Bank ID_to  \\\n",
       " 3437         70       10          1064.04   1064.04       70          10   \n",
       " 3878         70     1047         33647.60  33647.60       70        1047   \n",
       " 4118         70     1292         14777.01  14777.01       70        1292   \n",
       " 5612         70    11471          6117.78   6117.78       70       11471   \n",
       " 6266         70    11107         16561.46  16561.46       70       11107   \n",
       " \n",
       "       hour_x  hour_y  source_amount_sum_7d  source_amount_mean_7d  ...  \\\n",
       " 3437       0       0           54015486.75           1.385012e+06  ...   \n",
       " 3878       0       0           53957155.57           1.586975e+06  ...   \n",
       " 4118       0       0           53916860.66           1.739254e+06  ...   \n",
       " 5612       0       0               7661.17           2.553723e+03  ...   \n",
       " 6266       0       0           49486451.73           2.474323e+06  ...   \n",
       " \n",
       "       from_bank_frequency  from_bank_is_rare  to_bank_frequency  \\\n",
       " 3437             0.088584                  0           0.008378   \n",
       " 3878             0.088584                  0           0.001919   \n",
       " 4118             0.088584                  0           0.002781   \n",
       " 5612             0.088584                  0           0.001724   \n",
       " 6266             0.088584                  0           0.001759   \n",
       " \n",
       "       to_bank_is_rare  same_bank_transfer  rolling_amount_mean_3  \\\n",
       " 3437                1                   0                    NaN   \n",
       " 3878                1                   0                    NaN   \n",
       " 4118                1                   0           16496.216667   \n",
       " 5612                1                   0           18180.796667   \n",
       " 6266                1                   0           12485.416667   \n",
       " \n",
       "       rolling_amount_std_3  amount_cv_3  fan_out_degree  fan_in_degree  \n",
       " 3437                   NaN          NaN           14230              4  \n",
       " 3878                   NaN          NaN           14230              2  \n",
       " 4118          16359.671428     0.991723           14230              2  \n",
       " 5612          14077.005010     0.774279           14230              4  \n",
       " 6266           5586.247666     0.447422           14230              5  \n",
       " \n",
       " [5 rows x 51 columns],\n",
       " is_fraud\n",
       " 0    5073159\n",
       " 1       5177\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARREGAMENTO DOS DADOS (usando CONFIG centralizado)\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configurar modo rápido baseado em CONFIG\n",
    "RUN_QUICK = CONFIG['execution_mode']['quick_mode']\n",
    "\n",
    "# Caminhos usando CONFIG\n",
    "data_dir = CONFIG['paths']['data_dir']\n",
    "features_pkl = data_dir / CONFIG['paths']['features_file']\n",
    "\n",
    "logger.info(f\"Carregando dados de: {features_pkl}\")\n",
    "logger.info(f\"Modo rápido: {RUN_QUICK}\")\n",
    "\n",
    "# Carregar dados processados\n",
    "try:\n",
    "    df = pd.read_pickle(features_pkl)\n",
    "    # Separar features e target\n",
    "    y = df['is_fraud']\n",
    "    X = df.drop('is_fraud', axis=1)\n",
    "\n",
    "    # Selecionar apenas colunas numéricas\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    X = X[numeric_cols]\n",
    "\n",
    "    # Modo rápido (opcional)\n",
    "    if RUN_QUICK:\n",
    "        sample_size = CONFIG['data']['quick_sample_size']\n",
    "        indices = np.random.choice(len(X), sample_size, replace=False)\n",
    "        X = X.iloc[indices].reset_index(drop=True)\n",
    "        y = y.iloc[indices].reset_index(drop=True)\n",
    "        logger.info(f\"Amostra reduzida para {sample_size:,} registros\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao carregar dados: {e}\")\n",
    "    raise\n",
    "\n",
    "# Verificação visual e logging\n",
    "logger.info(f\"Dataset carregado: {len(X):,} transações × {X.shape[1]} features\")\n",
    "logger.info(f\"Taxa de fraude: {y.mean():.3%}\")\n",
    "\n",
    "print(f\" Dados carregados: {len(X):,} transações\")\n",
    "print(f\" Features: {X.shape[1]} | Fraude: {y.mean():.3%}\")\n",
    "X.head(), y.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
