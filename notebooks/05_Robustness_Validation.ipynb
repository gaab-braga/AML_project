{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79e62bd",
   "metadata": {},
   "source": [
    "# Valida√ß√£o de Robustez - Modelos AML\n",
    "\n",
    "Este notebook realiza testes de robustez dos modelos de detec√ß√£o de AML em diferentes cen√°rios futuros e an√°lise de concept drift.\n",
    "\n",
    "## Objetivos\n",
    "- Testar modelos em cen√°rios sint√©ticos de stress\n",
    "- Avaliar sensibilidade a concept drift\n",
    "- Simular ataques adversariais\n",
    "- Identificar vulnerabilidades e pontos de melhoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edff40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURA√á√ÉO INICIAL\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Adicionar diret√≥rio raiz ao path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, precision_score, recall_score\n",
    "\n",
    "# Configura√ß√µes\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Diret√≥rios\n",
    "artifacts_dir = project_root / 'artifacts'\n",
    "artifacts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Diret√≥rio de artefatos: {artifacts_dir}\")\n",
    "print(f\"Python path configurado: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a1886",
   "metadata": {},
   "source": [
    "## Carregamento dos Dados e Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR DADOS PROCESSADOS\n",
    "print(\"Carregando dados processados...\")\n",
    "\n",
    "# Carregar features\n",
    "features_path = artifacts_dir / 'X_processed.csv'\n",
    "X = pd.read_csv(features_path)\n",
    "print(f\"Features carregadas: {X.shape}\")\n",
    "\n",
    "# Carregar target\n",
    "target_path = artifacts_dir / 'y_processed.csv'\n",
    "y = pd.read_csv(target_path).iloc[:, 0]\n",
    "print(f\"Target carregado: {len(y)} amostras\")\n",
    "\n",
    "# Verificar consist√™ncia\n",
    "assert len(X) == len(y), \"Inconsist√™ncia entre features e target\"\n",
    "print(f\"Taxa de fraude: {y.mean():.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc148598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR MODELOS OTIMIZADOS\n",
    "models = {}\n",
    "model_names = ['XGBoost', 'LightGBM', 'RandomForest', 'Ensemble']\n",
    "\n",
    "for name in model_names:\n",
    "    try:\n",
    "        model_path = artifacts_dir / f'{name.lower()}_extended.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            models[name] = pickle.load(f)\n",
    "        print(f\"‚úÖ {name} carregado\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar {name}: {e}\")\n",
    "\n",
    "print(f\"\\nModelos carregados: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb0949",
   "metadata": {},
   "source": [
    "## Cria√ß√£o de Cen√°rios de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ec8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CEN√ÅRIOS DE TESTE DE ROBUSTEZ\n",
    "scenarios = {\n",
    "    'baseline': X.copy(),  # Cen√°rio normal\n",
    "    'fraud_increase': None,  # Ser√° criado\n",
    "    'value_shift': None,    # Ser√° criado\n",
    "    'noisy_data': None,     # Ser√° criado\n",
    "    'missing_data': None    # Ser√° criado\n",
    "}\n",
    "\n",
    "print(\"üîÆ CRIANDO CEN√ÅRIOS DE TESTE...\")\n",
    "\n",
    "# Cen√°rio 1: Aumento da taxa de fraude\n",
    "fraud_increase = X.copy()\n",
    "fraud_indices = y[y == 1].index\n",
    "additional_fraud = X.loc[fraud_indices].sample(frac=0.5, replace=True)\n",
    "additional_fraud_y = pd.Series([1] * len(additional_fraud), index=additional_fraud.index)\n",
    "fraud_increase = pd.concat([fraud_increase, additional_fraud])\n",
    "fraud_increase_y = pd.concat([y, additional_fraud_y])\n",
    "scenarios['fraud_increase'] = (fraud_increase, fraud_increase_y)\n",
    "\n",
    "# Cen√°rio 2: Mudan√ßa nos valores das transa√ß√µes\n",
    "value_shift = X.copy()\n",
    "numeric_cols = value_shift.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols = [col for col in numeric_cols if col != 'is_fraud']\n",
    "for col in numeric_cols:\n",
    "    if 'amount' in col.lower():\n",
    "        value_shift[col] = value_shift[col] * 1.2  # Aumento de 20%\n",
    "scenarios['value_shift'] = (value_shift, y)\n",
    "\n",
    "# Cen√°rio 3: Dados com ru√≠do\n",
    "noisy_data = X.copy()\n",
    "for col in numeric_cols:\n",
    "    noise = np.random.normal(0, noisy_data[col].std() * 0.1, len(noisy_data))\n",
    "    noisy_data[col] = noisy_data[col] + noise\n",
    "scenarios['noisy_data'] = (noisy_data, y)\n",
    "\n",
    "# Cen√°rio 4: Dados com missing values\n",
    "missing_data = X.copy()\n",
    "for col in missing_data.columns:\n",
    "    if col != 'is_fraud':\n",
    "        mask = np.random.random(len(missing_data)) < 0.05  # 5% missing\n",
    "        missing_data.loc[mask, col] = np.nan\n",
    "\n",
    "# Imputa√ß√£o simples (mediana)\n",
    "for col in numeric_cols:\n",
    "    median_val = missing_data[col].median()\n",
    "    missing_data[col] = missing_data[col].fillna(median_val)\n",
    "scenarios['missing_data'] = (missing_data, y)\n",
    "\n",
    "print(\"   ‚úÖ Cen√°rios criados:\")\n",
    "for name, data in scenarios.items():\n",
    "    if data is not None:\n",
    "        if isinstance(data, tuple):\n",
    "            X_scenario, y_scenario = data\n",
    "            fraud_rate = y_scenario.mean()\n",
    "            print(f\"      ‚Ä¢ {name}: {len(X_scenario):,} amostras ({fraud_rate:.3%} fraud)\")\n",
    "        else:\n",
    "            print(f\"      ‚Ä¢ {name}: {len(data):,} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426bc205",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o de Robustez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVALIA√á√ÉO DE ROBUSTEZ DOS MODELOS\n",
    "print(\"üõ°Ô∏è AVALIANDO ROBUSTEZ DOS MODELOS...\")\n",
    "\n",
    "robustness_results = {}\n",
    "\n",
    "for scenario_name, scenario_data in scenarios.items():\n",
    "    if scenario_data is None:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüîç Testando cen√°rio: {scenario_name}\")\n",
    "\n",
    "    if isinstance(scenario_data, tuple):\n",
    "        X_scenario, y_scenario = scenario_data\n",
    "    else:\n",
    "        X_scenario, y_scenario = scenario_data, y\n",
    "\n",
    "    # Limitar tamanho para avalia√ß√£o r√°pida\n",
    "    if len(X_scenario) > 50000:\n",
    "        sample_indices = np.random.choice(len(X_scenario), 50000, replace=False)\n",
    "        X_scenario = X_scenario.iloc[sample_indices]\n",
    "        y_scenario = y_scenario.iloc[sample_indices]\n",
    "\n",
    "    scenario_results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            # Fazer predi√ß√µes\n",
    "            y_pred_proba = model.predict_proba(X_scenario)[:, 1]\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "            # Calcular m√©tricas\n",
    "            precision = precision_score(y_scenario, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_scenario, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_scenario, y_pred, zero_division=0)\n",
    "\n",
    "            precision_curve, recall_curve, _ = precision_recall_curve(y_scenario, y_pred_proba)\n",
    "            pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "            scenario_results[model_name] = {\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'pr_auc': pr_auc,\n",
    "                'test_samples': len(y_scenario),\n",
    "                'fraud_cases': y_scenario.sum()\n",
    "            }\n",
    "\n",
    "            print(f\"     üìä {model_name}: F1={f1:.4f}, PR-AUC={pr_auc:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"     ‚ùå Erro em {model_name}: {e}\")\n",
    "            scenario_results[model_name] = {'error': str(e)}\n",
    "\n",
    "    robustness_results[scenario_name] = scenario_results\n",
    "\n",
    "print(f\"\\nCen√°rios testados: {len(robustness_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100dc44",
   "metadata": {},
   "source": [
    "## An√°lise de Concept Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b16f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AN√ÅLISE DE CONCEPT DRIFT\n",
    "print(\"üåä AN√ÅLISE DE CONCEPT DRIFT\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Usar o cen√°rio baseline (X, y originais)\n",
    "baseline_X, baseline_y = X, y\n",
    "baseline_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    try:\n",
    "        y_pred_proba = model.predict_proba(baseline_X)[:, 1]\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(baseline_y, y_pred_proba)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "        f1 = f1_score(baseline_y, y_pred)\n",
    "\n",
    "        baseline_results[model_name] = {\n",
    "            'pr_auc': pr_auc,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "    except Exception as e:\n",
    "        baseline_results[model_name] = {'error': str(e)}\n",
    "\n",
    "# Comparar cen√°rios vs baseline\n",
    "drift_analysis = {\n",
    "    'baseline_performance': baseline_results,\n",
    "    'drift_indicators': {},\n",
    "    'vulnerabilities': []\n",
    "}\n",
    "\n",
    "for scenario_name, scenario_results in robustness_results.items():\n",
    "    if scenario_name == 'baseline':\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüîÑ Comparando {scenario_name} vs baseline:\")\n",
    "\n",
    "    scenario_drift = {}\n",
    "\n",
    "    for model_name in baseline_results.keys():\n",
    "        if model_name in scenario_results and 'error' not in scenario_results[model_name]:\n",
    "            baseline_metrics = baseline_results[model_name]\n",
    "            scenario_metrics = scenario_results[model_name]\n",
    "\n",
    "            # Calcular diferen√ßas percentuais\n",
    "            pr_auc_diff = (scenario_metrics['pr_auc'] - baseline_metrics['pr_auc']) / baseline_metrics['pr_auc'] * 100\n",
    "            f1_diff = (scenario_metrics['f1_score'] - baseline_metrics['f1_score']) / baseline_metrics['f1_score'] * 100\n",
    "\n",
    "            scenario_drift[model_name] = {\n",
    "                'pr_auc_change_percent': pr_auc_diff,\n",
    "                'f1_change_percent': f1_diff,\n",
    "                'baseline_pr_auc': baseline_metrics['pr_auc'],\n",
    "                'scenario_pr_auc': scenario_metrics['pr_auc']\n",
    "            }\n",
    "\n",
    "            print(f\"     üìä {model_name}: PR-AUC {pr_auc_diff:+.1f}%, F1 {f1_diff:+.1f}%\")\n",
    "\n",
    "            # Identificar vulnerabilidades\n",
    "            if abs(pr_auc_diff) > 10:  # Mudan√ßa > 10%\n",
    "                severity = 'high' if abs(pr_auc_diff) > 20 else 'medium'\n",
    "                drift_analysis['vulnerabilities'].append({\n",
    "                    'scenario': scenario_name,\n",
    "                    'model': model_name,\n",
    "                    'metric': 'pr_auc',\n",
    "                    'change_percent': pr_auc_diff,\n",
    "                    'severity': severity\n",
    "                })\n",
    "\n",
    "    drift_analysis['drift_indicators'][scenario_name] = scenario_drift\n",
    "\n",
    "print(f\"\\nVulnerabilidades identificadas: {len(drift_analysis['vulnerabilities'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d8f5a8",
   "metadata": {},
   "source": [
    "## Simula√ß√£o de Ataques Adversariais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df172639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULA√á√ÉO DE ATAQUES ADVERSARIAIS\n",
    "print(\"üéØ SIMULA√á√ÉO DE ATAQUES ADVERSARIAIS\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "attack_results = {}\n",
    "\n",
    "# Usar uma amostra menor para ataques\n",
    "sample_size = min(10000, len(X))\n",
    "sample_indices = np.random.choice(len(X), sample_size, replace=False)\n",
    "X_attack = X.iloc[sample_indices]\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"   üîÑ Testando ataques em {model_name}...\")\n",
    "\n",
    "    try:\n",
    "        # Ataque: Feature perturbation\n",
    "        X_perturbed = X_attack.copy()\n",
    "        numeric_cols = X_perturbed.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "        # Identificar features importantes (simplificado - top 5)\n",
    "        important_features = numeric_cols[:5]  # Simplificado\n",
    "\n",
    "        # Adicionar ru√≠do direcionado\n",
    "        for col in important_features:\n",
    "            if col in numeric_cols:\n",
    "                noise = np.random.normal(0, X_perturbed[col].std() * 0.5, len(X_perturbed))\n",
    "                X_perturbed[col] = X_perturbed[col] + noise\n",
    "\n",
    "        # Avaliar impacto\n",
    "        y_pred_original = model.predict_proba(X_attack)[:, 1]\n",
    "        y_pred_perturbed = model.predict_proba(X_perturbed)[:, 1]\n",
    "\n",
    "        pred_diff = np.abs(y_pred_original - y_pred_perturbed)\n",
    "        avg_diff = pred_diff.mean()\n",
    "        stability = 1 - avg_diff\n",
    "\n",
    "        attack_results[model_name] = {\n",
    "            'perturbation_attack': {\n",
    "                'avg_prediction_change': avg_diff,\n",
    "                'max_prediction_change': pred_diff.max(),\n",
    "                'prediction_stability': stability\n",
    "            }\n",
    "        }\n",
    "\n",
    "        print(f\"     üìä Ataque de perturba√ß√£o: mudan√ßa m√©dia = {avg_diff:.4f}, estabilidade = {stability:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"     ‚ùå Erro no ataque para {model_name}: {e}\")\n",
    "        attack_results[model_name] = {'error': str(e)}\n",
    "\n",
    "print(f\"\\nModelos testados contra ataques: {len(attack_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa527a",
   "metadata": {},
   "source": [
    "## Relat√≥rio de Robustez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ed9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GERAR RELAT√ìRIO DE ROBUSTEZ\n",
    "print(\"üìã GERANDO RELAT√ìRIO DE ROBUSTEZ...\")\n",
    "\n",
    "robustness_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'phase': 'Valida√ß√£o de Robustez',\n",
    "    'scenarios_tested': list(robustness_results.keys()),\n",
    "    'robustness_results': robustness_results,\n",
    "    'concept_drift_analysis': drift_analysis,\n",
    "    'adversarial_attacks': attack_results,\n",
    "    'key_findings': {\n",
    "        'overall_robustness': 'Modelos mostram robustez vari√°vel por cen√°rio',\n",
    "        'vulnerabilities_identified': len(drift_analysis.get('vulnerabilities', [])),\n",
    "        'most_robust_model': None,  # Ser√° determinado\n",
    "        'drift_sensitivity': 'An√°lise de sensibilidade a concept drift realizada'\n",
    "    },\n",
    "    'recommendations': {\n",
    "        'monitoring': [\n",
    "            'Implementar monitoramento cont√≠nuo de performance',\n",
    "            'Alertas autom√°ticos para degrada√ß√£o de performance',\n",
    "            'Re-treinamento peri√≥dico baseado em thresholds',\n",
    "            'Valida√ß√£o cruzada temporal em produ√ß√£o'\n",
    "        ],\n",
    "        'robustness_improvements': [\n",
    "            'Considerar ensemble methods para maior robustez',\n",
    "            'Implementar detec√ß√£o de concept drift',\n",
    "            'Adicionar valida√ß√£o de entrada de dados',\n",
    "            'Desenvolver estrat√©gias de fallback'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Determinar modelo mais robusto\n",
    "if robustness_results:\n",
    "    baseline = robustness_results.get('baseline', {})\n",
    "    if baseline:\n",
    "        model_stability = {}\n",
    "        for model_name in baseline_results.keys():\n",
    "            stability_scores = []\n",
    "            for scenario_name, scenario_results in robustness_results.items():\n",
    "                if scenario_name != 'baseline' and model_name in scenario_results:\n",
    "                    scenario_metrics = scenario_results[model_name]\n",
    "                    baseline_metrics = baseline_results[model_name]\n",
    "                    if 'pr_auc' in scenario_metrics and 'pr_auc' in baseline_metrics:\n",
    "                        stability = 1 - abs(scenario_metrics['pr_auc'] - baseline_metrics['pr_auc'])\n",
    "                        stability_scores.append(stability)\n",
    "\n",
    "            if stability_scores:\n",
    "                model_stability[model_name] = np.mean(stability_scores)\n",
    "\n",
    "        if model_stability:\n",
    "            most_robust = max(model_stability.items(), key=lambda x: x[1])\n",
    "            robustness_report['key_findings']['most_robust_model'] = most_robust[0]\n",
    "\n",
    "# Salvar relat√≥rio\n",
    "with open(artifacts_dir / 'robustness_analysis_notebook.json', 'w') as f:\n",
    "    json.dump(robustness_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"   üíæ Relat√≥rio salvo: {artifacts_dir / 'robustness_analysis_notebook.json'}\")\n",
    "\n",
    "# Resumo executivo\n",
    "print(\"\\nüõ°Ô∏è RESUMO EXECUTIVO - VALIDA√á√ÉO DE ROBUSTEZ:\")\n",
    "print(\"   üõ°Ô∏è TESTES DE ROBUSTEZ CONCLU√çDOS:\")\n",
    "print(f\"   ‚Ä¢ Cen√°rios testados: {len(robustness_results)}\")\n",
    "print(\"   ‚Ä¢ An√°lise de concept drift: Realizada\")\n",
    "print(\"   ‚Ä¢ Ataques adversariais: Simulados\")\n",
    "\n",
    "vulnerabilities = len(drift_analysis.get('vulnerabilities', []))\n",
    "if vulnerabilities > 0:\n",
    "    print(f\"   ‚ö†Ô∏è Vulnerabilidades identificadas: {vulnerabilities}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Nenhuma vulnerabilidade cr√≠tica identificada\")\n",
    "\n",
    "most_robust = robustness_report['key_findings'].get('most_robust_model')\n",
    "if most_robust:\n",
    "    print(f\"   üèÜ Modelo mais robusto: {most_robust}\")\n",
    "\n",
    "print(\"\\nüí° PR√ìXIMAS A√á√ïES RECOMENDADAS:\")\n",
    "print(\"   1. Implementar monitoramento cont√≠nuo de performance\")\n",
    "print(\"   2. Configurar alertas para degrada√ß√£o de m√©tricas\")\n",
    "print(\"   3. Preparar estrat√©gias de re-treinamento\")\n",
    "print(\"   4. Finalizar documenta√ß√£o e reprodutibilidade\")\n",
    "\n",
    "print(\"\\n‚úÖ VALIDA√á√ÉO DE ROBUSTEZ CONCLU√çDA!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
