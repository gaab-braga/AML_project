{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b88779d",
   "metadata": {},
   "source": [
    "# Roadmap Detalhado para Implementação do Multi-GNN\n",
    "\n",
    "**Análise**: A pesquisa no repositório `IBM/multi-gnn` e a análise dos scripts `test_benchmark_improved.py` e `test_benchmark_integration.py` revelam que o processo de benchmark já foi parcialmente explorado. O principal desafio é a complexidade do ambiente (PyTorch Geometric no Windows) e a necessidade de adaptar o código original para gerar artefatos de predição, em vez de apenas métricas de F1-Score.\n",
    "\n",
    "Este notebook serve como um guia passo a passo para implementar, treinar e extrair predições do modelo Multi-GNN.\n",
    "\n",
    "---\n",
    "\n",
    "## Fase 0: Ambiente e Pré-requisitos\n",
    "\n",
    "**Problema**: O Multi-GNN depende de bibliotecas (torch-scatter, torch-sparse) que são notoriamente difíceis de instalar e usar diretamente no Windows. O script `test_benchmark_improved.py` corretamente identifica isso.\n",
    "\n",
    "**Solução**: Usar o **Windows Subsystem for Linux (WSL2)**. Ele permite executar um ambiente Linux diretamente no Windows, eliminando todos os problemas de compatibilidade.\n",
    "\n",
    "### Ações:\n",
    "1.  **Instale o WSL2**: Se ainda não o tiver, abra o PowerShell como administrador e execute:\n",
    "    ```bash\n",
    "    wsl --install\n",
    "    ```\n",
    "2.  **Clone o Repositório no WSL2**: Navegue até o diretório do seu projeto dentro do WSL2 (ex: `/mnt/c/Users/gafeb/AML_project`) e execute os comandos a partir daí.\n",
    "3.  **Crie o Ambiente Conda**: O repositório `benchmarks/Multi-GNN` já deve conter o arquivo `env.yml`. Crie o ambiente com o comando:\n",
    "    ```bash\n",
    "    conda env create -f benchmarks/Multi-GNN/env.yml\n",
    "    ```\n",
    "4.  **Ative o Ambiente**:\n",
    "    ```bash\n",
    "    conda activate multignn\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf6421",
   "metadata": {},
   "source": [
    "## Fase 1: Preparação dos Dados\n",
    "\n",
    "O Multi-GNN requer um formato de dados específico. O script `format_kaggle_files.py` é responsável por essa conversão.\n",
    "\n",
    "### Ações:\n",
    "1.  **Baixe os Dados**: Faça o download dos dados do [Kaggle](https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/data) e coloque o arquivo `HI-Small_Trans.csv` na pasta `data/raw/`.\n",
    "2.  **Execute o Script de Formatação**: Dentro do ambiente `multignn` no WSL2, execute:\n",
    "    ```bash\n",
    "    python benchmarks/Multi-GNN/format_kaggle_files.py data/raw/HI-Small_Trans.csv\n",
    "    ```\n",
    "    Isso criará um arquivo `formatted_transactions.csv` no mesmo diretório.\n",
    "3.  **Configure o `data_config.json`**: Este arquivo é crucial. Ele informa ao `main.py` onde encontrar os dados.\n",
    "    -   **Mova** o `formatted_transactions.csv` para uma pasta dedicada, por exemplo: `data/processed/multi-gnn/Small_HI/`.\n",
    "    -   **Abra** o arquivo `benchmarks/Multi-GNN/data_config.json`.\n",
    "    -   **Atualize** o caminho em `aml_data` para apontar para o diretório que você criou (ex: `\"aml_data\": \"data/processed/multi-gnn/\"`).\n",
    "\n",
    "---\n",
    "\n",
    "## Fase 2: Estrutura do Grafo (Análise)\n",
    "\n",
    "Não há ação de codificação aqui, mas é importante entender como o grafo é construído. O script `data_loading.py` do repositório da IBM:\n",
    "-   Lê o `formatted_transactions.csv`.\n",
    "-   Cria **nós** para cada conta (`from_id`, `to_id`).\n",
    "-   Cria **arestas** para cada transação.\n",
    "-   Adiciona **features de aresta**, como `Timestamp` e `Amount`.\n",
    "\n",
    "---\n",
    "\n",
    "## Fase 3: Treinamento do Modelo\n",
    "\n",
    "Com o ambiente e os dados prontos, podemos treinar o modelo.\n",
    "\n",
    "### Ação:\n",
    "1.  **Execute o Treinamento**: Use o comando abaixo no WSL2. Ele é derivado do `test_benchmark_improved.py`, mas simplificado.\n",
    "    ```bash\n",
    "    python benchmarks/Multi-GNN/main.py --data Small_HI --model gin --emlps --reverse_mp --testing --n_epochs 5\n",
    "    ```\n",
    "    -   `--data Small_HI`: Corresponde ao nome da pasta dos dados.\n",
    "    -   `--model gin`: Usa o modelo GIN, um dos mais eficazes.\n",
    "    -   `--emlps --reverse_mp`: Adaptações do modelo que melhoram a performance.\n",
    "    -   `--testing`: **Importante**: Desabilita o logging no `wandb`, evitando a necessidade de configuração de API.\n",
    "    -   `--n_epochs 5`: Apenas 5 épocas para um teste rápido. Aumente para 50-100 para um treinamento completo.\n",
    "\n",
    "---\n",
    "\n",
    "## Fase 4: Geração de Artefatos (Modificação Essencial)\n",
    "\n",
    "**Problema**: O código original da IBM foi feito para pesquisa e apenas imprime o F1-Score. Ele **não salva as predições**, que é o que precisamos para o benchmark.\n",
    "\n",
    "**Solução**: Faremos uma pequena modificação no código do Multi-GNN para salvar as probabilidades de predição (`preds`) e os identificadores verdadeiros (`ground_truth`) em um arquivo CSV.\n",
    "\n",
    "### Ação:\n",
    "1.  **Modifique o arquivo `train_util.py`**:\n",
    "    -   Abra o arquivo: `benchmarks/Multi-GNN/train_util.py`.\n",
    "    -   Encontre a função `evaluate_homo` (por volta da linha 99).\n",
    "    -   **Adicione o seguinte código** no final da função, logo antes da linha `return f1`:\n",
    "\n",
    "    ```python\n",
    "    # --- INÍCIO DA MODIFICAÇÃO PARA SALVAR PREDIÇÕES ---\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    # Salvar apenas durante a avaliação final (não na validação)\n",
    "    # Podemos checar o número de arestas no loader para diferenciar teste de validação.\n",
    "    # Esta é uma heurística; uma solução mais robusta passaria um argumento extra.\n",
    "    is_test_set = (loader.data.edge_attr.shape[0] == te_data.edge_attr.shape[0])\n",
    "\n",
    "    if is_test_set and args.save_model: # Usamos o save_model como gatilho\n",
    "        print(\"Salvando predições do conjunto de teste...\")\n",
    "        \n",
    "        # Extrai os IDs originais das arestas (transações)\n",
    "        # O loader embaralha os dados, então precisamos dos `input_id` para mapear de volta\n",
    "        original_edge_ids = inds[batch.input_id.detach().cpu()].numpy()\n",
    "\n",
    "        output_df = pd.DataFrame({\n",
    "            'edge_id': original_edge_ids,\n",
    "            'prediction_prob': out[:, 1].detach().cpu().numpy(), # Probabilidade da classe 1 (fraude)\n",
    "            'ground_truth': batch.y[mask].cpu().numpy()\n",
    "        })\n",
    "        \n",
    "        output_path = \"multi_gnn_predictions.csv\"\n",
    "        output_df.to_csv(output_path, index=False)\n",
    "        print(f\"Predições salvas em {os.path.abspath(output_path)}\")\n",
    "    # --- FIM DA MODIFICAÇÃO ---\n",
    "\n",
    "    return f1\n",
    "    ```\n",
    "    *Nota: A lógica acima é um exemplo. A implementação exata pode precisar de ajustes para capturar os tensores corretos (`out`, `batch.y`, etc.) dependendo da versão do PyG.*\n",
    "\n",
    "---\n",
    "\n",
    "## Fase 5: Execução Final e Integração\n",
    "\n",
    "Agora, execute o treinamento novamente, mas desta vez adicione o flag `--save_model` para ativar a lógica de salvamento que acabamos de adicionar.\n",
    "\n",
    "### Ações:\n",
    "1.  **Execute o Treinamento Final**:\n",
    "    ```bash\n",
    "    python benchmarks/Multi-GNN/main.py --data Small_HI --model gin --emlps --reverse_mp --testing --n_epochs 50 --save_model --unique_name aml_benchmark\n",
    "    ```\n",
    "    -   `--save_model`: Ativa o salvamento do modelo e, crucialmente, o nosso código de salvamento de predições.\n",
    "    -   `--unique_name aml_benchmark`: Nome para o checkpoint do modelo.\n",
    "\n",
    "2.  **Verifique o Artefato**: Após a execução, um arquivo `multi_gnn_predictions.csv` deve aparecer na raiz do projeto.\n",
    "\n",
    "3.  **Integre no Notebook Principal**: Agora você pode carregar este CSV no notebook `03_Modelagem_e_Avaliacao.ipynb` e comparar as probabilidades do Multi-GNN com as do seu modelo XGBoost no mesmo conjunto de teste."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
