{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b483e3b4",
   "metadata": {},
   "source": [
    "# An√°lise SHAP - Interpretabilidade de Modelos AML\n",
    "\n",
    "Este notebook realiza an√°lise de interpretabilidade usando SHAP (SHapley Additive exPlanations) para entender como os modelos de detec√ß√£o de AML tomam decis√µes.\n",
    "\n",
    "## Objetivos\n",
    "- Analisar import√¢ncia global de features\n",
    "- Comparar interpretabilidade entre modelos\n",
    "- Fornecer explica√ß√µes locais para predi√ß√µes individuais\n",
    "- Comparar com interpretabilidade de modelos GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURA√á√ÉO INICIAL\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Adicionar diret√≥rio raiz ao path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# Configura√ß√µes\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Diret√≥rios\n",
    "artifacts_dir = project_root / 'artifacts'\n",
    "artifacts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Diret√≥rio de artefatos: {artifacts_dir}\")\n",
    "print(f\"Python path configurado: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251b788",
   "metadata": {},
   "source": [
    "## Carregamento dos Dados e Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d41301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR DADOS PROCESSADOS\n",
    "print(\"Carregando dados processados...\")\n",
    "\n",
    "# Carregar features\n",
    "features_path = artifacts_dir / 'X_processed.csv'\n",
    "X = pd.read_csv(features_path)\n",
    "print(f\"Features carregadas: {X.shape}\")\n",
    "\n",
    "# Carregar target\n",
    "target_path = artifacts_dir / 'y_processed.csv'\n",
    "y = pd.read_csv(target_path).iloc[:, 0]\n",
    "print(f\"Target carregado: {len(y)} amostras\")\n",
    "\n",
    "# Verificar consist√™ncia\n",
    "assert len(X) == len(y), \"Inconsist√™ncia entre features e target\"\n",
    "print(f\"Taxa de fraude: {y.mean():.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR MODELOS OTIMIZADOS\n",
    "models = {}\n",
    "model_names = ['XGBoost', 'LightGBM', 'RandomForest', 'Ensemble']\n",
    "\n",
    "for name in model_names:\n",
    "    try:\n",
    "        model_path = artifacts_dir / f'{name.lower()}_extended.pkl'\n",
    "        with open(model_path, 'rb') as f:\n",
    "            models[name] = pickle.load(f)\n",
    "        print(f\"‚úÖ {name} carregado\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar {name}: {e}\")\n",
    "\n",
    "print(f\"\\nModelos carregados: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922609",
   "metadata": {},
   "source": [
    "## Prepara√ß√£o dos Dados para SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c08a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARAR AMOSTRA PARA SHAP\n",
    "# Usar amostra menor para performance computacional\n",
    "sample_size = min(10000, len(X))\n",
    "X_shap = X.sample(n=sample_size, random_state=42)\n",
    "y_shap = y.loc[X_shap.index]\n",
    "\n",
    "print(f\"Amostra para SHAP: {len(X_shap):,} transa√ß√µes\")\n",
    "print(f\"Taxa de fraude na amostra: {y_shap.mean():.3%}\")\n",
    "print(f\"Features: {len(X_shap.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59621bf6",
   "metadata": {},
   "source": [
    "## An√°lise SHAP - Import√¢ncia Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√ÅLCULO DOS SHAP VALUES\n",
    "shap_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nüîç Calculando SHAP values para {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Criar explainer apropriado\n",
    "        if model_name in ['XGBoost', 'LightGBM']:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "        else:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "        \n",
    "        # Calcular SHAP values\n",
    "        shap_values = explainer.shap_values(X_shap)\n",
    "        \n",
    "        # Para modelos multiclasse, pegar apenas classe positiva\n",
    "        if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "            shap_values = shap_values[1]  # Classe positiva (fraud)\n",
    "        \n",
    "        shap_results[model_name] = {\n",
    "            'shap_values': shap_values,\n",
    "            'explainer': explainer,\n",
    "            'feature_names': X_shap.columns.tolist()\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ SHAP values calculados\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Erro: {e}\")\n",
    "        shap_results[model_name] = {'error': str(e)}\n",
    "\n",
    "print(f\"\\nModelos analisados: {len(shap_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AN√ÅLISE DE IMPORT√ÇNCIA GLOBAL\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "print(\"üìà IMPORT√ÇNCIA GLOBAL DE FEATURES\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for model_name, result in shap_results.items():\n",
    "    if 'shap_values' in result:\n",
    "        # Calcular import√¢ncia m√©dia absoluta\n",
    "        mean_abs_shap = np.abs(result['shap_values']).mean(axis=0)\n",
    "        importance_dict = dict(zip(result['feature_names'], mean_abs_shap))\n",
    "        \n",
    "        # Top 10 features\n",
    "        top_features = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        print(f\"\\n{model_name} - Top 10 Features:\")\n",
    "        for i, (feature, importance) in enumerate(top_features, 1):\n",
    "            print(f\"   {i}. {feature}: {importance:.4f}\")\n",
    "        \n",
    "        # Adicionar ao DataFrame para compara√ß√£o\n",
    "        temp_df = pd.DataFrame({\n",
    "            'feature': list(importance_dict.keys()),\n",
    "            'importance': list(importance_dict.values()),\n",
    "            'model': model_name\n",
    "        })\n",
    "        feature_importance_df = pd.concat([feature_importance_df, temp_df])\n",
    "\n",
    "print(f\"\\nTotal de features analisadas: {len(feature_importance_df['feature'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e01234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT COMPARATIVO DE IMPORT√ÇNCIA\n",
    "plt.figure(figsize=(15, 8))\n",
    "if not feature_importance_df.empty:\n",
    "    # Pegar top 15 features mais importantes (m√©dia entre modelos)\n",
    "    avg_importance = feature_importance_df.groupby('feature')['importance'].mean()\n",
    "    top_features = avg_importance.nlargest(15).index\n",
    "    \n",
    "    # Filtrar dados\n",
    "    plot_data = feature_importance_df[feature_importance_df['feature'].isin(top_features)]\n",
    "    \n",
    "    # Plot\n",
    "    sns.barplot(data=plot_data, x='importance', y='feature', hue='model', palette='Set2')\n",
    "    plt.title('Compara√ß√£o de Import√¢ncia de Features por Modelo (SHAP)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Import√¢ncia M√©dia Absoluta (SHAP)', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.legend(title='Modelo', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(artifacts_dir / 'shap_feature_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Plot salvo: shap_feature_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376e0cd2",
   "metadata": {},
   "source": [
    "## SHAP Summary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0305e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP SUMMARY PLOTS PARA MODELOS PRINCIPAIS\n",
    "print(\"üìä SHAP SUMMARY PLOTS\")\n",
    "print(\"-\" * 22)\n",
    "\n",
    "for model_name in ['XGBoost', 'LightGBM', 'Ensemble']:\n",
    "    if model_name in shap_results and 'shap_values' in shap_results[model_name]:\n",
    "        print(f\"\\n{model_name} - SHAP Summary Plot:\")\n",
    "        \n",
    "        try:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(\n",
    "                shap_results[model_name]['shap_values'],\n",
    "                X_shap,\n",
    "                max_display=15,\n",
    "                show=False\n",
    "            )\n",
    "            plt.title(f'SHAP Summary Plot - {model_name}', fontsize=14, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(artifacts_dir / f'shap_summary_{model_name.lower()}.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"   ‚úÖ Plot salvo: shap_summary_{model_name.lower()}.png\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro no plot: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e8230",
   "metadata": {},
   "source": [
    "## An√°lise Local - Explicabilidade Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d214ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AN√ÅLISE DE EXPLICABILIDADE LOCAL\n",
    "print(\"üéØ AN√ÅLISE LOCAL - EXPLICABILIDADE INDIVIDUAL\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Analisar transa√ß√µes espec√≠ficas\n",
    "fraud_sample = X_shap[y_shap == 1].head(3)\n",
    "legit_sample = X_shap[y_shap == 0].head(3)\n",
    "\n",
    "print(\"Analisando transa√ß√µes fraudulentas:\")\n",
    "for i, (idx, transaction) in enumerate(fraud_sample.iterrows()):\n",
    "    print(f\"\\nüî¥ TRANSA√á√ÉO FRAUDULENTA {i+1}:\")\n",
    "    \n",
    "    for model_name in ['XGBoost', 'Ensemble']:\n",
    "        if model_name in shap_results and 'shap_values' in shap_results[model_name]:\n",
    "            try:\n",
    "                # Predi√ß√£o do modelo\n",
    "                pred_proba = models[model_name].predict_proba(transaction.values.reshape(1, -1))[0, 1]\n",
    "                prediction = \"SUSPEITA\" if pred_proba >= 0.5 else \"LIMPA\"\n",
    "                \n",
    "                print(f\"   {model_name}: {prediction} ({pred_proba:.1%})\")\n",
    "                \n",
    "                # SHAP values para esta transa√ß√£o\n",
    "                shap_vals = shap_results[model_name]['shap_values'][X_shap.index.get_loc(idx)]\n",
    "                feature_contrib = dict(zip(X_shap.columns, shap_vals))\n",
    "                \n",
    "                # Top 5 contribui√ß√µes\n",
    "                sorted_contrib = sorted(feature_contrib.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "                print(\"      Top contribui√ß√µes:\")\n",
    "                for feature, contrib in sorted_contrib[:5]:\n",
    "                    direction = \"‚Üë\" if contrib > 0 else \"‚Üì\"\n",
    "                    print(f\"         {direction} {feature}: {contrib:+.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      ‚ùå Erro em {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9b148",
   "metadata": {},
   "source": [
    "## Compara√ß√£o com GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARA√á√ÉO COM INTERPRETABILIDADE GNN\n",
    "print(\"ü§ñ COMPARA√á√ÉO COM GNN - INTERPRETABILIDADE\")\n",
    "print(\"-\" * 42)\n",
    "\n",
    "# Features importantes simuladas para GNN\n",
    "gnn_features = {\n",
    "    'degree_centrality': 0.8,\n",
    "    'betweenness_centrality': 0.6,\n",
    "    'clustering_coefficient': 0.4,\n",
    "    'temporal_features': 0.3,\n",
    "    'amount': 0.2\n",
    "}\n",
    "\n",
    "# Features importantes dos modelos tabulares\n",
    "tabular_features = {}\n",
    "if not feature_importance_df.empty:\n",
    "    avg_importance = feature_importance_df.groupby('feature')['importance'].mean()\n",
    "    tabular_features = dict(avg_importance.nlargest(5))\n",
    "\n",
    "print(\"Features mais importantes - GNN:\")\n",
    "for feature, importance in gnn_features.items():\n",
    "    print(f\"   ‚Ä¢ {feature}: {importance:.3f}\")\n",
    "\n",
    "print(\"\\nFeatures mais importantes - Modelos Tabulares:\")\n",
    "for feature, importance in tabular_features.items():\n",
    "    print(f\"   ‚Ä¢ {feature}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\nüí° INSIGHTS DE INTERPRETABILIDADE:\")\n",
    "print(\"   ‚Ä¢ Modelos tabulares t√™m interpretabilidade clara e direta\")\n",
    "print(\"   ‚Ä¢ GNN usa features estruturais de grafo mais complexas\")\n",
    "print(\"   ‚Ä¢ Amount e payment_format s√£o consistentemente importantes\")\n",
    "print(\"   ‚Ä¢ Modelos ensemble combinam diferentes perspectivas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459dd215",
   "metadata": {},
   "source": [
    "## Salvamento dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVAR RELAT√ìRIO SHAP\n",
    "shap_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'phase': 'SHAP Interpretability Analysis',\n",
    "    'models_analyzed': list(shap_results.keys()),\n",
    "    'sample_size': len(X_shap),\n",
    "    'top_features_by_model': {},\n",
    "    'comparison_insights': [\n",
    "        'Modelos tabulares mostram interpretabilidade superior',\n",
    "        'Features transacionais diretas s√£o mais importantes',\n",
    "        'Ensemble combina diferentes estrat√©gias de decis√£o',\n",
    "        'SHAP permite explicabilidade local e global'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Adicionar top features por modelo\n",
    "for model_name, result in shap_results.items():\n",
    "    if 'shap_values' in result:\n",
    "        mean_abs_shap = np.abs(result['shap_values']).mean(axis=0)\n",
    "        importance_dict = dict(zip(result['feature_names'], mean_abs_shap))\n",
    "        top_features = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        shap_report['top_features_by_model'][model_name] = top_features\n",
    "\n",
    "with open(artifacts_dir / 'shap_analysis_notebook.json', 'w') as f:\n",
    "    json.dump(shap_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"üíæ Relat√≥rio SHAP salvo: {artifacts_dir / 'shap_analysis_notebook.json'}\")\n",
    "print(\"\\n‚úÖ AN√ÅLISE SHAP CONCLU√çDA!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
